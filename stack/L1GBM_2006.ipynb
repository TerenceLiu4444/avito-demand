{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics#, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "import sys\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "path = \"/home/darragh/avito/data/\"\n",
    "#path = '/Users/dhanley2/Documents/avito/data/'\n",
    "#path = '/home/ubuntu/avito/data/'\n",
    "#data_path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb25 = pd.read_csv('../lgCV_2505.csv.gz', compression='gzip')\n",
    "lgb02A = pd.read_csv(path+'../sub/lgCV_0206A.csv.gz', compression='gzip')\n",
    "lgb09 = pd.read_csv(path+'../sub/lgCV_0906.csv.gz', compression='gzip')\n",
    "lgb10 = pd.read_csv(path+'../sub/lgCV_1006.csv.gz', compression='gzip')\n",
    "lgb11A= pd.read_csv(path+'../sub/lgCV_1106A.csv.gz', compression='gzip')\n",
    "lgb11D= pd.read_csv(path+'../sub/lgCV_1106D.csv.gz', compression='gzip')\n",
    "lgb14= pd.read_csv(path+'../sub/lgCV_1406.csv.gz', compression='gzip')\n",
    "lgb14A= pd.read_csv(path+'../sub/lgCV_1406A.csv.gz', compression='gzip')\n",
    "lgb27 = pd.read_csv(path+'../sub/lgCV_2705B.csv.gz', compression='gzip')\n",
    "lgb31 = pd.read_csv(path+'../sub/lgCV_3105.csv.gz', compression='gzip')\n",
    "lgb02 = pd.read_csv(path+'../sub/lgCV_0206.csv.gz', compression='gzip')\n",
    "lgb17 = pd.read_csv(path+'../sub/lgCV_1706.csv.gz', compression='gzip')\n",
    "lgb19 = pd.read_csv(path+'../sub/lgCV_1906.csv.gz', compression='gzip')\n",
    "lgb19A= pd.read_csv(path+'../sub/lgCV_1906A.csv.gz', compression='gzip')\n",
    "rnn =   pd.read_csv(path+'../sub/rnnCV_2805.csv.gz', compression='gzip')\n",
    "rnn27 = pd.read_csv(path+'../sub/rnnCV_2705A.csv.gz', compression='gzip')\n",
    "rnn12 = pd.read_csv(path+'../sub/rnnCV_1206.csv.gz', compression='gzip')\n",
    "mlp =   pd.read_csv(path+'../sub/mlpCV_2505.csv.gz', compression='gzip')\n",
    "rdgv19 =   pd.read_csv(path+'../sub/rdgv19CV_1606.csv.gz', compression='gzip')\n",
    "truth = pd.read_csv(path+'train.csv.zip', compression='zip', parse_dates = [\"activation_date\"])\n",
    "y =     truth['deal_probability'].values\n",
    "truth.drop('deal_probability', 1)\n",
    "test =  pd.read_csv(path+'test.csv.zip', compression='zip', parse_dates = [\"activation_date\"])\n",
    "test['deal_probability']=float('NAN') \n",
    "truth = pd.concat([truth,test[truth.columns]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb14['deal_probability'] =  ( lgb14['deal_probability'].values + lgb14A['deal_probability'].values)*0.5\n",
    "lgb17['deal_probability'] =  ( lgb17['deal_probability'].values + lgb19['deal_probability'].values)*0.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_cts = truth['image_top_1'].value_counts().reset_index()\n",
    "#truth['image_top_big'] = 'lo_count'\n",
    "#big_top_1 = img_cts[img_cts['image_top_1']>5000]['index'].tolist()\n",
    "#idx = truth['image_top_1'].isin(big_top_1)\n",
    "#truth['image_top_big'][idx] = truth['image_top_1'][idx].astype(str).values\n",
    "\n",
    "def keep_big(df, col, cutoff):\n",
    "    cts = df[col].value_counts().reset_index()\n",
    "    df[col+'_big'] = 'lo_count'\n",
    "    big = cts[cts[col]>cutoff]['index'].tolist()\n",
    "    idx = df[col].isin(big)\n",
    "    df[col+'_big'][idx] = df[col][idx].astype(str).values\n",
    "    return df[col+'_big'].values\n",
    "truth['image_top_1_big'] = keep_big(truth, 'image_top_1', 5000)\n",
    "truth['param_1_big'] = keep_big(truth, 'param_1', 5000)\n",
    "truth['param_2_big'] = keep_big(truth, 'param_2', 5000)\n",
    "truth['param_3_big'] = keep_big(truth, 'param_3', 5000)\n",
    "truth['city_big'] = keep_big(truth, 'city', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_top_1_big</th>\n",
       "      <th>param_1_big</th>\n",
       "      <th>param_2_big</th>\n",
       "      <th>param_3_big</th>\n",
       "      <th>city_big</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lo_count</td>\n",
       "      <td>Постельные принадлежности</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>Екатеринбург</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lo_count</td>\n",
       "      <td>Другое</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>Самара</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lo_count</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>Ростов-на-Дону</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>796.0</td>\n",
       "      <td>Автомобильные кресла</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>Набережные Челны</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2264.0</td>\n",
       "      <td>С пробегом</td>\n",
       "      <td>ВАЗ (LADA)</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>Волгоград</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_top_1_big                param_1_big param_2_big param_3_big  \\\n",
       "0        lo_count  Постельные принадлежности    lo_count    lo_count   \n",
       "1        lo_count                     Другое    lo_count    lo_count   \n",
       "2        lo_count                   lo_count    lo_count    lo_count   \n",
       "3           796.0       Автомобильные кресла    lo_count    lo_count   \n",
       "4          2264.0                 С пробегом  ВАЗ (LADA)    lo_count   \n",
       "\n",
       "           city_big  \n",
       "0      Екатеринбург  \n",
       "1            Самара  \n",
       "2    Ростов-на-Дону  \n",
       "3  Набережные Челны  \n",
       "4         Волгоград  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth[[c for c in truth.columns if 'big' in c]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb25.rename(columns={'deal_probability': 'lgb25_preds' }, inplace=True)\n",
    "lgb31.rename(columns={'deal_probability': 'lgb31_preds' }, inplace=True)\n",
    "lgb27.rename(columns={'deal_probability': 'lgb27_preds' }, inplace=True)\n",
    "lgb02.rename(columns={'deal_probability': 'lgb02_preds' }, inplace=True)\n",
    "lgb09.rename(columns={'deal_probability': 'lgb09_preds' }, inplace=True)\n",
    "lgb10.rename(columns={'deal_probability': 'lgb10_preds' }, inplace=True)\n",
    "lgb11D.rename(columns={'deal_probability': 'lgb11D_preds' }, inplace=True)\n",
    "lgb11A.rename(columns={'deal_probability': 'lgb11A_preds' }, inplace=True)\n",
    "lgb14.rename(columns={'deal_probability': 'lgb14_preds' }, inplace=True)\n",
    "lgb17.rename(columns={'deal_probability': 'lgb17_preds' }, inplace=True)\n",
    "lgb19A.rename(columns={'deal_probability': 'lgb19A_preds' }, inplace=True)\n",
    "lgb02A.rename(columns={'deal_probability': 'lgb02A_preds' }, inplace=True)\n",
    "rnn27.rename(columns={'deal_probability': 'rnn27_preds' }, inplace=True)\n",
    "rnn12.rename(columns={'deal_probability': 'rnn12_preds' }, inplace=True)\n",
    "rdgv19.rename(columns={'deal_probability': 'rdgv19_preds' }, inplace=True)\n",
    "mlp.rename(columns={'deal_probability': 'mlp_preds' }, inplace=True)\n",
    "preds_df = lgb27.merge(rnn, on='item_id')\\\n",
    "                .merge(mlp, on='item_id')\\\n",
    "                .merge(lgb31, on='item_id')\\\n",
    "                .merge(lgb02, on='item_id')\\\n",
    "                .merge(lgb09, on='item_id')\\\n",
    "                .merge(lgb10, on='item_id')\\\n",
    "                .merge(lgb11A, on='item_id')\\\n",
    "                .merge(lgb11D, on='item_id')\\\n",
    "                .merge(lgb14, on='item_id')\\\n",
    "                .merge(lgb17, on='item_id')\\\n",
    "                .merge(lgb19A, on='item_id')\\\n",
    "                .merge(lgb02A, on='item_id')\\\n",
    "                .merge(rnn27, on='item_id')\\\n",
    "                .merge(rnn12, on='item_id')\\\n",
    "                .merge(rdgv19, on='item_id')\\\n",
    "                .merge(truth, on='item_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rnn_preds',\n",
       " 'mlp_preds',\n",
       " 'lgb31_preds',\n",
       " 'lgb09_preds',\n",
       " 'lgb10_preds',\n",
       " 'lgb11D_preds',\n",
       " 'lgb14_preds',\n",
       " 'lgb17_preds',\n",
       " 'lgb19A_preds',\n",
       " 'lgb02A_preds',\n",
       " 'rnn27_preds',\n",
       " 'rnn12_preds']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cols = [col for col in preds_df.columns if ('_preds' in col) \\\n",
    "             and ('lgb27' not in col) and ('lgb02_' not in col) and ('lgb11A_' not in col) \\\n",
    "             and ('rdgv19_' not in col)]\n",
    "\n",
    "preds_df['preds_sum'] = preds_df[pred_cols].sum(axis=1)\n",
    "pred_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df['price'].fillna(-1,inplace=True)\n",
    "preds_df['max'] = np.max(np.array([preds_df[col] for col in pred_cols]),axis=0)\n",
    "preds_df['min'] = np.min(np.array([preds_df[col] for col in pred_cols]),axis=0)\n",
    "preds_df['avg'] = np.mean(np.array([preds_df[col] for col in pred_cols]),axis=0)\n",
    "preds_df['med'] = np.median(np.array([preds_df[col] for col in pred_cols]),axis=0)\n",
    "preds_df['std'] = np.std(np.array([preds_df[col] for col in pred_cols]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference_rnn_preds__mlp_preds\n",
      "difference_rnn_preds__lgb31_preds\n",
      "difference_rnn_preds__lgb09_preds\n",
      "difference_rnn_preds__lgb10_preds\n",
      "difference_rnn_preds__lgb11D_preds\n",
      "difference_rnn_preds__lgb14_preds\n",
      "difference_rnn_preds__lgb17_preds\n",
      "difference_rnn_preds__lgb19A_preds\n",
      "difference_rnn_preds__lgb02A_preds\n",
      "difference_rnn_preds__rnn27_preds\n",
      "difference_rnn_preds__rnn12_preds\n",
      "difference_mlp_preds__lgb31_preds\n",
      "difference_mlp_preds__lgb09_preds\n",
      "difference_mlp_preds__lgb10_preds\n",
      "difference_mlp_preds__lgb11D_preds\n",
      "difference_mlp_preds__lgb14_preds\n",
      "difference_mlp_preds__lgb17_preds\n",
      "difference_mlp_preds__lgb19A_preds\n",
      "difference_mlp_preds__lgb02A_preds\n",
      "difference_mlp_preds__rnn27_preds\n",
      "difference_mlp_preds__rnn12_preds\n",
      "difference_lgb31_preds__lgb09_preds\n",
      "difference_lgb31_preds__lgb10_preds\n",
      "difference_lgb31_preds__lgb11D_preds\n",
      "difference_lgb31_preds__lgb14_preds\n",
      "difference_lgb31_preds__lgb17_preds\n",
      "difference_lgb31_preds__lgb19A_preds\n",
      "difference_lgb31_preds__lgb02A_preds\n",
      "difference_lgb31_preds__rnn27_preds\n",
      "difference_lgb31_preds__rnn12_preds\n",
      "difference_lgb09_preds__lgb10_preds\n",
      "difference_lgb09_preds__lgb11D_preds\n",
      "difference_lgb09_preds__lgb14_preds\n",
      "difference_lgb09_preds__lgb17_preds\n",
      "difference_lgb09_preds__lgb19A_preds\n",
      "difference_lgb09_preds__lgb02A_preds\n",
      "difference_lgb09_preds__rnn27_preds\n",
      "difference_lgb09_preds__rnn12_preds\n",
      "difference_lgb10_preds__lgb11D_preds\n",
      "difference_lgb10_preds__lgb14_preds\n",
      "difference_lgb10_preds__lgb17_preds\n",
      "difference_lgb10_preds__lgb19A_preds\n",
      "difference_lgb10_preds__lgb02A_preds\n",
      "difference_lgb10_preds__rnn27_preds\n",
      "difference_lgb10_preds__rnn12_preds\n",
      "difference_lgb11D_preds__lgb14_preds\n",
      "difference_lgb11D_preds__lgb17_preds\n",
      "difference_lgb11D_preds__lgb19A_preds\n",
      "difference_lgb11D_preds__lgb02A_preds\n",
      "difference_lgb11D_preds__rnn27_preds\n",
      "difference_lgb11D_preds__rnn12_preds\n",
      "difference_lgb14_preds__lgb17_preds\n",
      "difference_lgb14_preds__lgb19A_preds\n",
      "difference_lgb14_preds__lgb02A_preds\n",
      "difference_lgb14_preds__rnn27_preds\n",
      "difference_lgb14_preds__rnn12_preds\n",
      "difference_lgb17_preds__lgb19A_preds\n",
      "difference_lgb17_preds__lgb02A_preds\n",
      "difference_lgb17_preds__rnn27_preds\n",
      "difference_lgb17_preds__rnn12_preds\n",
      "difference_lgb19A_preds__lgb02A_preds\n",
      "difference_lgb19A_preds__rnn27_preds\n",
      "difference_lgb19A_preds__rnn12_preds\n",
      "difference_lgb02A_preds__rnn27_preds\n",
      "difference_lgb02A_preds__rnn12_preds\n",
      "difference_rnn27_preds__rnn12_preds\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for p1, p2 in itertools.combinations(pred_cols, 2):\n",
    "    print('difference_%s__%s'%(p1,p2))\n",
    "    preds_df['difference_%s__%s'%(p1,p2)] = preds_df[p2] - preds_df[p1]\n",
    "    preds_df['sums_%s__%s'%(p1,p2)] = preds_df[p2] + preds_df[p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>lgb27_preds</th>\n",
       "      <th>rnn_preds</th>\n",
       "      <th>mlp_preds</th>\n",
       "      <th>lgb31_preds</th>\n",
       "      <th>lgb02_preds</th>\n",
       "      <th>lgb09_preds</th>\n",
       "      <th>lgb10_preds</th>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <th>...</th>\n",
       "      <th>difference_lgb19A_preds__rnn27_preds</th>\n",
       "      <th>sums_lgb19A_preds__rnn27_preds</th>\n",
       "      <th>difference_lgb19A_preds__rnn12_preds</th>\n",
       "      <th>sums_lgb19A_preds__rnn12_preds</th>\n",
       "      <th>difference_lgb02A_preds__rnn27_preds</th>\n",
       "      <th>sums_lgb02A_preds__rnn27_preds</th>\n",
       "      <th>difference_lgb02A_preds__rnn12_preds</th>\n",
       "      <th>sums_lgb02A_preds__rnn12_preds</th>\n",
       "      <th>difference_rnn27_preds__rnn12_preds</th>\n",
       "      <th>sums_rnn27_preds__rnn12_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b912c3c6a6ad</td>\n",
       "      <td>0.091656</td>\n",
       "      <td>0.069891</td>\n",
       "      <td>0.091223</td>\n",
       "      <td>0.083219</td>\n",
       "      <td>0.090855</td>\n",
       "      <td>0.109624</td>\n",
       "      <td>0.107764</td>\n",
       "      <td>0.095101</td>\n",
       "      <td>0.092921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017792</td>\n",
       "      <td>0.154454</td>\n",
       "      <td>-0.009246</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>-0.041287</td>\n",
       "      <td>0.177948</td>\n",
       "      <td>-0.032740</td>\n",
       "      <td>0.186494</td>\n",
       "      <td>0.008546</td>\n",
       "      <td>0.145208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dac0150717d</td>\n",
       "      <td>0.147801</td>\n",
       "      <td>0.075968</td>\n",
       "      <td>0.211844</td>\n",
       "      <td>0.157973</td>\n",
       "      <td>0.119609</td>\n",
       "      <td>0.157466</td>\n",
       "      <td>0.161107</td>\n",
       "      <td>0.140269</td>\n",
       "      <td>0.144395</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067602</td>\n",
       "      <td>0.208879</td>\n",
       "      <td>-0.049681</td>\n",
       "      <td>0.226800</td>\n",
       "      <td>-0.089406</td>\n",
       "      <td>0.230683</td>\n",
       "      <td>-0.071485</td>\n",
       "      <td>0.248604</td>\n",
       "      <td>0.017921</td>\n",
       "      <td>0.159198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba83aefab5dc</td>\n",
       "      <td>0.186261</td>\n",
       "      <td>0.167167</td>\n",
       "      <td>0.236579</td>\n",
       "      <td>0.227048</td>\n",
       "      <td>0.258980</td>\n",
       "      <td>0.245236</td>\n",
       "      <td>0.219107</td>\n",
       "      <td>0.234076</td>\n",
       "      <td>0.222678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061566</td>\n",
       "      <td>0.385415</td>\n",
       "      <td>-0.075465</td>\n",
       "      <td>0.371516</td>\n",
       "      <td>-0.079412</td>\n",
       "      <td>0.403260</td>\n",
       "      <td>-0.093311</td>\n",
       "      <td>0.389361</td>\n",
       "      <td>-0.013899</td>\n",
       "      <td>0.309950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02996f1dd2ea</td>\n",
       "      <td>0.241699</td>\n",
       "      <td>0.260876</td>\n",
       "      <td>0.383699</td>\n",
       "      <td>0.231447</td>\n",
       "      <td>0.284130</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>0.255519</td>\n",
       "      <td>0.241802</td>\n",
       "      <td>0.271355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044863</td>\n",
       "      <td>0.512745</td>\n",
       "      <td>0.014382</td>\n",
       "      <td>0.482264</td>\n",
       "      <td>-0.057652</td>\n",
       "      <td>0.615259</td>\n",
       "      <td>-0.088132</td>\n",
       "      <td>0.584779</td>\n",
       "      <td>-0.030481</td>\n",
       "      <td>0.527127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c90be56d2ab</td>\n",
       "      <td>0.407423</td>\n",
       "      <td>0.431520</td>\n",
       "      <td>0.420657</td>\n",
       "      <td>0.412563</td>\n",
       "      <td>0.430581</td>\n",
       "      <td>0.511145</td>\n",
       "      <td>0.511676</td>\n",
       "      <td>0.504849</td>\n",
       "      <td>0.503961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154635</td>\n",
       "      <td>0.855203</td>\n",
       "      <td>-0.083575</td>\n",
       "      <td>0.926263</td>\n",
       "      <td>-0.071704</td>\n",
       "      <td>0.772273</td>\n",
       "      <td>-0.000645</td>\n",
       "      <td>0.843332</td>\n",
       "      <td>0.071059</td>\n",
       "      <td>0.771628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id  lgb27_preds  rnn_preds  mlp_preds  lgb31_preds  lgb02_preds  \\\n",
       "0  b912c3c6a6ad     0.091656   0.069891   0.091223     0.083219     0.090855   \n",
       "1  2dac0150717d     0.147801   0.075968   0.211844     0.157973     0.119609   \n",
       "2  ba83aefab5dc     0.186261   0.167167   0.236579     0.227048     0.258980   \n",
       "3  02996f1dd2ea     0.241699   0.260876   0.383699     0.231447     0.284130   \n",
       "4  7c90be56d2ab     0.407423   0.431520   0.420657     0.412563     0.430581   \n",
       "\n",
       "   lgb09_preds  lgb10_preds  lgb11A_preds  lgb11D_preds  \\\n",
       "0     0.109624     0.107764      0.095101      0.092921   \n",
       "1     0.157466     0.161107      0.140269      0.144395   \n",
       "2     0.245236     0.219107      0.234076      0.222678   \n",
       "3     0.289101     0.255519      0.241802      0.271355   \n",
       "4     0.511145     0.511676      0.504849      0.503961   \n",
       "\n",
       "               ...               difference_lgb19A_preds__rnn27_preds  \\\n",
       "0              ...                                          -0.017792   \n",
       "1              ...                                          -0.067602   \n",
       "2              ...                                          -0.061566   \n",
       "3              ...                                           0.044863   \n",
       "4              ...                                          -0.154635   \n",
       "\n",
       "   sums_lgb19A_preds__rnn27_preds  difference_lgb19A_preds__rnn12_preds  \\\n",
       "0                        0.154454                             -0.009246   \n",
       "1                        0.208879                             -0.049681   \n",
       "2                        0.385415                             -0.075465   \n",
       "3                        0.512745                              0.014382   \n",
       "4                        0.855203                             -0.083575   \n",
       "\n",
       "   sums_lgb19A_preds__rnn12_preds  difference_lgb02A_preds__rnn27_preds  \\\n",
       "0                        0.163000                             -0.041287   \n",
       "1                        0.226800                             -0.089406   \n",
       "2                        0.371516                             -0.079412   \n",
       "3                        0.482264                             -0.057652   \n",
       "4                        0.926263                             -0.071704   \n",
       "\n",
       "   sums_lgb02A_preds__rnn27_preds  difference_lgb02A_preds__rnn12_preds  \\\n",
       "0                        0.177948                             -0.032740   \n",
       "1                        0.230683                             -0.071485   \n",
       "2                        0.403260                             -0.093311   \n",
       "3                        0.615259                             -0.088132   \n",
       "4                        0.772273                             -0.000645   \n",
       "\n",
       "   sums_lgb02A_preds__rnn12_preds difference_rnn27_preds__rnn12_preds  \\\n",
       "0                        0.186494                            0.008546   \n",
       "1                        0.248604                            0.017921   \n",
       "2                        0.389361                           -0.013899   \n",
       "3                        0.584779                           -0.030481   \n",
       "4                        0.843332                            0.071059   \n",
       "\n",
       "  sums_rnn27_preds__rnn12_preds  \n",
       "0                      0.145208  \n",
       "1                      0.159198  \n",
       "2                      0.309950  \n",
       "3                      0.527127  \n",
       "4                      0.771628  \n",
       "\n",
       "[5 rows x 178 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgb27_preds',\n",
       " 'rnn_preds',\n",
       " 'mlp_preds',\n",
       " 'lgb31_preds',\n",
       " 'lgb02_preds',\n",
       " 'lgb09_preds',\n",
       " 'lgb10_preds',\n",
       " 'lgb11A_preds',\n",
       " 'lgb11D_preds',\n",
       " 'lgb14_preds',\n",
       " 'lgb17_preds',\n",
       " 'lgb19A_preds',\n",
       " 'lgb02A_preds',\n",
       " 'rnn27_preds',\n",
       " 'rnn12_preds',\n",
       " 'rdgv19_preds']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cols = [col for col in preds_df.columns if ('preds' in col) \n",
    "             and ('difference' not in col) \n",
    "             and ('sum' not in col)]\n",
    "pred_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     1503424\n",
      "False     508438\n",
      "Name: deal_probability, dtype: int64\n",
      "RMSE lgb27_preds:  0.21681527582821059\n",
      "RMSE rnn_preds:  0.21771476573780568\n",
      "RMSE mlp_preds:  0.2187544351068867\n",
      "RMSE lgb31_preds:  0.21681135578306754\n",
      "RMSE lgb02_preds:  0.21625386267187377\n",
      "RMSE lgb09_preds:  0.21581543265040168\n",
      "RMSE lgb10_preds:  0.21533498019117664\n",
      "RMSE lgb11A_preds:  0.21403812331071156\n",
      "RMSE lgb11D_preds:  0.21392147604708842\n",
      "RMSE lgb14_preds:  0.21329729304260686\n",
      "RMSE lgb17_preds:  0.21311496843894262\n",
      "RMSE lgb19A_preds:  0.21341739569735188\n",
      "RMSE lgb02A_preds:  0.21627136604335995\n",
      "RMSE rnn27_preds:  0.21698040871120608\n",
      "RMSE rnn12_preds:  0.2167114508342396\n",
      "RMSE rdgv19_preds:  0.24593955235646558\n"
     ]
    }
   ],
   "source": [
    "idx = preds_df['deal_probability']==preds_df['deal_probability']\n",
    "print(idx.value_counts())\n",
    "for col in [c for c in preds_df.columns if ('_preds' in c) and ('difference' not in c) and ('sum' not in c)]:\n",
    "    print('RMSE %s: '%(col), np.sqrt(metrics.mean_squared_error(preds_df['deal_probability'][idx].values, preds_df[col][idx].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldls = [[\"2017-03-15\", \"2017-03-16\", \"2017-03-17\"], \\\n",
    "       [\"2017-03-18\", \"2017-03-19\", \"2017-03-20\"], \\\n",
    "       [\"2017-03-21\", \"2017-03-22\", \"2017-03-23\"], \\\n",
    "       [\"2017-03-24\", \"2017-03-25\", \"2017-03-26\"], \\\n",
    "        [\"2017-03-27\", \"2017-03-28\", \"2017-03-29\", \\\n",
    "            \"2017-03-30\", \"2017-03-31\", \"2017-04-01\", \\\n",
    "            \"2017-04-02\", \"2017-04-03\",\"2017-04-07\"]]\n",
    "foldls = [[pd.to_datetime(d) for d in f] for f in foldls]\n",
    "preds_df['fold'] = -1\n",
    "for t, fold in enumerate(foldls):\n",
    "    preds_df['fold'][preds_df.activation_date.isin(fold)] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold0</th>\n",
       "      <th>Fold1</th>\n",
       "      <th>Fold2</th>\n",
       "      <th>Fold3</th>\n",
       "      <th>Fold4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgb27_preds</td>\n",
       "      <td>0.216848</td>\n",
       "      <td>0.217096</td>\n",
       "      <td>0.217923</td>\n",
       "      <td>0.217597</td>\n",
       "      <td>0.213692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rnn_preds</td>\n",
       "      <td>0.218756</td>\n",
       "      <td>0.218966</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.219554</td>\n",
       "      <td>0.214747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlp_preds</td>\n",
       "      <td>0.219660</td>\n",
       "      <td>0.220088</td>\n",
       "      <td>0.216672</td>\n",
       "      <td>0.220347</td>\n",
       "      <td>0.216385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lgb31_preds</td>\n",
       "      <td>0.216537</td>\n",
       "      <td>0.216643</td>\n",
       "      <td>0.219230</td>\n",
       "      <td>0.217169</td>\n",
       "      <td>0.213430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgb02_preds</td>\n",
       "      <td>0.216371</td>\n",
       "      <td>0.216447</td>\n",
       "      <td>0.217354</td>\n",
       "      <td>0.217032</td>\n",
       "      <td>0.213158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lgb09_preds</td>\n",
       "      <td>0.215514</td>\n",
       "      <td>0.215678</td>\n",
       "      <td>0.218418</td>\n",
       "      <td>0.216073</td>\n",
       "      <td>0.212293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lgb10_preds</td>\n",
       "      <td>0.215240</td>\n",
       "      <td>0.215533</td>\n",
       "      <td>0.217072</td>\n",
       "      <td>0.215802</td>\n",
       "      <td>0.212023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lgb11A_preds</td>\n",
       "      <td>0.215011</td>\n",
       "      <td>0.215205</td>\n",
       "      <td>0.211879</td>\n",
       "      <td>0.215771</td>\n",
       "      <td>0.211735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lgb11D_preds</td>\n",
       "      <td>0.214818</td>\n",
       "      <td>0.215074</td>\n",
       "      <td>0.211837</td>\n",
       "      <td>0.215720</td>\n",
       "      <td>0.211549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lgb14_preds</td>\n",
       "      <td>0.214204</td>\n",
       "      <td>0.214441</td>\n",
       "      <td>0.211074</td>\n",
       "      <td>0.215146</td>\n",
       "      <td>0.211051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lgb17_preds</td>\n",
       "      <td>0.214061</td>\n",
       "      <td>0.214275</td>\n",
       "      <td>0.210872</td>\n",
       "      <td>0.214884</td>\n",
       "      <td>0.210930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lgb19A_preds</td>\n",
       "      <td>0.214280</td>\n",
       "      <td>0.214530</td>\n",
       "      <td>0.211292</td>\n",
       "      <td>0.215184</td>\n",
       "      <td>0.211253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>lgb02A_preds</td>\n",
       "      <td>0.216081</td>\n",
       "      <td>0.216051</td>\n",
       "      <td>0.218825</td>\n",
       "      <td>0.216562</td>\n",
       "      <td>0.212741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rnn27_preds</td>\n",
       "      <td>0.218097</td>\n",
       "      <td>0.218115</td>\n",
       "      <td>0.214982</td>\n",
       "      <td>0.218651</td>\n",
       "      <td>0.214379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rnn12_preds</td>\n",
       "      <td>0.217658</td>\n",
       "      <td>0.217913</td>\n",
       "      <td>0.214952</td>\n",
       "      <td>0.218472</td>\n",
       "      <td>0.213781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rdgv19_preds</td>\n",
       "      <td>0.246571</td>\n",
       "      <td>0.246399</td>\n",
       "      <td>0.244456</td>\n",
       "      <td>0.247503</td>\n",
       "      <td>0.244406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model     Fold0     Fold1     Fold2     Fold3     Fold4\n",
       "0    lgb27_preds  0.216848  0.217096  0.217923  0.217597  0.213692\n",
       "1      rnn_preds  0.218756  0.218966  0.215764  0.219554  0.214747\n",
       "2      mlp_preds  0.219660  0.220088  0.216672  0.220347  0.216385\n",
       "3    lgb31_preds  0.216537  0.216643  0.219230  0.217169  0.213430\n",
       "4    lgb02_preds  0.216371  0.216447  0.217354  0.217032  0.213158\n",
       "5    lgb09_preds  0.215514  0.215678  0.218418  0.216073  0.212293\n",
       "6    lgb10_preds  0.215240  0.215533  0.217072  0.215802  0.212023\n",
       "7   lgb11A_preds  0.215011  0.215205  0.211879  0.215771  0.211735\n",
       "8   lgb11D_preds  0.214818  0.215074  0.211837  0.215720  0.211549\n",
       "9    lgb14_preds  0.214204  0.214441  0.211074  0.215146  0.211051\n",
       "10   lgb17_preds  0.214061  0.214275  0.210872  0.214884  0.210930\n",
       "11  lgb19A_preds  0.214280  0.214530  0.211292  0.215184  0.211253\n",
       "12  lgb02A_preds  0.216081  0.216051  0.218825  0.216562  0.212741\n",
       "13   rnn27_preds  0.218097  0.218115  0.214982  0.218651  0.214379\n",
       "14   rnn12_preds  0.217658  0.217913  0.214952  0.218472  0.213781\n",
       "15  rdgv19_preds  0.246571  0.246399  0.244456  0.247503  0.244406"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for col in [c for c in preds_df.columns if ('_preds' in c) \\\n",
    "            and ('difference' not in c) \\\n",
    "            and ('sum' not in c)]:\n",
    "    lstmp = [col]\n",
    "    for i in range(5):\n",
    "        idx = preds_df['fold']==i\n",
    "        lstmp.append(np.sqrt(metrics.mean_squared_error(preds_df['deal_probability'][idx].values, \\\n",
    "                                                        preds_df[col][idx].values)))\n",
    "    scores.append(lstmp)\n",
    "pd.DataFrame(scores, columns = ['Model']+['Fold%s'%(i) for i in range(5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations in test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb27_preds</th>\n",
       "      <th>rnn_preds</th>\n",
       "      <th>mlp_preds</th>\n",
       "      <th>lgb31_preds</th>\n",
       "      <th>lgb02_preds</th>\n",
       "      <th>lgb09_preds</th>\n",
       "      <th>lgb10_preds</th>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <th>lgb14_preds</th>\n",
       "      <th>lgb17_preds</th>\n",
       "      <th>lgb19A_preds</th>\n",
       "      <th>lgb02A_preds</th>\n",
       "      <th>rnn27_preds</th>\n",
       "      <th>rnn12_preds</th>\n",
       "      <th>rdgv19_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lgb27_preds</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915952</td>\n",
       "      <td>0.919171</td>\n",
       "      <td>0.990750</td>\n",
       "      <td>0.988682</td>\n",
       "      <td>0.978331</td>\n",
       "      <td>0.978298</td>\n",
       "      <td>0.966819</td>\n",
       "      <td>0.965873</td>\n",
       "      <td>0.961540</td>\n",
       "      <td>0.963754</td>\n",
       "      <td>0.957731</td>\n",
       "      <td>0.983143</td>\n",
       "      <td>0.916804</td>\n",
       "      <td>0.920576</td>\n",
       "      <td>0.568406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn_preds</th>\n",
       "      <td>0.915952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929710</td>\n",
       "      <td>0.910602</td>\n",
       "      <td>0.913307</td>\n",
       "      <td>0.908867</td>\n",
       "      <td>0.913286</td>\n",
       "      <td>0.915655</td>\n",
       "      <td>0.913936</td>\n",
       "      <td>0.912870</td>\n",
       "      <td>0.915690</td>\n",
       "      <td>0.910086</td>\n",
       "      <td>0.911443</td>\n",
       "      <td>0.985360</td>\n",
       "      <td>0.978274</td>\n",
       "      <td>0.551100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_preds</th>\n",
       "      <td>0.919171</td>\n",
       "      <td>0.929710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914307</td>\n",
       "      <td>0.916343</td>\n",
       "      <td>0.909521</td>\n",
       "      <td>0.913883</td>\n",
       "      <td>0.915367</td>\n",
       "      <td>0.913018</td>\n",
       "      <td>0.911656</td>\n",
       "      <td>0.915252</td>\n",
       "      <td>0.908837</td>\n",
       "      <td>0.913600</td>\n",
       "      <td>0.925010</td>\n",
       "      <td>0.929518</td>\n",
       "      <td>0.577280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb31_preds</th>\n",
       "      <td>0.990750</td>\n",
       "      <td>0.910602</td>\n",
       "      <td>0.914307</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991984</td>\n",
       "      <td>0.981891</td>\n",
       "      <td>0.981375</td>\n",
       "      <td>0.966656</td>\n",
       "      <td>0.965897</td>\n",
       "      <td>0.961575</td>\n",
       "      <td>0.963672</td>\n",
       "      <td>0.957796</td>\n",
       "      <td>0.986851</td>\n",
       "      <td>0.914204</td>\n",
       "      <td>0.916939</td>\n",
       "      <td>0.570034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb02_preds</th>\n",
       "      <td>0.988682</td>\n",
       "      <td>0.913307</td>\n",
       "      <td>0.916343</td>\n",
       "      <td>0.991984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982596</td>\n",
       "      <td>0.982052</td>\n",
       "      <td>0.970858</td>\n",
       "      <td>0.969933</td>\n",
       "      <td>0.966325</td>\n",
       "      <td>0.968201</td>\n",
       "      <td>0.962391</td>\n",
       "      <td>0.987434</td>\n",
       "      <td>0.916726</td>\n",
       "      <td>0.920105</td>\n",
       "      <td>0.567698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb09_preds</th>\n",
       "      <td>0.978331</td>\n",
       "      <td>0.908867</td>\n",
       "      <td>0.909521</td>\n",
       "      <td>0.981891</td>\n",
       "      <td>0.982596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990447</td>\n",
       "      <td>0.976755</td>\n",
       "      <td>0.976540</td>\n",
       "      <td>0.972392</td>\n",
       "      <td>0.972977</td>\n",
       "      <td>0.968260</td>\n",
       "      <td>0.988708</td>\n",
       "      <td>0.912375</td>\n",
       "      <td>0.915090</td>\n",
       "      <td>0.560909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb10_preds</th>\n",
       "      <td>0.978298</td>\n",
       "      <td>0.913286</td>\n",
       "      <td>0.913883</td>\n",
       "      <td>0.981375</td>\n",
       "      <td>0.982052</td>\n",
       "      <td>0.990447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982841</td>\n",
       "      <td>0.982033</td>\n",
       "      <td>0.977396</td>\n",
       "      <td>0.978691</td>\n",
       "      <td>0.973449</td>\n",
       "      <td>0.985858</td>\n",
       "      <td>0.916436</td>\n",
       "      <td>0.920034</td>\n",
       "      <td>0.562639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <td>0.966819</td>\n",
       "      <td>0.915655</td>\n",
       "      <td>0.915367</td>\n",
       "      <td>0.966656</td>\n",
       "      <td>0.970858</td>\n",
       "      <td>0.976755</td>\n",
       "      <td>0.982841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992400</td>\n",
       "      <td>0.988703</td>\n",
       "      <td>0.989962</td>\n",
       "      <td>0.984745</td>\n",
       "      <td>0.971893</td>\n",
       "      <td>0.918727</td>\n",
       "      <td>0.923137</td>\n",
       "      <td>0.558477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <td>0.965873</td>\n",
       "      <td>0.913936</td>\n",
       "      <td>0.913018</td>\n",
       "      <td>0.965897</td>\n",
       "      <td>0.969933</td>\n",
       "      <td>0.976540</td>\n",
       "      <td>0.982033</td>\n",
       "      <td>0.992400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989978</td>\n",
       "      <td>0.990876</td>\n",
       "      <td>0.985921</td>\n",
       "      <td>0.971846</td>\n",
       "      <td>0.917196</td>\n",
       "      <td>0.921322</td>\n",
       "      <td>0.557072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb14_preds</th>\n",
       "      <td>0.961540</td>\n",
       "      <td>0.912870</td>\n",
       "      <td>0.911656</td>\n",
       "      <td>0.961575</td>\n",
       "      <td>0.966325</td>\n",
       "      <td>0.972392</td>\n",
       "      <td>0.977396</td>\n",
       "      <td>0.988703</td>\n",
       "      <td>0.989978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994906</td>\n",
       "      <td>0.990040</td>\n",
       "      <td>0.967560</td>\n",
       "      <td>0.916160</td>\n",
       "      <td>0.920547</td>\n",
       "      <td>0.553930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb17_preds</th>\n",
       "      <td>0.963754</td>\n",
       "      <td>0.915690</td>\n",
       "      <td>0.915252</td>\n",
       "      <td>0.963672</td>\n",
       "      <td>0.968201</td>\n",
       "      <td>0.972977</td>\n",
       "      <td>0.978691</td>\n",
       "      <td>0.989962</td>\n",
       "      <td>0.990876</td>\n",
       "      <td>0.994906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990674</td>\n",
       "      <td>0.968335</td>\n",
       "      <td>0.918859</td>\n",
       "      <td>0.923748</td>\n",
       "      <td>0.558075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb19A_preds</th>\n",
       "      <td>0.957731</td>\n",
       "      <td>0.910086</td>\n",
       "      <td>0.908837</td>\n",
       "      <td>0.957796</td>\n",
       "      <td>0.962391</td>\n",
       "      <td>0.968260</td>\n",
       "      <td>0.973449</td>\n",
       "      <td>0.984745</td>\n",
       "      <td>0.985921</td>\n",
       "      <td>0.990040</td>\n",
       "      <td>0.990674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963496</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.917690</td>\n",
       "      <td>0.552865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb02A_preds</th>\n",
       "      <td>0.983143</td>\n",
       "      <td>0.911443</td>\n",
       "      <td>0.913600</td>\n",
       "      <td>0.986851</td>\n",
       "      <td>0.987434</td>\n",
       "      <td>0.988708</td>\n",
       "      <td>0.985858</td>\n",
       "      <td>0.971893</td>\n",
       "      <td>0.971846</td>\n",
       "      <td>0.967560</td>\n",
       "      <td>0.968335</td>\n",
       "      <td>0.963496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914911</td>\n",
       "      <td>0.917453</td>\n",
       "      <td>0.564071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn27_preds</th>\n",
       "      <td>0.916804</td>\n",
       "      <td>0.985360</td>\n",
       "      <td>0.925010</td>\n",
       "      <td>0.914204</td>\n",
       "      <td>0.916726</td>\n",
       "      <td>0.912375</td>\n",
       "      <td>0.916436</td>\n",
       "      <td>0.918727</td>\n",
       "      <td>0.917196</td>\n",
       "      <td>0.916160</td>\n",
       "      <td>0.918859</td>\n",
       "      <td>0.913268</td>\n",
       "      <td>0.914911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979744</td>\n",
       "      <td>0.558103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn12_preds</th>\n",
       "      <td>0.920576</td>\n",
       "      <td>0.978274</td>\n",
       "      <td>0.929518</td>\n",
       "      <td>0.916939</td>\n",
       "      <td>0.920105</td>\n",
       "      <td>0.915090</td>\n",
       "      <td>0.920034</td>\n",
       "      <td>0.923137</td>\n",
       "      <td>0.921322</td>\n",
       "      <td>0.920547</td>\n",
       "      <td>0.923748</td>\n",
       "      <td>0.917690</td>\n",
       "      <td>0.917453</td>\n",
       "      <td>0.979744</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.564928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rdgv19_preds</th>\n",
       "      <td>0.568406</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.577280</td>\n",
       "      <td>0.570034</td>\n",
       "      <td>0.567698</td>\n",
       "      <td>0.560909</td>\n",
       "      <td>0.562639</td>\n",
       "      <td>0.558477</td>\n",
       "      <td>0.557072</td>\n",
       "      <td>0.553930</td>\n",
       "      <td>0.558075</td>\n",
       "      <td>0.552865</td>\n",
       "      <td>0.564071</td>\n",
       "      <td>0.558103</td>\n",
       "      <td>0.564928</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lgb27_preds  rnn_preds  mlp_preds  lgb31_preds  lgb02_preds  \\\n",
       "lgb27_preds      1.000000   0.915952   0.919171     0.990750     0.988682   \n",
       "rnn_preds        0.915952   1.000000   0.929710     0.910602     0.913307   \n",
       "mlp_preds        0.919171   0.929710   1.000000     0.914307     0.916343   \n",
       "lgb31_preds      0.990750   0.910602   0.914307     1.000000     0.991984   \n",
       "lgb02_preds      0.988682   0.913307   0.916343     0.991984     1.000000   \n",
       "lgb09_preds      0.978331   0.908867   0.909521     0.981891     0.982596   \n",
       "lgb10_preds      0.978298   0.913286   0.913883     0.981375     0.982052   \n",
       "lgb11A_preds     0.966819   0.915655   0.915367     0.966656     0.970858   \n",
       "lgb11D_preds     0.965873   0.913936   0.913018     0.965897     0.969933   \n",
       "lgb14_preds      0.961540   0.912870   0.911656     0.961575     0.966325   \n",
       "lgb17_preds      0.963754   0.915690   0.915252     0.963672     0.968201   \n",
       "lgb19A_preds     0.957731   0.910086   0.908837     0.957796     0.962391   \n",
       "lgb02A_preds     0.983143   0.911443   0.913600     0.986851     0.987434   \n",
       "rnn27_preds      0.916804   0.985360   0.925010     0.914204     0.916726   \n",
       "rnn12_preds      0.920576   0.978274   0.929518     0.916939     0.920105   \n",
       "rdgv19_preds     0.568406   0.551100   0.577280     0.570034     0.567698   \n",
       "\n",
       "              lgb09_preds  lgb10_preds  lgb11A_preds  lgb11D_preds  \\\n",
       "lgb27_preds      0.978331     0.978298      0.966819      0.965873   \n",
       "rnn_preds        0.908867     0.913286      0.915655      0.913936   \n",
       "mlp_preds        0.909521     0.913883      0.915367      0.913018   \n",
       "lgb31_preds      0.981891     0.981375      0.966656      0.965897   \n",
       "lgb02_preds      0.982596     0.982052      0.970858      0.969933   \n",
       "lgb09_preds      1.000000     0.990447      0.976755      0.976540   \n",
       "lgb10_preds      0.990447     1.000000      0.982841      0.982033   \n",
       "lgb11A_preds     0.976755     0.982841      1.000000      0.992400   \n",
       "lgb11D_preds     0.976540     0.982033      0.992400      1.000000   \n",
       "lgb14_preds      0.972392     0.977396      0.988703      0.989978   \n",
       "lgb17_preds      0.972977     0.978691      0.989962      0.990876   \n",
       "lgb19A_preds     0.968260     0.973449      0.984745      0.985921   \n",
       "lgb02A_preds     0.988708     0.985858      0.971893      0.971846   \n",
       "rnn27_preds      0.912375     0.916436      0.918727      0.917196   \n",
       "rnn12_preds      0.915090     0.920034      0.923137      0.921322   \n",
       "rdgv19_preds     0.560909     0.562639      0.558477      0.557072   \n",
       "\n",
       "              lgb14_preds  lgb17_preds  lgb19A_preds  lgb02A_preds  \\\n",
       "lgb27_preds      0.961540     0.963754      0.957731      0.983143   \n",
       "rnn_preds        0.912870     0.915690      0.910086      0.911443   \n",
       "mlp_preds        0.911656     0.915252      0.908837      0.913600   \n",
       "lgb31_preds      0.961575     0.963672      0.957796      0.986851   \n",
       "lgb02_preds      0.966325     0.968201      0.962391      0.987434   \n",
       "lgb09_preds      0.972392     0.972977      0.968260      0.988708   \n",
       "lgb10_preds      0.977396     0.978691      0.973449      0.985858   \n",
       "lgb11A_preds     0.988703     0.989962      0.984745      0.971893   \n",
       "lgb11D_preds     0.989978     0.990876      0.985921      0.971846   \n",
       "lgb14_preds      1.000000     0.994906      0.990040      0.967560   \n",
       "lgb17_preds      0.994906     1.000000      0.990674      0.968335   \n",
       "lgb19A_preds     0.990040     0.990674      1.000000      0.963496   \n",
       "lgb02A_preds     0.967560     0.968335      0.963496      1.000000   \n",
       "rnn27_preds      0.916160     0.918859      0.913268      0.914911   \n",
       "rnn12_preds      0.920547     0.923748      0.917690      0.917453   \n",
       "rdgv19_preds     0.553930     0.558075      0.552865      0.564071   \n",
       "\n",
       "              rnn27_preds  rnn12_preds  rdgv19_preds  \n",
       "lgb27_preds      0.916804     0.920576      0.568406  \n",
       "rnn_preds        0.985360     0.978274      0.551100  \n",
       "mlp_preds        0.925010     0.929518      0.577280  \n",
       "lgb31_preds      0.914204     0.916939      0.570034  \n",
       "lgb02_preds      0.916726     0.920105      0.567698  \n",
       "lgb09_preds      0.912375     0.915090      0.560909  \n",
       "lgb10_preds      0.916436     0.920034      0.562639  \n",
       "lgb11A_preds     0.918727     0.923137      0.558477  \n",
       "lgb11D_preds     0.917196     0.921322      0.557072  \n",
       "lgb14_preds      0.916160     0.920547      0.553930  \n",
       "lgb17_preds      0.918859     0.923748      0.558075  \n",
       "lgb19A_preds     0.913268     0.917690      0.552865  \n",
       "lgb02A_preds     0.914911     0.917453      0.564071  \n",
       "rnn27_preds      1.000000     0.979744      0.558103  \n",
       "rnn12_preds      0.979744     1.000000      0.564928  \n",
       "rdgv19_preds     0.558103     0.564928      1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test correlation\n",
    "preds_df[~preds_df['deal_probability'].isnull()][[c for c in preds_df.columns if ('_preds' in c) \\\n",
    "                                                  and ('difference' not in c) and ('sum' not in c) ]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb27_preds</th>\n",
       "      <th>rnn_preds</th>\n",
       "      <th>mlp_preds</th>\n",
       "      <th>lgb31_preds</th>\n",
       "      <th>lgb02_preds</th>\n",
       "      <th>lgb09_preds</th>\n",
       "      <th>lgb10_preds</th>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <th>lgb14_preds</th>\n",
       "      <th>lgb17_preds</th>\n",
       "      <th>lgb19A_preds</th>\n",
       "      <th>lgb02A_preds</th>\n",
       "      <th>rnn27_preds</th>\n",
       "      <th>rnn12_preds</th>\n",
       "      <th>rdgv19_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lgb27_preds</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930288</td>\n",
       "      <td>0.924283</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.989502</td>\n",
       "      <td>0.979729</td>\n",
       "      <td>0.979341</td>\n",
       "      <td>0.975840</td>\n",
       "      <td>0.973725</td>\n",
       "      <td>0.970062</td>\n",
       "      <td>0.972503</td>\n",
       "      <td>0.967059</td>\n",
       "      <td>0.984742</td>\n",
       "      <td>0.930692</td>\n",
       "      <td>0.932951</td>\n",
       "      <td>0.571110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn_preds</th>\n",
       "      <td>0.930288</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.939951</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.927867</td>\n",
       "      <td>0.926158</td>\n",
       "      <td>0.928367</td>\n",
       "      <td>0.927119</td>\n",
       "      <td>0.925632</td>\n",
       "      <td>0.924680</td>\n",
       "      <td>0.926976</td>\n",
       "      <td>0.922491</td>\n",
       "      <td>0.928496</td>\n",
       "      <td>0.988198</td>\n",
       "      <td>0.984113</td>\n",
       "      <td>0.559376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_preds</th>\n",
       "      <td>0.924283</td>\n",
       "      <td>0.939951</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922413</td>\n",
       "      <td>0.921927</td>\n",
       "      <td>0.918064</td>\n",
       "      <td>0.920496</td>\n",
       "      <td>0.919275</td>\n",
       "      <td>0.917496</td>\n",
       "      <td>0.916323</td>\n",
       "      <td>0.919199</td>\n",
       "      <td>0.914513</td>\n",
       "      <td>0.922121</td>\n",
       "      <td>0.935069</td>\n",
       "      <td>0.936609</td>\n",
       "      <td>0.561935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb31_preds</th>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.922413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993168</td>\n",
       "      <td>0.982874</td>\n",
       "      <td>0.982519</td>\n",
       "      <td>0.978877</td>\n",
       "      <td>0.976777</td>\n",
       "      <td>0.973170</td>\n",
       "      <td>0.975607</td>\n",
       "      <td>0.970094</td>\n",
       "      <td>0.988043</td>\n",
       "      <td>0.931468</td>\n",
       "      <td>0.932981</td>\n",
       "      <td>0.572757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb02_preds</th>\n",
       "      <td>0.989502</td>\n",
       "      <td>0.927867</td>\n",
       "      <td>0.921927</td>\n",
       "      <td>0.993168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984427</td>\n",
       "      <td>0.983525</td>\n",
       "      <td>0.980105</td>\n",
       "      <td>0.978173</td>\n",
       "      <td>0.975031</td>\n",
       "      <td>0.977087</td>\n",
       "      <td>0.971908</td>\n",
       "      <td>0.989577</td>\n",
       "      <td>0.931447</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.570342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb09_preds</th>\n",
       "      <td>0.979729</td>\n",
       "      <td>0.926158</td>\n",
       "      <td>0.918064</td>\n",
       "      <td>0.982874</td>\n",
       "      <td>0.984427</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991413</td>\n",
       "      <td>0.988267</td>\n",
       "      <td>0.986666</td>\n",
       "      <td>0.983504</td>\n",
       "      <td>0.984455</td>\n",
       "      <td>0.980115</td>\n",
       "      <td>0.989106</td>\n",
       "      <td>0.929748</td>\n",
       "      <td>0.931167</td>\n",
       "      <td>0.565333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb10_preds</th>\n",
       "      <td>0.979341</td>\n",
       "      <td>0.928367</td>\n",
       "      <td>0.920496</td>\n",
       "      <td>0.982519</td>\n",
       "      <td>0.983525</td>\n",
       "      <td>0.991413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>0.990473</td>\n",
       "      <td>0.986869</td>\n",
       "      <td>0.988382</td>\n",
       "      <td>0.983483</td>\n",
       "      <td>0.986654</td>\n",
       "      <td>0.931841</td>\n",
       "      <td>0.933902</td>\n",
       "      <td>0.566736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <td>0.975840</td>\n",
       "      <td>0.927119</td>\n",
       "      <td>0.919275</td>\n",
       "      <td>0.978877</td>\n",
       "      <td>0.980105</td>\n",
       "      <td>0.988267</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993474</td>\n",
       "      <td>0.990047</td>\n",
       "      <td>0.991264</td>\n",
       "      <td>0.986600</td>\n",
       "      <td>0.983556</td>\n",
       "      <td>0.930518</td>\n",
       "      <td>0.932743</td>\n",
       "      <td>0.563841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <td>0.973725</td>\n",
       "      <td>0.925632</td>\n",
       "      <td>0.917496</td>\n",
       "      <td>0.976777</td>\n",
       "      <td>0.978173</td>\n",
       "      <td>0.986666</td>\n",
       "      <td>0.990473</td>\n",
       "      <td>0.993474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991525</td>\n",
       "      <td>0.992446</td>\n",
       "      <td>0.988002</td>\n",
       "      <td>0.981933</td>\n",
       "      <td>0.929068</td>\n",
       "      <td>0.931133</td>\n",
       "      <td>0.561824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb14_preds</th>\n",
       "      <td>0.970062</td>\n",
       "      <td>0.924680</td>\n",
       "      <td>0.916323</td>\n",
       "      <td>0.973170</td>\n",
       "      <td>0.975031</td>\n",
       "      <td>0.983504</td>\n",
       "      <td>0.986869</td>\n",
       "      <td>0.990047</td>\n",
       "      <td>0.991525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995582</td>\n",
       "      <td>0.991390</td>\n",
       "      <td>0.978724</td>\n",
       "      <td>0.928224</td>\n",
       "      <td>0.930421</td>\n",
       "      <td>0.558673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb17_preds</th>\n",
       "      <td>0.972503</td>\n",
       "      <td>0.926976</td>\n",
       "      <td>0.919199</td>\n",
       "      <td>0.975607</td>\n",
       "      <td>0.977087</td>\n",
       "      <td>0.984455</td>\n",
       "      <td>0.988382</td>\n",
       "      <td>0.991264</td>\n",
       "      <td>0.992446</td>\n",
       "      <td>0.995582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991955</td>\n",
       "      <td>0.979791</td>\n",
       "      <td>0.930381</td>\n",
       "      <td>0.932982</td>\n",
       "      <td>0.561605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb19A_preds</th>\n",
       "      <td>0.967059</td>\n",
       "      <td>0.922491</td>\n",
       "      <td>0.914513</td>\n",
       "      <td>0.970094</td>\n",
       "      <td>0.971908</td>\n",
       "      <td>0.980115</td>\n",
       "      <td>0.983483</td>\n",
       "      <td>0.986600</td>\n",
       "      <td>0.988002</td>\n",
       "      <td>0.991390</td>\n",
       "      <td>0.991955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.975407</td>\n",
       "      <td>0.925964</td>\n",
       "      <td>0.928202</td>\n",
       "      <td>0.557790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb02A_preds</th>\n",
       "      <td>0.984742</td>\n",
       "      <td>0.928496</td>\n",
       "      <td>0.922121</td>\n",
       "      <td>0.988043</td>\n",
       "      <td>0.989577</td>\n",
       "      <td>0.989106</td>\n",
       "      <td>0.986654</td>\n",
       "      <td>0.983556</td>\n",
       "      <td>0.981933</td>\n",
       "      <td>0.978724</td>\n",
       "      <td>0.979791</td>\n",
       "      <td>0.975407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.932071</td>\n",
       "      <td>0.933267</td>\n",
       "      <td>0.567816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn27_preds</th>\n",
       "      <td>0.930692</td>\n",
       "      <td>0.988198</td>\n",
       "      <td>0.935069</td>\n",
       "      <td>0.931468</td>\n",
       "      <td>0.931447</td>\n",
       "      <td>0.929748</td>\n",
       "      <td>0.931841</td>\n",
       "      <td>0.930518</td>\n",
       "      <td>0.929068</td>\n",
       "      <td>0.928224</td>\n",
       "      <td>0.930381</td>\n",
       "      <td>0.925964</td>\n",
       "      <td>0.932071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987051</td>\n",
       "      <td>0.562929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn12_preds</th>\n",
       "      <td>0.932951</td>\n",
       "      <td>0.984113</td>\n",
       "      <td>0.936609</td>\n",
       "      <td>0.932981</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.931167</td>\n",
       "      <td>0.933902</td>\n",
       "      <td>0.932743</td>\n",
       "      <td>0.931133</td>\n",
       "      <td>0.930421</td>\n",
       "      <td>0.932982</td>\n",
       "      <td>0.928202</td>\n",
       "      <td>0.933267</td>\n",
       "      <td>0.987051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.568866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rdgv19_preds</th>\n",
       "      <td>0.571110</td>\n",
       "      <td>0.559376</td>\n",
       "      <td>0.561935</td>\n",
       "      <td>0.572757</td>\n",
       "      <td>0.570342</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>0.566736</td>\n",
       "      <td>0.563841</td>\n",
       "      <td>0.561824</td>\n",
       "      <td>0.558673</td>\n",
       "      <td>0.561605</td>\n",
       "      <td>0.557790</td>\n",
       "      <td>0.567816</td>\n",
       "      <td>0.562929</td>\n",
       "      <td>0.568866</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lgb27_preds  rnn_preds  mlp_preds  lgb31_preds  lgb02_preds  \\\n",
       "lgb27_preds      1.000000   0.930288   0.924283     0.991439     0.989502   \n",
       "rnn_preds        0.930288   1.000000   0.939951     0.927835     0.927867   \n",
       "mlp_preds        0.924283   0.939951   1.000000     0.922413     0.921927   \n",
       "lgb31_preds      0.991439   0.927835   0.922413     1.000000     0.993168   \n",
       "lgb02_preds      0.989502   0.927867   0.921927     0.993168     1.000000   \n",
       "lgb09_preds      0.979729   0.926158   0.918064     0.982874     0.984427   \n",
       "lgb10_preds      0.979341   0.928367   0.920496     0.982519     0.983525   \n",
       "lgb11A_preds     0.975840   0.927119   0.919275     0.978877     0.980105   \n",
       "lgb11D_preds     0.973725   0.925632   0.917496     0.976777     0.978173   \n",
       "lgb14_preds      0.970062   0.924680   0.916323     0.973170     0.975031   \n",
       "lgb17_preds      0.972503   0.926976   0.919199     0.975607     0.977087   \n",
       "lgb19A_preds     0.967059   0.922491   0.914513     0.970094     0.971908   \n",
       "lgb02A_preds     0.984742   0.928496   0.922121     0.988043     0.989577   \n",
       "rnn27_preds      0.930692   0.988198   0.935069     0.931468     0.931447   \n",
       "rnn12_preds      0.932951   0.984113   0.936609     0.932981     0.933333   \n",
       "rdgv19_preds     0.571110   0.559376   0.561935     0.572757     0.570342   \n",
       "\n",
       "              lgb09_preds  lgb10_preds  lgb11A_preds  lgb11D_preds  \\\n",
       "lgb27_preds      0.979729     0.979341      0.975840      0.973725   \n",
       "rnn_preds        0.926158     0.928367      0.927119      0.925632   \n",
       "mlp_preds        0.918064     0.920496      0.919275      0.917496   \n",
       "lgb31_preds      0.982874     0.982519      0.978877      0.976777   \n",
       "lgb02_preds      0.984427     0.983525      0.980105      0.978173   \n",
       "lgb09_preds      1.000000     0.991413      0.988267      0.986666   \n",
       "lgb10_preds      0.991413     1.000000      0.992340      0.990473   \n",
       "lgb11A_preds     0.988267     0.992340      1.000000      0.993474   \n",
       "lgb11D_preds     0.986666     0.990473      0.993474      1.000000   \n",
       "lgb14_preds      0.983504     0.986869      0.990047      0.991525   \n",
       "lgb17_preds      0.984455     0.988382      0.991264      0.992446   \n",
       "lgb19A_preds     0.980115     0.983483      0.986600      0.988002   \n",
       "lgb02A_preds     0.989106     0.986654      0.983556      0.981933   \n",
       "rnn27_preds      0.929748     0.931841      0.930518      0.929068   \n",
       "rnn12_preds      0.931167     0.933902      0.932743      0.931133   \n",
       "rdgv19_preds     0.565333     0.566736      0.563841      0.561824   \n",
       "\n",
       "              lgb14_preds  lgb17_preds  lgb19A_preds  lgb02A_preds  \\\n",
       "lgb27_preds      0.970062     0.972503      0.967059      0.984742   \n",
       "rnn_preds        0.924680     0.926976      0.922491      0.928496   \n",
       "mlp_preds        0.916323     0.919199      0.914513      0.922121   \n",
       "lgb31_preds      0.973170     0.975607      0.970094      0.988043   \n",
       "lgb02_preds      0.975031     0.977087      0.971908      0.989577   \n",
       "lgb09_preds      0.983504     0.984455      0.980115      0.989106   \n",
       "lgb10_preds      0.986869     0.988382      0.983483      0.986654   \n",
       "lgb11A_preds     0.990047     0.991264      0.986600      0.983556   \n",
       "lgb11D_preds     0.991525     0.992446      0.988002      0.981933   \n",
       "lgb14_preds      1.000000     0.995582      0.991390      0.978724   \n",
       "lgb17_preds      0.995582     1.000000      0.991955      0.979791   \n",
       "lgb19A_preds     0.991390     0.991955      1.000000      0.975407   \n",
       "lgb02A_preds     0.978724     0.979791      0.975407      1.000000   \n",
       "rnn27_preds      0.928224     0.930381      0.925964      0.932071   \n",
       "rnn12_preds      0.930421     0.932982      0.928202      0.933267   \n",
       "rdgv19_preds     0.558673     0.561605      0.557790      0.567816   \n",
       "\n",
       "              rnn27_preds  rnn12_preds  rdgv19_preds  \n",
       "lgb27_preds      0.930692     0.932951      0.571110  \n",
       "rnn_preds        0.988198     0.984113      0.559376  \n",
       "mlp_preds        0.935069     0.936609      0.561935  \n",
       "lgb31_preds      0.931468     0.932981      0.572757  \n",
       "lgb02_preds      0.931447     0.933333      0.570342  \n",
       "lgb09_preds      0.929748     0.931167      0.565333  \n",
       "lgb10_preds      0.931841     0.933902      0.566736  \n",
       "lgb11A_preds     0.930518     0.932743      0.563841  \n",
       "lgb11D_preds     0.929068     0.931133      0.561824  \n",
       "lgb14_preds      0.928224     0.930421      0.558673  \n",
       "lgb17_preds      0.930381     0.932982      0.561605  \n",
       "lgb19A_preds     0.925964     0.928202      0.557790  \n",
       "lgb02A_preds     0.932071     0.933267      0.567816  \n",
       "rnn27_preds      1.000000     0.987051      0.562929  \n",
       "rnn12_preds      0.987051     1.000000      0.568866  \n",
       "rdgv19_preds     0.562929     0.568866      1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train correlation\n",
    "preds_df[preds_df['deal_probability'].isnull()][[c for c in preds_df.columns if ('_preds' in c)  \\\n",
    "                                                  and ('difference' not in c) and ('sum' not in c) ]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [c for c in preds_df.columns if '_preds' in c]\n",
    "cols += [c for c in preds_df.columns if 'difference' in c]\n",
    "cols += ['price', 'max', 'min', 'avg', 'std', 'med', 'item_seq_number']\n",
    "categories = ['region', 'param_1_big', 'parent_category_name', 'category_name', \\\n",
    "              'param_2_big', 'param_3_big', 'city_big', 'user_type', 'image_top_1_big']#,\n",
    "cols += categories\n",
    "cols = list(set(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categories:\n",
    "    preds_df[col] = LabelEncoder().fit_transform(preds_df[col].fillna(\"0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = preds_df[~preds_df['deal_probability'].isnull()]\n",
    "test_df = preds_df[preds_df['deal_probability'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 4000\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(train_df[cols], y, train_size=.8, random_state=12345)\n",
    "eval_set = [(train_X,train_y),(valid_X,valid_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1202739"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds.\n",
      "[100]\ttraining's rmse: 0.21913\tvalid_1's rmse: 0.219519\n",
      "[200]\ttraining's rmse: 0.212703\tvalid_1's rmse: 0.213329\n",
      "[300]\ttraining's rmse: 0.211577\tvalid_1's rmse: 0.212398\n",
      "[400]\ttraining's rmse: 0.21122\tvalid_1's rmse: 0.21222\n",
      "[500]\ttraining's rmse: 0.210991\tvalid_1's rmse: 0.212155\n",
      "[600]\ttraining's rmse: 0.210797\tvalid_1's rmse: 0.212119\n",
      "[700]\ttraining's rmse: 0.210629\tvalid_1's rmse: 0.212101\n",
      "[800]\ttraining's rmse: 0.210476\tvalid_1's rmse: 0.212088\n",
      "[900]\ttraining's rmse: 0.210329\tvalid_1's rmse: 0.212082\n",
      "[1000]\ttraining's rmse: 0.21019\tvalid_1's rmse: 0.212073\n",
      "[1100]\ttraining's rmse: 0.210052\tvalid_1's rmse: 0.212066\n",
      "[1200]\ttraining's rmse: 0.209913\tvalid_1's rmse: 0.21206\n",
      "[1300]\ttraining's rmse: 0.209782\tvalid_1's rmse: 0.212054\n",
      "[1400]\ttraining's rmse: 0.209651\tvalid_1's rmse: 0.21205\n",
      "[1500]\ttraining's rmse: 0.209522\tvalid_1's rmse: 0.212046\n",
      "[1600]\ttraining's rmse: 0.209395\tvalid_1's rmse: 0.212045\n",
      "[1700]\ttraining's rmse: 0.209271\tvalid_1's rmse: 0.212041\n",
      "[1800]\ttraining's rmse: 0.209147\tvalid_1's rmse: 0.212037\n",
      "[1900]\ttraining's rmse: 0.209025\tvalid_1's rmse: 0.212034\n",
      "[2000]\ttraining's rmse: 0.208902\tvalid_1's rmse: 0.212032\n",
      "[2100]\ttraining's rmse: 0.20878\tvalid_1's rmse: 0.212028\n",
      "Early stopping, best iteration is:\n",
      "[2107]\ttraining's rmse: 0.208771\tvalid_1's rmse: 0.212027\n",
      "CPU times: user 45min 27s, sys: 11.9 s, total: 45min 39s\n",
      "Wall time: 5min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gc.collect()\n",
    "clf = LGBMRegressor(n_estimators=n_estimators, \n",
    "                    max_depth=-1, \n",
    "                    feature_fraction= 0.4,\n",
    "                    num_leaves=32, \n",
    "                    learning_rate=.01)#, device='gpu')\n",
    "clf.fit(train_X, train_y, early_stopping_rounds=80, \n",
    "        eval_set=eval_set, eval_metric='rmse', verbose=100, \n",
    "        categorical_feature=categories)\n",
    "# [2796]\ttraining's rmse: 0.208275\tvalid_1's rmse: 0.212167\n",
    "# [2500]\ttraining's rmse: 0.208429\tvalid_1's rmse: 0.212098\n",
    "# [2107]\ttraining's rmse: 0.208771\tvalid_1's rmse: 0.212027"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4355, 'city_big'),\n",
       " (3648, 'param_1_big'),\n",
       " (2672, 'category_name'),\n",
       " (2254, 'region'),\n",
       " (1635, 'image_top_1_big'),\n",
       " (1090, 'difference_rnn_preds__rnn27_preds'),\n",
       " (1067, 'rdgv19_preds'),\n",
       " (867, 'difference_rnn_preds__rnn12_preds'),\n",
       " (845, 'param_3_big'),\n",
       " (704, 'item_seq_number'),\n",
       " (664, 'difference_lgb11D_preds__lgb14_preds'),\n",
       " (640, 'difference_lgb11D_preds__lgb17_preds'),\n",
       " (607, 'difference_rnn27_preds__rnn12_preds'),\n",
       " (602, 'price'),\n",
       " (590, 'param_2_big'),\n",
       " (558, 'difference_lgb14_preds__lgb19A_preds'),\n",
       " (557, 'difference_lgb10_preds__lgb17_preds'),\n",
       " (552, 'difference_lgb31_preds__lgb19A_preds'),\n",
       " (547, 'difference_lgb31_preds__lgb17_preds'),\n",
       " (546, 'difference_lgb09_preds__lgb10_preds'),\n",
       " (538, 'difference_mlp_preds__rnn27_preds'),\n",
       " (535, 'difference_lgb14_preds__lgb17_preds'),\n",
       " (533, 'difference_mlp_preds__rnn12_preds'),\n",
       " (530, 'difference_lgb09_preds__lgb02A_preds'),\n",
       " (529, 'difference_lgb17_preds__lgb19A_preds'),\n",
       " (525, 'sums_mlp_preds__lgb17_preds'),\n",
       " (518, 'difference_lgb31_preds__lgb09_preds'),\n",
       " (513, 'min'),\n",
       " (511, 'lgb17_preds'),\n",
       " (508, 'difference_lgb31_preds__lgb02A_preds'),\n",
       " (508, 'difference_mlp_preds__lgb31_preds'),\n",
       " (506, 'sums_lgb19A_preds__rnn27_preds'),\n",
       " (504, 'difference_lgb17_preds__lgb02A_preds'),\n",
       " (501, 'sums_lgb17_preds__rnn27_preds'),\n",
       " (495, 'difference_lgb11D_preds__lgb19A_preds'),\n",
       " (493, 'sums_lgb19A_preds__rnn12_preds'),\n",
       " (485, 'sums_lgb17_preds__lgb19A_preds'),\n",
       " (478, 'difference_lgb31_preds__lgb14_preds'),\n",
       " (476, 'difference_lgb10_preds__lgb02A_preds'),\n",
       " (465, 'difference_lgb19A_preds__lgb02A_preds'),\n",
       " (460, 'mlp_preds'),\n",
       " (458, 'difference_lgb09_preds__lgb11D_preds'),\n",
       " (451, 'difference_rnn_preds__mlp_preds'),\n",
       " (442, 'sums_mlp_preds__lgb19A_preds'),\n",
       " (440, 'difference_lgb31_preds__lgb10_preds'),\n",
       " (438, 'difference_lgb09_preds__lgb19A_preds'),\n",
       " (437, 'difference_lgb10_preds__lgb14_preds'),\n",
       " (435, 'sums_lgb17_preds__rnn12_preds'),\n",
       " (424, 'sums_lgb14_preds__lgb19A_preds'),\n",
       " (422, 'difference_lgb11D_preds__lgb02A_preds'),\n",
       " (420, 'difference_lgb31_preds__lgb11D_preds'),\n",
       " (419, 'difference_lgb09_preds__lgb14_preds'),\n",
       " (417, 'difference_lgb10_preds__lgb19A_preds'),\n",
       " (411, 'difference_lgb10_preds__lgb11D_preds'),\n",
       " (402, 'difference_lgb31_preds__rnn12_preds'),\n",
       " (391, 'difference_lgb31_preds__rnn27_preds'),\n",
       " (389, 'difference_rnn_preds__lgb19A_preds'),\n",
       " (389, 'sums_lgb14_preds__rnn27_preds'),\n",
       " (389, 'difference_mlp_preds__lgb11D_preds'),\n",
       " (386, 'difference_mlp_preds__lgb10_preds'),\n",
       " (378, 'difference_lgb19A_preds__rnn12_preds'),\n",
       " (377, 'difference_mlp_preds__lgb02A_preds'),\n",
       " (375, 'difference_lgb14_preds__lgb02A_preds'),\n",
       " (371, 'difference_mlp_preds__lgb14_preds'),\n",
       " (369, 'difference_lgb02A_preds__rnn12_preds'),\n",
       " (356, 'sums_mlp_preds__lgb14_preds'),\n",
       " (356, 'difference_rnn_preds__lgb31_preds'),\n",
       " (353, 'difference_lgb09_preds__lgb17_preds'),\n",
       " (344, 'sums_mlp_preds__rnn12_preds'),\n",
       " (341, 'sums_lgb14_preds__lgb17_preds'),\n",
       " (340, 'rnn12_preds'),\n",
       " (338, 'difference_mlp_preds__lgb09_preds'),\n",
       " (329, 'rnn27_preds'),\n",
       " (325, 'lgb19A_preds'),\n",
       " (323, 'difference_mlp_preds__lgb19A_preds'),\n",
       " (323, 'difference_mlp_preds__lgb17_preds'),\n",
       " (321, 'difference_lgb11D_preds__rnn27_preds'),\n",
       " (314, 'difference_rnn_preds__lgb11D_preds'),\n",
       " (314, 'difference_lgb02A_preds__rnn27_preds'),\n",
       " (310, 'difference_lgb19A_preds__rnn27_preds'),\n",
       " (309, 'sums_mlp_preds__rnn27_preds'),\n",
       " (308, 'difference_lgb17_preds__rnn12_preds'),\n",
       " (300, 'difference_lgb10_preds__rnn12_preds'),\n",
       " (299, 'difference_lgb10_preds__rnn27_preds'),\n",
       " (298, 'difference_lgb09_preds__rnn12_preds'),\n",
       " (296, 'difference_lgb14_preds__rnn27_preds'),\n",
       " (295, 'difference_rnn_preds__lgb02A_preds'),\n",
       " (294, 'sums_lgb14_preds__rnn12_preds'),\n",
       " (293, 'difference_rnn_preds__lgb14_preds'),\n",
       " (291, 'difference_lgb17_preds__rnn27_preds'),\n",
       " (290, 'difference_rnn_preds__lgb17_preds'),\n",
       " (287, 'std'),\n",
       " (287, 'lgb14_preds'),\n",
       " (286, 'difference_lgb09_preds__rnn27_preds'),\n",
       " (272, 'difference_lgb14_preds__rnn12_preds'),\n",
       " (269, 'difference_rnn_preds__lgb10_preds'),\n",
       " (267, 'lgb27_preds'),\n",
       " (263, 'difference_rnn_preds__lgb09_preds'),\n",
       " (257, 'difference_lgb11D_preds__rnn12_preds'),\n",
       " (243, 'lgb11A_preds'),\n",
       " (243, 'rnn_preds'),\n",
       " (240, 'sums_rnn_preds__mlp_preds'),\n",
       " (238, 'parent_category_name'),\n",
       " (232, 'sums_rnn27_preds__rnn12_preds'),\n",
       " (223, 'lgb02_preds'),\n",
       " (212, 'sums_mlp_preds__lgb02A_preds'),\n",
       " (202, 'sums_rnn_preds__rnn27_preds'),\n",
       " (201, 'sums_mlp_preds__lgb09_preds'),\n",
       " (201, 'lgb31_preds'),\n",
       " (195, 'max'),\n",
       " (183, 'sums_mlp_preds__lgb11D_preds'),\n",
       " (173, 'sums_lgb11D_preds__rnn12_preds'),\n",
       " (170, 'sums_mlp_preds__lgb31_preds'),\n",
       " (168, 'sums_mlp_preds__lgb10_preds'),\n",
       " (166, 'sums_rnn_preds__rnn12_preds'),\n",
       " (162, 'sums_lgb02A_preds__rnn27_preds'),\n",
       " (159, 'sums_lgb31_preds__lgb02A_preds'),\n",
       " (158, 'lgb02A_preds'),\n",
       " (157, 'lgb09_preds'),\n",
       " (155, 'sums_lgb09_preds__rnn27_preds'),\n",
       " (154, 'sums_lgb31_preds__rnn27_preds'),\n",
       " (151, 'lgb11D_preds'),\n",
       " (149, 'sums_lgb10_preds__rnn27_preds'),\n",
       " (148, 'sums_rnn_preds__lgb19A_preds'),\n",
       " (147, 'sums_lgb09_preds__rnn12_preds'),\n",
       " (146, 'sums_lgb11D_preds__lgb17_preds'),\n",
       " (145, 'lgb10_preds'),\n",
       " (144, 'sums_rnn_preds__lgb09_preds'),\n",
       " (139, 'sums_lgb09_preds__lgb17_preds'),\n",
       " (138, 'sums_rnn_preds__lgb31_preds'),\n",
       " (138, 'sums_lgb31_preds__lgb19A_preds'),\n",
       " (137, 'sums_rnn_preds__lgb14_preds'),\n",
       " (137, 'sums_lgb31_preds__rnn12_preds'),\n",
       " (135, 'sums_lgb09_preds__lgb10_preds'),\n",
       " (135, 'sums_rnn_preds__lgb02A_preds'),\n",
       " (134, 'sums_lgb02A_preds__rnn12_preds'),\n",
       " (133, 'sums_lgb11D_preds__lgb19A_preds'),\n",
       " (133, 'sums_lgb10_preds__rnn12_preds'),\n",
       " (130, 'sums_rnn_preds__lgb11D_preds'),\n",
       " (130, 'sums_lgb09_preds__lgb02A_preds'),\n",
       " (128, 'sums_lgb09_preds__lgb19A_preds'),\n",
       " (127, 'sums_lgb11D_preds__rnn27_preds'),\n",
       " (123, 'sums_lgb09_preds__lgb14_preds'),\n",
       " (120, 'sums_lgb31_preds__lgb17_preds'),\n",
       " (116, 'sums_lgb31_preds__lgb09_preds'),\n",
       " (115, 'sums_rnn_preds__lgb17_preds'),\n",
       " (113, 'sums_lgb14_preds__lgb02A_preds'),\n",
       " (112, 'sums_lgb10_preds__lgb19A_preds'),\n",
       " (112, 'sums_lgb10_preds__lgb14_preds'),\n",
       " (111, 'sums_lgb10_preds__lgb17_preds'),\n",
       " (111, 'sums_lgb19A_preds__lgb02A_preds'),\n",
       " (110, 'sums_lgb11D_preds__lgb02A_preds'),\n",
       " (108, 'sums_lgb31_preds__lgb10_preds'),\n",
       " (106, 'sums_rnn_preds__lgb10_preds'),\n",
       " (106, 'sums_lgb09_preds__lgb11D_preds'),\n",
       " (105, 'sums_lgb31_preds__lgb14_preds'),\n",
       " (102, 'sums_lgb10_preds__lgb02A_preds'),\n",
       " (99, 'sums_lgb17_preds__lgb02A_preds'),\n",
       " (99, 'sums_lgb11D_preds__lgb14_preds'),\n",
       " (97, 'sums_lgb31_preds__lgb11D_preds'),\n",
       " (93, 'med'),\n",
       " (90, 'sums_lgb10_preds__lgb11D_preds'),\n",
       " (88, 'avg'),\n",
       " (53, 'user_type')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(clf.feature_importances_, train_X.columns ),key=lambda x: -x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1503424"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = 2500\n",
    "train_X = train_df[cols]\n",
    "train_y = y\n",
    "eval_set = [(train_X,train_y)]\n",
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds.\n",
      "[100]\ttraining's rmse: 0.219217\n",
      "[200]\ttraining's rmse: 0.212833\n",
      "[300]\ttraining's rmse: 0.211744\n",
      "[400]\ttraining's rmse: 0.21142\n",
      "[500]\ttraining's rmse: 0.211216\n",
      "[600]\ttraining's rmse: 0.211049\n",
      "[700]\ttraining's rmse: 0.210905\n",
      "[800]\ttraining's rmse: 0.210775\n",
      "[900]\ttraining's rmse: 0.210649\n",
      "[1000]\ttraining's rmse: 0.210527\n",
      "[1100]\ttraining's rmse: 0.210413\n",
      "[1200]\ttraining's rmse: 0.210301\n",
      "[1300]\ttraining's rmse: 0.210193\n",
      "[1400]\ttraining's rmse: 0.210086\n",
      "[1500]\ttraining's rmse: 0.209978\n",
      "[1600]\ttraining's rmse: 0.209869\n",
      "[1700]\ttraining's rmse: 0.209764\n",
      "[1800]\ttraining's rmse: 0.20966\n",
      "[1900]\ttraining's rmse: 0.209557\n",
      "[2000]\ttraining's rmse: 0.209457\n",
      "[2100]\ttraining's rmse: 0.209355\n",
      "[2200]\ttraining's rmse: 0.209251\n",
      "[2300]\ttraining's rmse: 0.209149\n",
      "[2400]\ttraining's rmse: 0.209047\n",
      "[2500]\ttraining's rmse: 0.208947\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\ttraining's rmse: 0.208947\n",
      "Training until validation scores don't improve for 80 rounds.\n",
      "[100]\ttraining's rmse: 0.219218\n",
      "[200]\ttraining's rmse: 0.212829\n",
      "[300]\ttraining's rmse: 0.21174\n",
      "[400]\ttraining's rmse: 0.211412\n",
      "[500]\ttraining's rmse: 0.211212\n",
      "[600]\ttraining's rmse: 0.211047\n",
      "[700]\ttraining's rmse: 0.210901\n",
      "[800]\ttraining's rmse: 0.210768\n",
      "[900]\ttraining's rmse: 0.210641\n",
      "[1000]\ttraining's rmse: 0.21052\n",
      "[1100]\ttraining's rmse: 0.210408\n",
      "[1200]\ttraining's rmse: 0.210294\n",
      "[1300]\ttraining's rmse: 0.210183\n",
      "[1400]\ttraining's rmse: 0.210075\n",
      "[1500]\ttraining's rmse: 0.209968\n",
      "[1600]\ttraining's rmse: 0.209858\n",
      "[1700]\ttraining's rmse: 0.209749\n",
      "[1800]\ttraining's rmse: 0.209644\n",
      "[1900]\ttraining's rmse: 0.209537\n",
      "[2000]\ttraining's rmse: 0.209431\n",
      "[2100]\ttraining's rmse: 0.209327\n",
      "[2200]\ttraining's rmse: 0.209222\n",
      "[2300]\ttraining's rmse: 0.209121\n",
      "[2400]\ttraining's rmse: 0.209019\n",
      "[2500]\ttraining's rmse: 0.20892\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\ttraining's rmse: 0.20892\n",
      "Training until validation scores don't improve for 80 rounds.\n",
      "[100]\ttraining's rmse: 0.219219\n",
      "[200]\ttraining's rmse: 0.212832\n",
      "[300]\ttraining's rmse: 0.211742\n",
      "[400]\ttraining's rmse: 0.211423\n",
      "[500]\ttraining's rmse: 0.211219\n",
      "[600]\ttraining's rmse: 0.211055\n",
      "[700]\ttraining's rmse: 0.210907\n",
      "[800]\ttraining's rmse: 0.210773\n",
      "[900]\ttraining's rmse: 0.210651\n",
      "[1000]\ttraining's rmse: 0.210534\n",
      "[1100]\ttraining's rmse: 0.210416\n",
      "[1200]\ttraining's rmse: 0.210303\n",
      "[1300]\ttraining's rmse: 0.210192\n",
      "[1400]\ttraining's rmse: 0.210084\n",
      "[1500]\ttraining's rmse: 0.209975\n",
      "[1600]\ttraining's rmse: 0.209868\n",
      "[1700]\ttraining's rmse: 0.20976\n",
      "[1800]\ttraining's rmse: 0.209657\n",
      "[1900]\ttraining's rmse: 0.209551\n",
      "[2000]\ttraining's rmse: 0.209447\n",
      "[2100]\ttraining's rmse: 0.209343\n",
      "[2200]\ttraining's rmse: 0.209242\n",
      "[2300]\ttraining's rmse: 0.209138\n",
      "[2400]\ttraining's rmse: 0.209037\n",
      "[2500]\ttraining's rmse: 0.208936\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\ttraining's rmse: 0.208936\n",
      "Training until validation scores don't improve for 80 rounds.\n",
      "[100]\ttraining's rmse: 0.219219\n",
      "[200]\ttraining's rmse: 0.212831\n",
      "[300]\ttraining's rmse: 0.211746\n",
      "[400]\ttraining's rmse: 0.211423\n",
      "[500]\ttraining's rmse: 0.211221\n",
      "[600]\ttraining's rmse: 0.211057\n",
      "[700]\ttraining's rmse: 0.210911\n",
      "[800]\ttraining's rmse: 0.210779\n",
      "[900]\ttraining's rmse: 0.210655\n",
      "[1000]\ttraining's rmse: 0.210534\n",
      "[1100]\ttraining's rmse: 0.210417\n",
      "[1200]\ttraining's rmse: 0.210305\n",
      "[1300]\ttraining's rmse: 0.210191\n",
      "[1400]\ttraining's rmse: 0.210082\n",
      "[1500]\ttraining's rmse: 0.209974\n",
      "[1600]\ttraining's rmse: 0.209866\n",
      "[1700]\ttraining's rmse: 0.209759\n",
      "[1800]\ttraining's rmse: 0.209654\n",
      "[1900]\ttraining's rmse: 0.209551\n",
      "[2000]\ttraining's rmse: 0.209449\n",
      "[2100]\ttraining's rmse: 0.209346\n",
      "[2200]\ttraining's rmse: 0.209246\n",
      "[2300]\ttraining's rmse: 0.209144\n",
      "[2400]\ttraining's rmse: 0.209041\n",
      "[2500]\ttraining's rmse: 0.208939\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\ttraining's rmse: 0.208939\n",
      "Training until validation scores don't improve for 80 rounds.\n",
      "[100]\ttraining's rmse: 0.219212\n",
      "[200]\ttraining's rmse: 0.212828\n",
      "[300]\ttraining's rmse: 0.211737\n",
      "[400]\ttraining's rmse: 0.211415\n",
      "[500]\ttraining's rmse: 0.211217\n",
      "[600]\ttraining's rmse: 0.211053\n",
      "[700]\ttraining's rmse: 0.210906\n",
      "[800]\ttraining's rmse: 0.210771\n",
      "[900]\ttraining's rmse: 0.210646\n",
      "[1000]\ttraining's rmse: 0.210524\n",
      "[1100]\ttraining's rmse: 0.210407\n",
      "[1200]\ttraining's rmse: 0.210295\n",
      "[1300]\ttraining's rmse: 0.210186\n",
      "[1400]\ttraining's rmse: 0.210077\n",
      "[1500]\ttraining's rmse: 0.209968\n",
      "[1600]\ttraining's rmse: 0.20986\n",
      "[1700]\ttraining's rmse: 0.209754\n",
      "[1800]\ttraining's rmse: 0.209648\n",
      "[1900]\ttraining's rmse: 0.209543\n",
      "[2000]\ttraining's rmse: 0.209439\n",
      "[2100]\ttraining's rmse: 0.209334\n",
      "[2200]\ttraining's rmse: 0.209231\n",
      "[2300]\ttraining's rmse: 0.209127\n",
      "[2400]\ttraining's rmse: 0.209023\n",
      "[2500]\ttraining's rmse: 0.20892\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\ttraining's rmse: 0.20892\n",
      "CPU times: user 5h 14min 30s, sys: 1min 3s, total: 5h 15min 34s\n",
      "Wall time: 40min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_predls = []\n",
    "for i in range(5):\n",
    "    clf = LGBMRegressor(n_estimators=n_estimators, \n",
    "                    max_depth=-1, \n",
    "                    feature_fraction= 0.4,\n",
    "                    num_leaves=32, \n",
    "                    seed = i, \n",
    "                    learning_rate=.01)#, device='gpu')\n",
    "    clf.fit(train_X, train_y, early_stopping_rounds=80, \n",
    "        eval_set=eval_set, eval_metric='rmse', verbose=100, \n",
    "        categorical_feature=categories)\n",
    "    y_predls.append(clf.predict(test_df[cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>deal_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1503424</th>\n",
       "      <td>6544e41a8817</td>\n",
       "      <td>0.446934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503425</th>\n",
       "      <td>65b9484d670f</td>\n",
       "      <td>0.155028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503426</th>\n",
       "      <td>8bab230b2ecd</td>\n",
       "      <td>0.171616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503427</th>\n",
       "      <td>8e348601fefc</td>\n",
       "      <td>0.105203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503428</th>\n",
       "      <td>8bd2fe400b89</td>\n",
       "      <td>0.164077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              item_id  deal_probability\n",
       "1503424  6544e41a8817          0.446934\n",
       "1503425  65b9484d670f          0.155028\n",
       "1503426  8bab230b2ecd          0.171616\n",
       "1503427  8e348601fefc          0.105203\n",
       "1503428  8bd2fe400b89          0.164077"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['deal_probability'] = sum(y_predls)/len(y_predls)\n",
    "test_df['deal_probability'] = np.clip(test_df['deal_probability'], .0001, .9999)\n",
    "test_df[['item_id', 'deal_probability']].to_csv('../lgbbsub_2006L2.csv.gz', compression='gzip', index=False, header=True)\n",
    "test_df[['item_id', 'deal_probability']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
