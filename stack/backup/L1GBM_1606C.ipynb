{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "import sys\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "path = \"/home/darragh/avito/data/\"\n",
    "#path = '/Users/dhanley2/Documents/avito/data/'\n",
    "#path = '/home/ubuntu/avito/data/'\n",
    "#data_path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lgb25 = pd.read_csv('../lgCV_2505.csv.gz', compression='gzip')\n",
    "lgb02A = pd.read_csv(path+'../sub/lgCV_0206A.csv.gz', compression='gzip')\n",
    "lgb09 = pd.read_csv(path+'../sub/lgCV_0906.csv.gz', compression='gzip')\n",
    "lgb10 = pd.read_csv(path+'../sub/lgCV_1006.csv.gz', compression='gzip')\n",
    "lgb11A= pd.read_csv(path+'../sub/lgCV_1106A.csv.gz', compression='gzip')\n",
    "lgb11D= pd.read_csv(path+'../sub/lgCV_1106D.csv.gz', compression='gzip')\n",
    "lgb14= pd.read_csv(path+'../sub/lgCV_1406.csv.gz', compression='gzip')\n",
    "lgb14A= pd.read_csv(path+'../sub/lgCV_1406A.csv.gz', compression='gzip')\n",
    "lgb27 = pd.read_csv(path+'../sub/lgCV_2705B.csv.gz', compression='gzip')\n",
    "lgb31 = pd.read_csv(path+'../sub/lgCV_3105.csv.gz', compression='gzip')\n",
    "lgb02 = pd.read_csv(path+'../sub/lgCV_0206.csv.gz', compression='gzip')\n",
    "rnn =   pd.read_csv(path+'../sub/rnnCV_2805.csv.gz', compression='gzip')\n",
    "rnn27 = pd.read_csv(path+'../sub/rnnCV_2705A.csv.gz', compression='gzip')\n",
    "rnn12 = pd.read_csv(path+'../sub/rnnCV_1206.csv.gz', compression='gzip')\n",
    "mlp =   pd.read_csv(path+'../sub/mlpCV_2505.csv.gz', compression='gzip')\n",
    "nnet16 =   pd.read_csv(path+'../sub/nnetImgV5CV.csv.gz', compression='gzip')\n",
    "rdgv19 =   pd.read_csv(path+'../sub/rdgv19CV_1606.csv.gz', compression='gzip')\n",
    "truth = pd.read_csv(path+'train.csv.zip', compression='zip', parse_dates = [\"activation_date\"])\n",
    "y =     truth['deal_probability'].values\n",
    "truth.drop('deal_probability', 1)\n",
    "test =  pd.read_csv(path+'test.csv.zip', compression='zip', parse_dates = [\"activation_date\"])\n",
    "test['deal_probability']=float('NAN') \n",
    "truth = pd.concat([truth,test[truth.columns]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb14['deal_probability'] =  ( lgb14['deal_probability'].values + lgb14A['deal_probability'].values)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['item_id', 'user_id', 'region', 'city', 'parent_category_name',\n",
       "       'category_name', 'param_1', 'param_2', 'param_3', 'title',\n",
       "       'description', 'price', 'item_seq_number', 'activation_date',\n",
       "       'user_type', 'image', 'image_top_1', 'deal_probability'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#img_cts = truth['image_top_1'].value_counts().reset_index()\n",
    "#truth['image_top_big'] = 'lo_count'\n",
    "#big_top_1 = img_cts[img_cts['image_top_1']>5000]['index'].tolist()\n",
    "#idx = truth['image_top_1'].isin(big_top_1)\n",
    "#truth['image_top_big'][idx] = truth['image_top_1'][idx].astype(str).values\n",
    "\n",
    "def keep_big(df, col, cutoff):\n",
    "    cts = df[col].value_counts().reset_index()\n",
    "    df[col+'_big'] = 'lo_count'\n",
    "    big = cts[cts[col]>cutoff]['index'].tolist()\n",
    "    idx = df[col].isin(big)\n",
    "    df[col+'_big'][idx] = df[col][idx].astype(str).values\n",
    "    return df[col+'_big'].values\n",
    "truth['image_top_1_big'] = keep_big(truth, 'image_top_1', 5000)\n",
    "truth['param_1_big'] = keep_big(truth, 'param_1', 5000)\n",
    "truth['param_2_big'] = keep_big(truth, 'param_2', 5000)\n",
    "truth['param_3_big'] = keep_big(truth, 'param_3', 5000)\n",
    "truth['city_big'] = keep_big(truth, 'city', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_top_1_big</th>\n",
       "      <th>param_1_big</th>\n",
       "      <th>param_2_big</th>\n",
       "      <th>param_3_big</th>\n",
       "      <th>city_big</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lo_count</td>\n",
       "      <td>Постельные принадлежности</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>Екатеринбург</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lo_count</td>\n",
       "      <td>Другое</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>Самара</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lo_count</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>Ростов-на-Дону</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>796.0</td>\n",
       "      <td>Автомобильные кресла</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>Набережные Челны</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2264.0</td>\n",
       "      <td>С пробегом</td>\n",
       "      <td>ВАЗ (LADA)</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>Волгоград</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_top_1_big                param_1_big param_2_big param_3_big  \\\n",
       "0        lo_count  Постельные принадлежности    lo_count    lo_count   \n",
       "1        lo_count                     Другое    lo_count    lo_count   \n",
       "2        lo_count                   lo_count    lo_count    lo_count   \n",
       "3           796.0       Автомобильные кресла    lo_count    lo_count   \n",
       "4          2264.0                 С пробегом  ВАЗ (LADA)    lo_count   \n",
       "\n",
       "           city_big  \n",
       "0      Екатеринбург  \n",
       "1            Самара  \n",
       "2    Ростов-на-Дону  \n",
       "3  Набережные Челны  \n",
       "4         Волгоград  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth[[c for c in truth.columns if 'big' in c]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lgb25.rename(columns={'deal_probability': 'lgb25_preds' }, inplace=True)\n",
    "lgb31.rename(columns={'deal_probability': 'lgb31_preds' }, inplace=True)\n",
    "lgb27.rename(columns={'deal_probability': 'lgb27_preds' }, inplace=True)\n",
    "lgb02.rename(columns={'deal_probability': 'lgb02_preds' }, inplace=True)\n",
    "lgb09.rename(columns={'deal_probability': 'lgb09_preds' }, inplace=True)\n",
    "lgb10.rename(columns={'deal_probability': 'lgb10_preds' }, inplace=True)\n",
    "lgb11D.rename(columns={'deal_probability': 'lgb11D_preds' }, inplace=True)\n",
    "lgb11A.rename(columns={'deal_probability': 'lgb11A_preds' }, inplace=True)\n",
    "lgb14.rename(columns={'deal_probability': 'lgb14_preds' }, inplace=True)\n",
    "lgb02A.rename(columns={'deal_probability': 'lgb02A_preds' }, inplace=True)\n",
    "rnn27.rename(columns={'deal_probability': 'rnn27_preds' }, inplace=True)\n",
    "rnn12.rename(columns={'deal_probability': 'rnn12_preds' }, inplace=True)\n",
    "rdgv19.rename(columns={'deal_probability': 'rdgv19_preds' }, inplace=True)\n",
    "nnet16.rename(columns={'deal_probability': 'nnet16_preds' }, inplace=True)\n",
    "\n",
    "mlp.rename(columns={'deal_probability': 'mlp_preds' }, inplace=True)\n",
    "preds_df = lgb27.merge(rnn, on='item_id')\\\n",
    "                .merge(mlp, on='item_id')\\\n",
    "                .merge(lgb31, on='item_id')\\\n",
    "                .merge(lgb02, on='item_id')\\\n",
    "                .merge(lgb09, on='item_id')\\\n",
    "                .merge(lgb10, on='item_id')\\\n",
    "                .merge(lgb11A, on='item_id')\\\n",
    "                .merge(lgb11D, on='item_id')\\\n",
    "                .merge(lgb14, on='item_id')\\\n",
    "                .merge(lgb02A, on='item_id')\\\n",
    "                .merge(rnn27, on='item_id')\\\n",
    "                .merge(rnn12, on='item_id')\\\n",
    "                .merge(rdgv19, on='item_id')\\\n",
    "                .merge(nnet16, on='item_id')\\\n",
    "                .merge(truth, on='item_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rnn_preds',\n",
       " 'mlp_preds',\n",
       " 'lgb31_preds',\n",
       " 'lgb09_preds',\n",
       " 'lgb10_preds',\n",
       " 'lgb11D_preds',\n",
       " 'lgb14_preds',\n",
       " 'lgb02A_preds',\n",
       " 'rnn27_preds',\n",
       " 'rnn12_preds']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cols = [col for col in preds_df.columns if ('_preds' in col) \\\n",
    "             and ('lgb27' not in col) and ('lgb02_' not in col) and ('lgb11A_' not in col) \\\n",
    "             and ('rdgv19_' not in col) and ('nnet16_' not in col)]\n",
    "\n",
    "preds_df['preds_sum'] = preds_df[pred_cols].sum(axis=1)\n",
    "pred_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_df['price'].fillna(-1,inplace=True)\n",
    "preds_df['max'] = np.max(np.array([preds_df[col] for col in pred_cols]),axis=0)\n",
    "preds_df['min'] = np.min(np.array([preds_df[col] for col in pred_cols]),axis=0)\n",
    "preds_df['avg'] = np.mean(np.array([preds_df[col] for col in pred_cols]),axis=0)\n",
    "preds_df['med'] = np.median(np.array([preds_df[col] for col in pred_cols]),axis=0)\n",
    "preds_df['std'] = np.std(np.array([preds_df[col] for col in pred_cols]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference_rnn_preds__mlp_preds\n",
      "difference_rnn_preds__lgb31_preds\n",
      "difference_rnn_preds__lgb09_preds\n",
      "difference_rnn_preds__lgb10_preds\n",
      "difference_rnn_preds__lgb11D_preds\n",
      "difference_rnn_preds__lgb14_preds\n",
      "difference_rnn_preds__lgb02A_preds\n",
      "difference_rnn_preds__rnn27_preds\n",
      "difference_rnn_preds__rnn12_preds\n",
      "difference_mlp_preds__lgb31_preds\n",
      "difference_mlp_preds__lgb09_preds\n",
      "difference_mlp_preds__lgb10_preds\n",
      "difference_mlp_preds__lgb11D_preds\n",
      "difference_mlp_preds__lgb14_preds\n",
      "difference_mlp_preds__lgb02A_preds\n",
      "difference_mlp_preds__rnn27_preds\n",
      "difference_mlp_preds__rnn12_preds\n",
      "difference_lgb31_preds__lgb09_preds\n",
      "difference_lgb31_preds__lgb10_preds\n",
      "difference_lgb31_preds__lgb11D_preds\n",
      "difference_lgb31_preds__lgb14_preds\n",
      "difference_lgb31_preds__lgb02A_preds\n",
      "difference_lgb31_preds__rnn27_preds\n",
      "difference_lgb31_preds__rnn12_preds\n",
      "difference_lgb09_preds__lgb10_preds\n",
      "difference_lgb09_preds__lgb11D_preds\n",
      "difference_lgb09_preds__lgb14_preds\n",
      "difference_lgb09_preds__lgb02A_preds\n",
      "difference_lgb09_preds__rnn27_preds\n",
      "difference_lgb09_preds__rnn12_preds\n",
      "difference_lgb10_preds__lgb11D_preds\n",
      "difference_lgb10_preds__lgb14_preds\n",
      "difference_lgb10_preds__lgb02A_preds\n",
      "difference_lgb10_preds__rnn27_preds\n",
      "difference_lgb10_preds__rnn12_preds\n",
      "difference_lgb11D_preds__lgb14_preds\n",
      "difference_lgb11D_preds__lgb02A_preds\n",
      "difference_lgb11D_preds__rnn27_preds\n",
      "difference_lgb11D_preds__rnn12_preds\n",
      "difference_lgb14_preds__lgb02A_preds\n",
      "difference_lgb14_preds__rnn27_preds\n",
      "difference_lgb14_preds__rnn12_preds\n",
      "difference_lgb02A_preds__rnn27_preds\n",
      "difference_lgb02A_preds__rnn12_preds\n",
      "difference_rnn27_preds__rnn12_preds\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for p1, p2 in itertools.combinations(pred_cols, 2):\n",
    "    print('difference_%s__%s'%(p1,p2))\n",
    "    preds_df['difference_%s__%s'%(p1,p2)] = preds_df[p2] - preds_df[p1]\n",
    "    preds_df['sums_%s__%s'%(p1,p2)] = preds_df[p2] + preds_df[p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>lgb27_preds</th>\n",
       "      <th>rnn_preds</th>\n",
       "      <th>mlp_preds</th>\n",
       "      <th>lgb31_preds</th>\n",
       "      <th>lgb02_preds</th>\n",
       "      <th>lgb09_preds</th>\n",
       "      <th>lgb10_preds</th>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <th>...</th>\n",
       "      <th>difference_lgb14_preds__rnn27_preds</th>\n",
       "      <th>sums_lgb14_preds__rnn27_preds</th>\n",
       "      <th>difference_lgb14_preds__rnn12_preds</th>\n",
       "      <th>sums_lgb14_preds__rnn12_preds</th>\n",
       "      <th>difference_lgb02A_preds__rnn27_preds</th>\n",
       "      <th>sums_lgb02A_preds__rnn27_preds</th>\n",
       "      <th>difference_lgb02A_preds__rnn12_preds</th>\n",
       "      <th>sums_lgb02A_preds__rnn12_preds</th>\n",
       "      <th>difference_rnn27_preds__rnn12_preds</th>\n",
       "      <th>sums_rnn27_preds__rnn12_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b912c3c6a6ad</td>\n",
       "      <td>0.091656</td>\n",
       "      <td>0.069891</td>\n",
       "      <td>0.091223</td>\n",
       "      <td>0.083219</td>\n",
       "      <td>0.090855</td>\n",
       "      <td>0.109624</td>\n",
       "      <td>0.107764</td>\n",
       "      <td>0.095101</td>\n",
       "      <td>0.092921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015875</td>\n",
       "      <td>0.152536</td>\n",
       "      <td>-0.007329</td>\n",
       "      <td>0.161083</td>\n",
       "      <td>-0.041287</td>\n",
       "      <td>0.177948</td>\n",
       "      <td>-0.032740</td>\n",
       "      <td>0.186494</td>\n",
       "      <td>0.008546</td>\n",
       "      <td>0.145208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dac0150717d</td>\n",
       "      <td>0.147801</td>\n",
       "      <td>0.075968</td>\n",
       "      <td>0.211844</td>\n",
       "      <td>0.157973</td>\n",
       "      <td>0.119609</td>\n",
       "      <td>0.157466</td>\n",
       "      <td>0.161107</td>\n",
       "      <td>0.140269</td>\n",
       "      <td>0.144395</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065534</td>\n",
       "      <td>0.206810</td>\n",
       "      <td>-0.047612</td>\n",
       "      <td>0.224731</td>\n",
       "      <td>-0.089406</td>\n",
       "      <td>0.230683</td>\n",
       "      <td>-0.071485</td>\n",
       "      <td>0.248604</td>\n",
       "      <td>0.017921</td>\n",
       "      <td>0.159198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba83aefab5dc</td>\n",
       "      <td>0.186261</td>\n",
       "      <td>0.167167</td>\n",
       "      <td>0.236579</td>\n",
       "      <td>0.227048</td>\n",
       "      <td>0.258980</td>\n",
       "      <td>0.245236</td>\n",
       "      <td>0.219107</td>\n",
       "      <td>0.234076</td>\n",
       "      <td>0.222678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037524</td>\n",
       "      <td>0.361372</td>\n",
       "      <td>-0.051423</td>\n",
       "      <td>0.347473</td>\n",
       "      <td>-0.079412</td>\n",
       "      <td>0.403260</td>\n",
       "      <td>-0.093311</td>\n",
       "      <td>0.389361</td>\n",
       "      <td>-0.013899</td>\n",
       "      <td>0.309950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02996f1dd2ea</td>\n",
       "      <td>0.241699</td>\n",
       "      <td>0.260876</td>\n",
       "      <td>0.383699</td>\n",
       "      <td>0.231447</td>\n",
       "      <td>0.284130</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>0.255519</td>\n",
       "      <td>0.241802</td>\n",
       "      <td>0.271355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019735</td>\n",
       "      <td>0.537873</td>\n",
       "      <td>-0.010746</td>\n",
       "      <td>0.507392</td>\n",
       "      <td>-0.057652</td>\n",
       "      <td>0.615259</td>\n",
       "      <td>-0.088132</td>\n",
       "      <td>0.584779</td>\n",
       "      <td>-0.030481</td>\n",
       "      <td>0.527127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c90be56d2ab</td>\n",
       "      <td>0.407423</td>\n",
       "      <td>0.431520</td>\n",
       "      <td>0.420657</td>\n",
       "      <td>0.412563</td>\n",
       "      <td>0.430581</td>\n",
       "      <td>0.511145</td>\n",
       "      <td>0.511676</td>\n",
       "      <td>0.504849</td>\n",
       "      <td>0.503961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.150753</td>\n",
       "      <td>0.851322</td>\n",
       "      <td>-0.079694</td>\n",
       "      <td>0.922381</td>\n",
       "      <td>-0.071704</td>\n",
       "      <td>0.772273</td>\n",
       "      <td>-0.000645</td>\n",
       "      <td>0.843332</td>\n",
       "      <td>0.071059</td>\n",
       "      <td>0.771628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id  lgb27_preds  rnn_preds  mlp_preds  lgb31_preds  lgb02_preds  \\\n",
       "0  b912c3c6a6ad     0.091656   0.069891   0.091223     0.083219     0.090855   \n",
       "1  2dac0150717d     0.147801   0.075968   0.211844     0.157973     0.119609   \n",
       "2  ba83aefab5dc     0.186261   0.167167   0.236579     0.227048     0.258980   \n",
       "3  02996f1dd2ea     0.241699   0.260876   0.383699     0.231447     0.284130   \n",
       "4  7c90be56d2ab     0.407423   0.431520   0.420657     0.412563     0.430581   \n",
       "\n",
       "   lgb09_preds  lgb10_preds  lgb11A_preds  lgb11D_preds  \\\n",
       "0     0.109624     0.107764      0.095101      0.092921   \n",
       "1     0.157466     0.161107      0.140269      0.144395   \n",
       "2     0.245236     0.219107      0.234076      0.222678   \n",
       "3     0.289101     0.255519      0.241802      0.271355   \n",
       "4     0.511145     0.511676      0.504849      0.503961   \n",
       "\n",
       "               ...               difference_lgb14_preds__rnn27_preds  \\\n",
       "0              ...                                         -0.015875   \n",
       "1              ...                                         -0.065534   \n",
       "2              ...                                         -0.037524   \n",
       "3              ...                                          0.019735   \n",
       "4              ...                                         -0.150753   \n",
       "\n",
       "   sums_lgb14_preds__rnn27_preds  difference_lgb14_preds__rnn12_preds  \\\n",
       "0                       0.152536                            -0.007329   \n",
       "1                       0.206810                            -0.047612   \n",
       "2                       0.361372                            -0.051423   \n",
       "3                       0.537873                            -0.010746   \n",
       "4                       0.851322                            -0.079694   \n",
       "\n",
       "   sums_lgb14_preds__rnn12_preds  difference_lgb02A_preds__rnn27_preds  \\\n",
       "0                       0.161083                             -0.041287   \n",
       "1                       0.224731                             -0.089406   \n",
       "2                       0.347473                             -0.079412   \n",
       "3                       0.507392                             -0.057652   \n",
       "4                       0.922381                             -0.071704   \n",
       "\n",
       "   sums_lgb02A_preds__rnn27_preds  difference_lgb02A_preds__rnn12_preds  \\\n",
       "0                        0.177948                             -0.032740   \n",
       "1                        0.230683                             -0.071485   \n",
       "2                        0.403260                             -0.093311   \n",
       "3                        0.615259                             -0.088132   \n",
       "4                        0.772273                             -0.000645   \n",
       "\n",
       "  sums_lgb02A_preds__rnn12_preds difference_rnn27_preds__rnn12_preds  \\\n",
       "0                       0.186494                            0.008546   \n",
       "1                       0.248604                            0.017921   \n",
       "2                       0.389361                           -0.013899   \n",
       "3                       0.584779                           -0.030481   \n",
       "4                       0.843332                            0.071059   \n",
       "\n",
       "  sums_rnn27_preds__rnn12_preds  \n",
       "0                      0.145208  \n",
       "1                      0.159198  \n",
       "2                      0.309950  \n",
       "3                      0.527127  \n",
       "4                      0.771628  \n",
       "\n",
       "[5 rows x 135 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgb27_preds',\n",
       " 'rnn_preds',\n",
       " 'mlp_preds',\n",
       " 'lgb31_preds',\n",
       " 'lgb02_preds',\n",
       " 'lgb09_preds',\n",
       " 'lgb10_preds',\n",
       " 'lgb11A_preds',\n",
       " 'lgb11D_preds',\n",
       " 'lgb14_preds',\n",
       " 'lgb02A_preds',\n",
       " 'rnn27_preds',\n",
       " 'rnn12_preds',\n",
       " 'rdgv19_preds',\n",
       " 'nnet16_preds']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cols = [col for col in preds_df.columns if ('preds' in col) \n",
    "             and ('difference' not in col) \n",
    "             and ('sum' not in col)]\n",
    "pred_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     1503424\n",
      "False     508438\n",
      "Name: deal_probability, dtype: int64\n",
      "RMSE lgb27_preds:  0.21681527582821059\n",
      "RMSE rnn_preds:  0.21771476573780568\n",
      "RMSE mlp_preds:  0.2187544351068867\n",
      "RMSE lgb31_preds:  0.21681135578306754\n",
      "RMSE lgb02_preds:  0.21625386267187377\n",
      "RMSE lgb09_preds:  0.21581543265040168\n",
      "RMSE lgb10_preds:  0.21533498019117664\n",
      "RMSE lgb11A_preds:  0.21403812331071156\n",
      "RMSE lgb11D_preds:  0.21392147604708842\n",
      "RMSE lgb14_preds:  0.21329729304260686\n",
      "RMSE lgb02A_preds:  0.21627136604335995\n",
      "RMSE rnn27_preds:  0.21698040871120608\n",
      "RMSE rnn12_preds:  0.2167114508342396\n",
      "RMSE rdgv19_preds:  0.24593955235646558\n",
      "RMSE nnet16_preds:  0.2356712803522193\n"
     ]
    }
   ],
   "source": [
    "idx = preds_df['deal_probability']==preds_df['deal_probability']\n",
    "print(idx.value_counts())\n",
    "for col in [c for c in preds_df.columns if ('_preds' in c) and ('difference' not in c) and ('sum' not in c)]:\n",
    "    print('RMSE %s: '%(col), np.sqrt(metrics.mean_squared_error(preds_df['deal_probability'][idx].values, preds_df[col][idx].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foldls = [[\"2017-03-15\", \"2017-03-16\", \"2017-03-17\"], \\\n",
    "       [\"2017-03-18\", \"2017-03-19\", \"2017-03-20\"], \\\n",
    "       [\"2017-03-21\", \"2017-03-22\", \"2017-03-23\"], \\\n",
    "       [\"2017-03-24\", \"2017-03-25\", \"2017-03-26\"], \\\n",
    "        [\"2017-03-27\", \"2017-03-28\", \"2017-03-29\", \\\n",
    "            \"2017-03-30\", \"2017-03-31\", \"2017-04-01\", \\\n",
    "            \"2017-04-02\", \"2017-04-03\",\"2017-04-07\"]]\n",
    "foldls = [[pd.to_datetime(d) for d in f] for f in foldls]\n",
    "preds_df['fold'] = -1\n",
    "for t, fold in enumerate(foldls):\n",
    "    preds_df['fold'][preds_df.activation_date.isin(fold)] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold0</th>\n",
       "      <th>Fold1</th>\n",
       "      <th>Fold2</th>\n",
       "      <th>Fold3</th>\n",
       "      <th>Fold4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgb27_preds</td>\n",
       "      <td>0.216848</td>\n",
       "      <td>0.217096</td>\n",
       "      <td>0.217923</td>\n",
       "      <td>0.217597</td>\n",
       "      <td>0.213692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rnn_preds</td>\n",
       "      <td>0.218756</td>\n",
       "      <td>0.218966</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.219554</td>\n",
       "      <td>0.214747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlp_preds</td>\n",
       "      <td>0.219660</td>\n",
       "      <td>0.220088</td>\n",
       "      <td>0.216672</td>\n",
       "      <td>0.220347</td>\n",
       "      <td>0.216385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lgb31_preds</td>\n",
       "      <td>0.216537</td>\n",
       "      <td>0.216643</td>\n",
       "      <td>0.219230</td>\n",
       "      <td>0.217169</td>\n",
       "      <td>0.213430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgb02_preds</td>\n",
       "      <td>0.216371</td>\n",
       "      <td>0.216447</td>\n",
       "      <td>0.217354</td>\n",
       "      <td>0.217032</td>\n",
       "      <td>0.213158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lgb09_preds</td>\n",
       "      <td>0.215514</td>\n",
       "      <td>0.215678</td>\n",
       "      <td>0.218418</td>\n",
       "      <td>0.216073</td>\n",
       "      <td>0.212293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lgb10_preds</td>\n",
       "      <td>0.215240</td>\n",
       "      <td>0.215533</td>\n",
       "      <td>0.217072</td>\n",
       "      <td>0.215802</td>\n",
       "      <td>0.212023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lgb11A_preds</td>\n",
       "      <td>0.215011</td>\n",
       "      <td>0.215205</td>\n",
       "      <td>0.211879</td>\n",
       "      <td>0.215771</td>\n",
       "      <td>0.211735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lgb11D_preds</td>\n",
       "      <td>0.214818</td>\n",
       "      <td>0.215074</td>\n",
       "      <td>0.211837</td>\n",
       "      <td>0.215720</td>\n",
       "      <td>0.211549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lgb14_preds</td>\n",
       "      <td>0.214204</td>\n",
       "      <td>0.214441</td>\n",
       "      <td>0.211074</td>\n",
       "      <td>0.215146</td>\n",
       "      <td>0.211051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lgb02A_preds</td>\n",
       "      <td>0.216081</td>\n",
       "      <td>0.216051</td>\n",
       "      <td>0.218825</td>\n",
       "      <td>0.216562</td>\n",
       "      <td>0.212741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rnn27_preds</td>\n",
       "      <td>0.218097</td>\n",
       "      <td>0.218115</td>\n",
       "      <td>0.214982</td>\n",
       "      <td>0.218651</td>\n",
       "      <td>0.214379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rnn12_preds</td>\n",
       "      <td>0.217658</td>\n",
       "      <td>0.217913</td>\n",
       "      <td>0.214952</td>\n",
       "      <td>0.218472</td>\n",
       "      <td>0.213781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rdgv19_preds</td>\n",
       "      <td>0.246571</td>\n",
       "      <td>0.246399</td>\n",
       "      <td>0.244456</td>\n",
       "      <td>0.247503</td>\n",
       "      <td>0.244406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nnet16_preds</td>\n",
       "      <td>0.236667</td>\n",
       "      <td>0.236622</td>\n",
       "      <td>0.233930</td>\n",
       "      <td>0.237406</td>\n",
       "      <td>0.233052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model     Fold0     Fold1     Fold2     Fold3     Fold4\n",
       "0    lgb27_preds  0.216848  0.217096  0.217923  0.217597  0.213692\n",
       "1      rnn_preds  0.218756  0.218966  0.215764  0.219554  0.214747\n",
       "2      mlp_preds  0.219660  0.220088  0.216672  0.220347  0.216385\n",
       "3    lgb31_preds  0.216537  0.216643  0.219230  0.217169  0.213430\n",
       "4    lgb02_preds  0.216371  0.216447  0.217354  0.217032  0.213158\n",
       "5    lgb09_preds  0.215514  0.215678  0.218418  0.216073  0.212293\n",
       "6    lgb10_preds  0.215240  0.215533  0.217072  0.215802  0.212023\n",
       "7   lgb11A_preds  0.215011  0.215205  0.211879  0.215771  0.211735\n",
       "8   lgb11D_preds  0.214818  0.215074  0.211837  0.215720  0.211549\n",
       "9    lgb14_preds  0.214204  0.214441  0.211074  0.215146  0.211051\n",
       "10  lgb02A_preds  0.216081  0.216051  0.218825  0.216562  0.212741\n",
       "11   rnn27_preds  0.218097  0.218115  0.214982  0.218651  0.214379\n",
       "12   rnn12_preds  0.217658  0.217913  0.214952  0.218472  0.213781\n",
       "13  rdgv19_preds  0.246571  0.246399  0.244456  0.247503  0.244406\n",
       "14  nnet16_preds  0.236667  0.236622  0.233930  0.237406  0.233052"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for col in [c for c in preds_df.columns if ('_preds' in c) \\\n",
    "            and ('difference' not in c) \\\n",
    "            and ('sum' not in c)]:\n",
    "    lstmp = [col]\n",
    "    for i in range(5):\n",
    "        idx = preds_df['fold']==i\n",
    "        lstmp.append(np.sqrt(metrics.mean_squared_error(preds_df['deal_probability'][idx].values, \\\n",
    "                                                        preds_df[col][idx].values)))\n",
    "    scores.append(lstmp)\n",
    "pd.DataFrame(scores, columns = ['Model']+['Fold%s'%(i) for i in range(5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations in test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb27_preds</th>\n",
       "      <th>rnn_preds</th>\n",
       "      <th>mlp_preds</th>\n",
       "      <th>lgb31_preds</th>\n",
       "      <th>lgb02_preds</th>\n",
       "      <th>lgb09_preds</th>\n",
       "      <th>lgb10_preds</th>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <th>lgb14_preds</th>\n",
       "      <th>lgb02A_preds</th>\n",
       "      <th>rnn27_preds</th>\n",
       "      <th>rnn12_preds</th>\n",
       "      <th>rdgv19_preds</th>\n",
       "      <th>nnet16_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lgb27_preds</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915952</td>\n",
       "      <td>0.919171</td>\n",
       "      <td>0.990750</td>\n",
       "      <td>0.988682</td>\n",
       "      <td>0.978331</td>\n",
       "      <td>0.978298</td>\n",
       "      <td>0.966819</td>\n",
       "      <td>0.965873</td>\n",
       "      <td>0.961540</td>\n",
       "      <td>0.983143</td>\n",
       "      <td>0.916804</td>\n",
       "      <td>0.920576</td>\n",
       "      <td>0.568406</td>\n",
       "      <td>0.721926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn_preds</th>\n",
       "      <td>0.915952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929710</td>\n",
       "      <td>0.910602</td>\n",
       "      <td>0.913307</td>\n",
       "      <td>0.908867</td>\n",
       "      <td>0.913286</td>\n",
       "      <td>0.915655</td>\n",
       "      <td>0.913936</td>\n",
       "      <td>0.912870</td>\n",
       "      <td>0.911443</td>\n",
       "      <td>0.985360</td>\n",
       "      <td>0.978274</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.720972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_preds</th>\n",
       "      <td>0.919171</td>\n",
       "      <td>0.929710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914307</td>\n",
       "      <td>0.916343</td>\n",
       "      <td>0.909521</td>\n",
       "      <td>0.913883</td>\n",
       "      <td>0.915367</td>\n",
       "      <td>0.913018</td>\n",
       "      <td>0.911656</td>\n",
       "      <td>0.913600</td>\n",
       "      <td>0.925010</td>\n",
       "      <td>0.929518</td>\n",
       "      <td>0.577280</td>\n",
       "      <td>0.747602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb31_preds</th>\n",
       "      <td>0.990750</td>\n",
       "      <td>0.910602</td>\n",
       "      <td>0.914307</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991984</td>\n",
       "      <td>0.981891</td>\n",
       "      <td>0.981375</td>\n",
       "      <td>0.966656</td>\n",
       "      <td>0.965897</td>\n",
       "      <td>0.961575</td>\n",
       "      <td>0.986851</td>\n",
       "      <td>0.914204</td>\n",
       "      <td>0.916939</td>\n",
       "      <td>0.570034</td>\n",
       "      <td>0.722562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb02_preds</th>\n",
       "      <td>0.988682</td>\n",
       "      <td>0.913307</td>\n",
       "      <td>0.916343</td>\n",
       "      <td>0.991984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982596</td>\n",
       "      <td>0.982052</td>\n",
       "      <td>0.970858</td>\n",
       "      <td>0.969933</td>\n",
       "      <td>0.966325</td>\n",
       "      <td>0.987434</td>\n",
       "      <td>0.916726</td>\n",
       "      <td>0.920105</td>\n",
       "      <td>0.567698</td>\n",
       "      <td>0.721808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb09_preds</th>\n",
       "      <td>0.978331</td>\n",
       "      <td>0.908867</td>\n",
       "      <td>0.909521</td>\n",
       "      <td>0.981891</td>\n",
       "      <td>0.982596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990447</td>\n",
       "      <td>0.976755</td>\n",
       "      <td>0.976540</td>\n",
       "      <td>0.972392</td>\n",
       "      <td>0.988708</td>\n",
       "      <td>0.912375</td>\n",
       "      <td>0.915090</td>\n",
       "      <td>0.560909</td>\n",
       "      <td>0.711925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb10_preds</th>\n",
       "      <td>0.978298</td>\n",
       "      <td>0.913286</td>\n",
       "      <td>0.913883</td>\n",
       "      <td>0.981375</td>\n",
       "      <td>0.982052</td>\n",
       "      <td>0.990447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982841</td>\n",
       "      <td>0.982033</td>\n",
       "      <td>0.977396</td>\n",
       "      <td>0.985858</td>\n",
       "      <td>0.916436</td>\n",
       "      <td>0.920034</td>\n",
       "      <td>0.562639</td>\n",
       "      <td>0.717218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <td>0.966819</td>\n",
       "      <td>0.915655</td>\n",
       "      <td>0.915367</td>\n",
       "      <td>0.966656</td>\n",
       "      <td>0.970858</td>\n",
       "      <td>0.976755</td>\n",
       "      <td>0.982841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992400</td>\n",
       "      <td>0.988703</td>\n",
       "      <td>0.971893</td>\n",
       "      <td>0.918727</td>\n",
       "      <td>0.923137</td>\n",
       "      <td>0.558477</td>\n",
       "      <td>0.717910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <td>0.965873</td>\n",
       "      <td>0.913936</td>\n",
       "      <td>0.913018</td>\n",
       "      <td>0.965897</td>\n",
       "      <td>0.969933</td>\n",
       "      <td>0.976540</td>\n",
       "      <td>0.982033</td>\n",
       "      <td>0.992400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989978</td>\n",
       "      <td>0.971846</td>\n",
       "      <td>0.917196</td>\n",
       "      <td>0.921322</td>\n",
       "      <td>0.557072</td>\n",
       "      <td>0.714570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb14_preds</th>\n",
       "      <td>0.961540</td>\n",
       "      <td>0.912870</td>\n",
       "      <td>0.911656</td>\n",
       "      <td>0.961575</td>\n",
       "      <td>0.966325</td>\n",
       "      <td>0.972392</td>\n",
       "      <td>0.977396</td>\n",
       "      <td>0.988703</td>\n",
       "      <td>0.989978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967560</td>\n",
       "      <td>0.916160</td>\n",
       "      <td>0.920547</td>\n",
       "      <td>0.553930</td>\n",
       "      <td>0.712319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb02A_preds</th>\n",
       "      <td>0.983143</td>\n",
       "      <td>0.911443</td>\n",
       "      <td>0.913600</td>\n",
       "      <td>0.986851</td>\n",
       "      <td>0.987434</td>\n",
       "      <td>0.988708</td>\n",
       "      <td>0.985858</td>\n",
       "      <td>0.971893</td>\n",
       "      <td>0.971846</td>\n",
       "      <td>0.967560</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914911</td>\n",
       "      <td>0.917453</td>\n",
       "      <td>0.564071</td>\n",
       "      <td>0.716301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn27_preds</th>\n",
       "      <td>0.916804</td>\n",
       "      <td>0.985360</td>\n",
       "      <td>0.925010</td>\n",
       "      <td>0.914204</td>\n",
       "      <td>0.916726</td>\n",
       "      <td>0.912375</td>\n",
       "      <td>0.916436</td>\n",
       "      <td>0.918727</td>\n",
       "      <td>0.917196</td>\n",
       "      <td>0.916160</td>\n",
       "      <td>0.914911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979744</td>\n",
       "      <td>0.558103</td>\n",
       "      <td>0.725452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn12_preds</th>\n",
       "      <td>0.920576</td>\n",
       "      <td>0.978274</td>\n",
       "      <td>0.929518</td>\n",
       "      <td>0.916939</td>\n",
       "      <td>0.920105</td>\n",
       "      <td>0.915090</td>\n",
       "      <td>0.920034</td>\n",
       "      <td>0.923137</td>\n",
       "      <td>0.921322</td>\n",
       "      <td>0.920547</td>\n",
       "      <td>0.917453</td>\n",
       "      <td>0.979744</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.564928</td>\n",
       "      <td>0.735670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rdgv19_preds</th>\n",
       "      <td>0.568406</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.577280</td>\n",
       "      <td>0.570034</td>\n",
       "      <td>0.567698</td>\n",
       "      <td>0.560909</td>\n",
       "      <td>0.562639</td>\n",
       "      <td>0.558477</td>\n",
       "      <td>0.557072</td>\n",
       "      <td>0.553930</td>\n",
       "      <td>0.564071</td>\n",
       "      <td>0.558103</td>\n",
       "      <td>0.564928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnet16_preds</th>\n",
       "      <td>0.721926</td>\n",
       "      <td>0.720972</td>\n",
       "      <td>0.747602</td>\n",
       "      <td>0.722562</td>\n",
       "      <td>0.721808</td>\n",
       "      <td>0.711925</td>\n",
       "      <td>0.717218</td>\n",
       "      <td>0.717910</td>\n",
       "      <td>0.714570</td>\n",
       "      <td>0.712319</td>\n",
       "      <td>0.716301</td>\n",
       "      <td>0.725452</td>\n",
       "      <td>0.735670</td>\n",
       "      <td>0.784145</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lgb27_preds  rnn_preds  mlp_preds  lgb31_preds  lgb02_preds  \\\n",
       "lgb27_preds      1.000000   0.915952   0.919171     0.990750     0.988682   \n",
       "rnn_preds        0.915952   1.000000   0.929710     0.910602     0.913307   \n",
       "mlp_preds        0.919171   0.929710   1.000000     0.914307     0.916343   \n",
       "lgb31_preds      0.990750   0.910602   0.914307     1.000000     0.991984   \n",
       "lgb02_preds      0.988682   0.913307   0.916343     0.991984     1.000000   \n",
       "lgb09_preds      0.978331   0.908867   0.909521     0.981891     0.982596   \n",
       "lgb10_preds      0.978298   0.913286   0.913883     0.981375     0.982052   \n",
       "lgb11A_preds     0.966819   0.915655   0.915367     0.966656     0.970858   \n",
       "lgb11D_preds     0.965873   0.913936   0.913018     0.965897     0.969933   \n",
       "lgb14_preds      0.961540   0.912870   0.911656     0.961575     0.966325   \n",
       "lgb02A_preds     0.983143   0.911443   0.913600     0.986851     0.987434   \n",
       "rnn27_preds      0.916804   0.985360   0.925010     0.914204     0.916726   \n",
       "rnn12_preds      0.920576   0.978274   0.929518     0.916939     0.920105   \n",
       "rdgv19_preds     0.568406   0.551100   0.577280     0.570034     0.567698   \n",
       "nnet16_preds     0.721926   0.720972   0.747602     0.722562     0.721808   \n",
       "\n",
       "              lgb09_preds  lgb10_preds  lgb11A_preds  lgb11D_preds  \\\n",
       "lgb27_preds      0.978331     0.978298      0.966819      0.965873   \n",
       "rnn_preds        0.908867     0.913286      0.915655      0.913936   \n",
       "mlp_preds        0.909521     0.913883      0.915367      0.913018   \n",
       "lgb31_preds      0.981891     0.981375      0.966656      0.965897   \n",
       "lgb02_preds      0.982596     0.982052      0.970858      0.969933   \n",
       "lgb09_preds      1.000000     0.990447      0.976755      0.976540   \n",
       "lgb10_preds      0.990447     1.000000      0.982841      0.982033   \n",
       "lgb11A_preds     0.976755     0.982841      1.000000      0.992400   \n",
       "lgb11D_preds     0.976540     0.982033      0.992400      1.000000   \n",
       "lgb14_preds      0.972392     0.977396      0.988703      0.989978   \n",
       "lgb02A_preds     0.988708     0.985858      0.971893      0.971846   \n",
       "rnn27_preds      0.912375     0.916436      0.918727      0.917196   \n",
       "rnn12_preds      0.915090     0.920034      0.923137      0.921322   \n",
       "rdgv19_preds     0.560909     0.562639      0.558477      0.557072   \n",
       "nnet16_preds     0.711925     0.717218      0.717910      0.714570   \n",
       "\n",
       "              lgb14_preds  lgb02A_preds  rnn27_preds  rnn12_preds  \\\n",
       "lgb27_preds      0.961540      0.983143     0.916804     0.920576   \n",
       "rnn_preds        0.912870      0.911443     0.985360     0.978274   \n",
       "mlp_preds        0.911656      0.913600     0.925010     0.929518   \n",
       "lgb31_preds      0.961575      0.986851     0.914204     0.916939   \n",
       "lgb02_preds      0.966325      0.987434     0.916726     0.920105   \n",
       "lgb09_preds      0.972392      0.988708     0.912375     0.915090   \n",
       "lgb10_preds      0.977396      0.985858     0.916436     0.920034   \n",
       "lgb11A_preds     0.988703      0.971893     0.918727     0.923137   \n",
       "lgb11D_preds     0.989978      0.971846     0.917196     0.921322   \n",
       "lgb14_preds      1.000000      0.967560     0.916160     0.920547   \n",
       "lgb02A_preds     0.967560      1.000000     0.914911     0.917453   \n",
       "rnn27_preds      0.916160      0.914911     1.000000     0.979744   \n",
       "rnn12_preds      0.920547      0.917453     0.979744     1.000000   \n",
       "rdgv19_preds     0.553930      0.564071     0.558103     0.564928   \n",
       "nnet16_preds     0.712319      0.716301     0.725452     0.735670   \n",
       "\n",
       "              rdgv19_preds  nnet16_preds  \n",
       "lgb27_preds       0.568406      0.721926  \n",
       "rnn_preds         0.551100      0.720972  \n",
       "mlp_preds         0.577280      0.747602  \n",
       "lgb31_preds       0.570034      0.722562  \n",
       "lgb02_preds       0.567698      0.721808  \n",
       "lgb09_preds       0.560909      0.711925  \n",
       "lgb10_preds       0.562639      0.717218  \n",
       "lgb11A_preds      0.558477      0.717910  \n",
       "lgb11D_preds      0.557072      0.714570  \n",
       "lgb14_preds       0.553930      0.712319  \n",
       "lgb02A_preds      0.564071      0.716301  \n",
       "rnn27_preds       0.558103      0.725452  \n",
       "rnn12_preds       0.564928      0.735670  \n",
       "rdgv19_preds      1.000000      0.784145  \n",
       "nnet16_preds      0.784145      1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test correlation\n",
    "preds_df[~preds_df['deal_probability'].isnull()][[c for c in preds_df.columns if ('_preds' in c) \\\n",
    "                                                  and ('difference' not in c) and ('sum' not in c) ]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb27_preds</th>\n",
       "      <th>rnn_preds</th>\n",
       "      <th>mlp_preds</th>\n",
       "      <th>lgb31_preds</th>\n",
       "      <th>lgb02_preds</th>\n",
       "      <th>lgb09_preds</th>\n",
       "      <th>lgb10_preds</th>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <th>lgb14_preds</th>\n",
       "      <th>lgb02A_preds</th>\n",
       "      <th>rnn27_preds</th>\n",
       "      <th>rnn12_preds</th>\n",
       "      <th>rdgv19_preds</th>\n",
       "      <th>nnet16_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lgb27_preds</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930288</td>\n",
       "      <td>0.924283</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.989502</td>\n",
       "      <td>0.979729</td>\n",
       "      <td>0.979341</td>\n",
       "      <td>0.975840</td>\n",
       "      <td>0.973725</td>\n",
       "      <td>0.970062</td>\n",
       "      <td>0.984742</td>\n",
       "      <td>0.930692</td>\n",
       "      <td>0.932951</td>\n",
       "      <td>0.571110</td>\n",
       "      <td>0.725704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn_preds</th>\n",
       "      <td>0.930288</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.939951</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.927867</td>\n",
       "      <td>0.926158</td>\n",
       "      <td>0.928367</td>\n",
       "      <td>0.927119</td>\n",
       "      <td>0.925632</td>\n",
       "      <td>0.924680</td>\n",
       "      <td>0.928496</td>\n",
       "      <td>0.988198</td>\n",
       "      <td>0.984113</td>\n",
       "      <td>0.559376</td>\n",
       "      <td>0.733735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_preds</th>\n",
       "      <td>0.924283</td>\n",
       "      <td>0.939951</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922413</td>\n",
       "      <td>0.921927</td>\n",
       "      <td>0.918064</td>\n",
       "      <td>0.920496</td>\n",
       "      <td>0.919275</td>\n",
       "      <td>0.917496</td>\n",
       "      <td>0.916323</td>\n",
       "      <td>0.922121</td>\n",
       "      <td>0.935069</td>\n",
       "      <td>0.936609</td>\n",
       "      <td>0.561935</td>\n",
       "      <td>0.740330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb31_preds</th>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.922413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993168</td>\n",
       "      <td>0.982874</td>\n",
       "      <td>0.982519</td>\n",
       "      <td>0.978877</td>\n",
       "      <td>0.976777</td>\n",
       "      <td>0.973170</td>\n",
       "      <td>0.988043</td>\n",
       "      <td>0.931468</td>\n",
       "      <td>0.932981</td>\n",
       "      <td>0.572757</td>\n",
       "      <td>0.729209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb02_preds</th>\n",
       "      <td>0.989502</td>\n",
       "      <td>0.927867</td>\n",
       "      <td>0.921927</td>\n",
       "      <td>0.993168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984427</td>\n",
       "      <td>0.983525</td>\n",
       "      <td>0.980105</td>\n",
       "      <td>0.978173</td>\n",
       "      <td>0.975031</td>\n",
       "      <td>0.989577</td>\n",
       "      <td>0.931447</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.570342</td>\n",
       "      <td>0.726748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb09_preds</th>\n",
       "      <td>0.979729</td>\n",
       "      <td>0.926158</td>\n",
       "      <td>0.918064</td>\n",
       "      <td>0.982874</td>\n",
       "      <td>0.984427</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991413</td>\n",
       "      <td>0.988267</td>\n",
       "      <td>0.986666</td>\n",
       "      <td>0.983504</td>\n",
       "      <td>0.989106</td>\n",
       "      <td>0.929748</td>\n",
       "      <td>0.931167</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>0.719919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb10_preds</th>\n",
       "      <td>0.979341</td>\n",
       "      <td>0.928367</td>\n",
       "      <td>0.920496</td>\n",
       "      <td>0.982519</td>\n",
       "      <td>0.983525</td>\n",
       "      <td>0.991413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>0.990473</td>\n",
       "      <td>0.986869</td>\n",
       "      <td>0.986654</td>\n",
       "      <td>0.931841</td>\n",
       "      <td>0.933902</td>\n",
       "      <td>0.566736</td>\n",
       "      <td>0.723894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <td>0.975840</td>\n",
       "      <td>0.927119</td>\n",
       "      <td>0.919275</td>\n",
       "      <td>0.978877</td>\n",
       "      <td>0.980105</td>\n",
       "      <td>0.988267</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993474</td>\n",
       "      <td>0.990047</td>\n",
       "      <td>0.983556</td>\n",
       "      <td>0.930518</td>\n",
       "      <td>0.932743</td>\n",
       "      <td>0.563841</td>\n",
       "      <td>0.724409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <td>0.973725</td>\n",
       "      <td>0.925632</td>\n",
       "      <td>0.917496</td>\n",
       "      <td>0.976777</td>\n",
       "      <td>0.978173</td>\n",
       "      <td>0.986666</td>\n",
       "      <td>0.990473</td>\n",
       "      <td>0.993474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991525</td>\n",
       "      <td>0.981933</td>\n",
       "      <td>0.929068</td>\n",
       "      <td>0.931133</td>\n",
       "      <td>0.561824</td>\n",
       "      <td>0.721531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb14_preds</th>\n",
       "      <td>0.970062</td>\n",
       "      <td>0.924680</td>\n",
       "      <td>0.916323</td>\n",
       "      <td>0.973170</td>\n",
       "      <td>0.975031</td>\n",
       "      <td>0.983504</td>\n",
       "      <td>0.986869</td>\n",
       "      <td>0.990047</td>\n",
       "      <td>0.991525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978724</td>\n",
       "      <td>0.928224</td>\n",
       "      <td>0.930421</td>\n",
       "      <td>0.558673</td>\n",
       "      <td>0.719337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb02A_preds</th>\n",
       "      <td>0.984742</td>\n",
       "      <td>0.928496</td>\n",
       "      <td>0.922121</td>\n",
       "      <td>0.988043</td>\n",
       "      <td>0.989577</td>\n",
       "      <td>0.989106</td>\n",
       "      <td>0.986654</td>\n",
       "      <td>0.983556</td>\n",
       "      <td>0.981933</td>\n",
       "      <td>0.978724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.932071</td>\n",
       "      <td>0.933267</td>\n",
       "      <td>0.567816</td>\n",
       "      <td>0.723825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn27_preds</th>\n",
       "      <td>0.930692</td>\n",
       "      <td>0.988198</td>\n",
       "      <td>0.935069</td>\n",
       "      <td>0.931468</td>\n",
       "      <td>0.931447</td>\n",
       "      <td>0.929748</td>\n",
       "      <td>0.931841</td>\n",
       "      <td>0.930518</td>\n",
       "      <td>0.929068</td>\n",
       "      <td>0.928224</td>\n",
       "      <td>0.932071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987051</td>\n",
       "      <td>0.562929</td>\n",
       "      <td>0.736113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn12_preds</th>\n",
       "      <td>0.932951</td>\n",
       "      <td>0.984113</td>\n",
       "      <td>0.936609</td>\n",
       "      <td>0.932981</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.931167</td>\n",
       "      <td>0.933902</td>\n",
       "      <td>0.932743</td>\n",
       "      <td>0.931133</td>\n",
       "      <td>0.930421</td>\n",
       "      <td>0.933267</td>\n",
       "      <td>0.987051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.568866</td>\n",
       "      <td>0.744002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rdgv19_preds</th>\n",
       "      <td>0.571110</td>\n",
       "      <td>0.559376</td>\n",
       "      <td>0.561935</td>\n",
       "      <td>0.572757</td>\n",
       "      <td>0.570342</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>0.566736</td>\n",
       "      <td>0.563841</td>\n",
       "      <td>0.561824</td>\n",
       "      <td>0.558673</td>\n",
       "      <td>0.567816</td>\n",
       "      <td>0.562929</td>\n",
       "      <td>0.568866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.772450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nnet16_preds</th>\n",
       "      <td>0.725704</td>\n",
       "      <td>0.733735</td>\n",
       "      <td>0.740330</td>\n",
       "      <td>0.729209</td>\n",
       "      <td>0.726748</td>\n",
       "      <td>0.719919</td>\n",
       "      <td>0.723894</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.721531</td>\n",
       "      <td>0.719337</td>\n",
       "      <td>0.723825</td>\n",
       "      <td>0.736113</td>\n",
       "      <td>0.744002</td>\n",
       "      <td>0.772450</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lgb27_preds  rnn_preds  mlp_preds  lgb31_preds  lgb02_preds  \\\n",
       "lgb27_preds      1.000000   0.930288   0.924283     0.991439     0.989502   \n",
       "rnn_preds        0.930288   1.000000   0.939951     0.927835     0.927867   \n",
       "mlp_preds        0.924283   0.939951   1.000000     0.922413     0.921927   \n",
       "lgb31_preds      0.991439   0.927835   0.922413     1.000000     0.993168   \n",
       "lgb02_preds      0.989502   0.927867   0.921927     0.993168     1.000000   \n",
       "lgb09_preds      0.979729   0.926158   0.918064     0.982874     0.984427   \n",
       "lgb10_preds      0.979341   0.928367   0.920496     0.982519     0.983525   \n",
       "lgb11A_preds     0.975840   0.927119   0.919275     0.978877     0.980105   \n",
       "lgb11D_preds     0.973725   0.925632   0.917496     0.976777     0.978173   \n",
       "lgb14_preds      0.970062   0.924680   0.916323     0.973170     0.975031   \n",
       "lgb02A_preds     0.984742   0.928496   0.922121     0.988043     0.989577   \n",
       "rnn27_preds      0.930692   0.988198   0.935069     0.931468     0.931447   \n",
       "rnn12_preds      0.932951   0.984113   0.936609     0.932981     0.933333   \n",
       "rdgv19_preds     0.571110   0.559376   0.561935     0.572757     0.570342   \n",
       "nnet16_preds     0.725704   0.733735   0.740330     0.729209     0.726748   \n",
       "\n",
       "              lgb09_preds  lgb10_preds  lgb11A_preds  lgb11D_preds  \\\n",
       "lgb27_preds      0.979729     0.979341      0.975840      0.973725   \n",
       "rnn_preds        0.926158     0.928367      0.927119      0.925632   \n",
       "mlp_preds        0.918064     0.920496      0.919275      0.917496   \n",
       "lgb31_preds      0.982874     0.982519      0.978877      0.976777   \n",
       "lgb02_preds      0.984427     0.983525      0.980105      0.978173   \n",
       "lgb09_preds      1.000000     0.991413      0.988267      0.986666   \n",
       "lgb10_preds      0.991413     1.000000      0.992340      0.990473   \n",
       "lgb11A_preds     0.988267     0.992340      1.000000      0.993474   \n",
       "lgb11D_preds     0.986666     0.990473      0.993474      1.000000   \n",
       "lgb14_preds      0.983504     0.986869      0.990047      0.991525   \n",
       "lgb02A_preds     0.989106     0.986654      0.983556      0.981933   \n",
       "rnn27_preds      0.929748     0.931841      0.930518      0.929068   \n",
       "rnn12_preds      0.931167     0.933902      0.932743      0.931133   \n",
       "rdgv19_preds     0.565333     0.566736      0.563841      0.561824   \n",
       "nnet16_preds     0.719919     0.723894      0.724409      0.721531   \n",
       "\n",
       "              lgb14_preds  lgb02A_preds  rnn27_preds  rnn12_preds  \\\n",
       "lgb27_preds      0.970062      0.984742     0.930692     0.932951   \n",
       "rnn_preds        0.924680      0.928496     0.988198     0.984113   \n",
       "mlp_preds        0.916323      0.922121     0.935069     0.936609   \n",
       "lgb31_preds      0.973170      0.988043     0.931468     0.932981   \n",
       "lgb02_preds      0.975031      0.989577     0.931447     0.933333   \n",
       "lgb09_preds      0.983504      0.989106     0.929748     0.931167   \n",
       "lgb10_preds      0.986869      0.986654     0.931841     0.933902   \n",
       "lgb11A_preds     0.990047      0.983556     0.930518     0.932743   \n",
       "lgb11D_preds     0.991525      0.981933     0.929068     0.931133   \n",
       "lgb14_preds      1.000000      0.978724     0.928224     0.930421   \n",
       "lgb02A_preds     0.978724      1.000000     0.932071     0.933267   \n",
       "rnn27_preds      0.928224      0.932071     1.000000     0.987051   \n",
       "rnn12_preds      0.930421      0.933267     0.987051     1.000000   \n",
       "rdgv19_preds     0.558673      0.567816     0.562929     0.568866   \n",
       "nnet16_preds     0.719337      0.723825     0.736113     0.744002   \n",
       "\n",
       "              rdgv19_preds  nnet16_preds  \n",
       "lgb27_preds       0.571110      0.725704  \n",
       "rnn_preds         0.559376      0.733735  \n",
       "mlp_preds         0.561935      0.740330  \n",
       "lgb31_preds       0.572757      0.729209  \n",
       "lgb02_preds       0.570342      0.726748  \n",
       "lgb09_preds       0.565333      0.719919  \n",
       "lgb10_preds       0.566736      0.723894  \n",
       "lgb11A_preds      0.563841      0.724409  \n",
       "lgb11D_preds      0.561824      0.721531  \n",
       "lgb14_preds       0.558673      0.719337  \n",
       "lgb02A_preds      0.567816      0.723825  \n",
       "rnn27_preds       0.562929      0.736113  \n",
       "rnn12_preds       0.568866      0.744002  \n",
       "rdgv19_preds      1.000000      0.772450  \n",
       "nnet16_preds      0.772450      1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train correlation\n",
    "preds_df[preds_df['deal_probability'].isnull()][[c for c in preds_df.columns if ('_preds' in c)  \\\n",
    "                                                  and ('difference' not in c) and ('sum' not in c) ]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [c for c in preds_df.columns if '_preds' in c]\n",
    "cols += [c for c in preds_df.columns if 'difference' in c]\n",
    "cols += ['price', 'max', 'min', 'avg', 'std', 'med', 'item_seq_number']\n",
    "categories = ['region', 'param_1_big', 'parent_category_name', 'category_name', \\\n",
    "              'param_2_big', 'param_3_big', 'city_big', 'user_type', 'image_top_1_big']#,\n",
    "cols += categories\n",
    "cols = list(set(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in categories:\n",
    "    preds_df[col] = LabelEncoder().fit_transform(preds_df[col].fillna(\"0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = preds_df[~preds_df['deal_probability'].isnull()]\n",
    "test_df = preds_df[preds_df['deal_probability'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators = 4000\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(train_df[cols], y, train_size=.8, random_state=12345)\n",
    "eval_set = [(train_X,train_y),(valid_X,valid_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1202739"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds.\n",
      "[100]\ttraining's rmse: 0.219287\tvalid_1's rmse: 0.219644\n",
      "[200]\ttraining's rmse: 0.212878\tvalid_1's rmse: 0.213458\n",
      "[300]\ttraining's rmse: 0.211756\tvalid_1's rmse: 0.212524\n",
      "[400]\ttraining's rmse: 0.211385\tvalid_1's rmse: 0.212329\n",
      "[500]\ttraining's rmse: 0.211153\tvalid_1's rmse: 0.212258\n",
      "[600]\ttraining's rmse: 0.21096\tvalid_1's rmse: 0.212216\n",
      "[700]\ttraining's rmse: 0.210789\tvalid_1's rmse: 0.212187\n",
      "[800]\ttraining's rmse: 0.210633\tvalid_1's rmse: 0.212167\n",
      "[900]\ttraining's rmse: 0.210489\tvalid_1's rmse: 0.212153\n",
      "[1000]\ttraining's rmse: 0.210351\tvalid_1's rmse: 0.212143\n",
      "[1100]\ttraining's rmse: 0.210221\tvalid_1's rmse: 0.212136\n",
      "[1200]\ttraining's rmse: 0.210089\tvalid_1's rmse: 0.212127\n",
      "[1300]\ttraining's rmse: 0.209961\tvalid_1's rmse: 0.212118\n",
      "[1400]\ttraining's rmse: 0.209836\tvalid_1's rmse: 0.212111\n",
      "[1500]\ttraining's rmse: 0.209713\tvalid_1's rmse: 0.212107\n",
      "[1600]\ttraining's rmse: 0.209587\tvalid_1's rmse: 0.212102\n",
      "[1700]\ttraining's rmse: 0.209466\tvalid_1's rmse: 0.212098\n",
      "[1800]\ttraining's rmse: 0.209346\tvalid_1's rmse: 0.212093\n",
      "[1900]\ttraining's rmse: 0.209226\tvalid_1's rmse: 0.212091\n",
      "[2000]\ttraining's rmse: 0.209105\tvalid_1's rmse: 0.212084\n",
      "[2100]\ttraining's rmse: 0.208987\tvalid_1's rmse: 0.212081\n",
      "[2200]\ttraining's rmse: 0.208868\tvalid_1's rmse: 0.212077\n",
      "[2300]\ttraining's rmse: 0.208753\tvalid_1's rmse: 0.212075\n",
      "[2400]\ttraining's rmse: 0.208636\tvalid_1's rmse: 0.212072\n",
      "[2500]\ttraining's rmse: 0.208523\tvalid_1's rmse: 0.212071\n",
      "[2600]\ttraining's rmse: 0.208408\tvalid_1's rmse: 0.212068\n",
      "[2700]\ttraining's rmse: 0.208292\tvalid_1's rmse: 0.212067\n",
      "[2800]\ttraining's rmse: 0.208177\tvalid_1's rmse: 0.212064\n",
      "[2900]\ttraining's rmse: 0.208065\tvalid_1's rmse: 0.212063\n",
      "[3000]\ttraining's rmse: 0.207954\tvalid_1's rmse: 0.212062\n",
      "[3100]\ttraining's rmse: 0.207843\tvalid_1's rmse: 0.212061\n",
      "[3200]\ttraining's rmse: 0.20773\tvalid_1's rmse: 0.212058\n",
      "[3300]\ttraining's rmse: 0.207616\tvalid_1's rmse: 0.212057\n",
      "Early stopping, best iteration is:\n",
      "[3230]\ttraining's rmse: 0.207695\tvalid_1's rmse: 0.212056\n",
      "CPU times: user 1h 13min 11s, sys: 42.2 s, total: 1h 13min 53s\n",
      "Wall time: 10min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gc.collect()\n",
    "clf = LGBMRegressor(n_estimators=n_estimators, \n",
    "                    max_depth=-1, \n",
    "                    feature_fraction= 0.4,\n",
    "                    num_leaves=32, \n",
    "                    learning_rate=.01)#, device='gpu')\n",
    "clf.fit(train_X, train_y, early_stopping_rounds=80, \n",
    "        eval_set=eval_set, eval_metric='rmse', verbose=100, \n",
    "        categorical_feature=categories)\n",
    "# [3230]\ttraining's rmse: 0.207695\tvalid_1's rmse: 0.212056"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6358, 'city_big'),\n",
       " (4767, 'param_1_big'),\n",
       " (3833, 'region'),\n",
       " (3594, 'category_name'),\n",
       " (2598, 'image_top_1_big'),\n",
       " (2209, 'nnet16_preds'),\n",
       " (1693, 'difference_rnn_preds__rnn27_preds'),\n",
       " (1462, 'difference_rnn_preds__rnn12_preds'),\n",
       " (1363, 'param_3_big'),\n",
       " (1323, 'rdgv19_preds'),\n",
       " (1304, 'lgb14_preds'),\n",
       " (1295, 'item_seq_number'),\n",
       " (1292, 'price'),\n",
       " (1266, 'difference_rnn27_preds__rnn12_preds'),\n",
       " (1205, 'difference_lgb11D_preds__lgb14_preds'),\n",
       " (1191, 'difference_lgb10_preds__lgb14_preds'),\n",
       " (1167, 'difference_lgb09_preds__lgb02A_preds'),\n",
       " (1148, 'difference_lgb10_preds__lgb02A_preds'),\n",
       " (1115, 'difference_lgb31_preds__lgb14_preds'),\n",
       " (1114, 'difference_rnn_preds__mlp_preds'),\n",
       " (1107, 'difference_lgb31_preds__lgb09_preds'),\n",
       " (1092, 'sums_lgb14_preds__rnn27_preds'),\n",
       " (1076, 'difference_lgb14_preds__lgb02A_preds'),\n",
       " (1070, 'difference_lgb31_preds__lgb02A_preds'),\n",
       " (1067, 'difference_lgb09_preds__lgb10_preds'),\n",
       " (1039, 'sums_lgb14_preds__rnn12_preds'),\n",
       " (1009, 'difference_mlp_preds__rnn12_preds'),\n",
       " (997, 'difference_mlp_preds__rnn27_preds'),\n",
       " (982, 'difference_lgb31_preds__lgb11D_preds'),\n",
       " (981, 'difference_lgb09_preds__lgb14_preds'),\n",
       " (981, 'difference_mlp_preds__lgb31_preds'),\n",
       " (978, 'difference_lgb31_preds__lgb10_preds'),\n",
       " (968, 'difference_lgb11D_preds__lgb02A_preds'),\n",
       " (950, 'difference_lgb10_preds__lgb11D_preds'),\n",
       " (925, 'sums_mlp_preds__lgb14_preds'),\n",
       " (918, 'difference_lgb09_preds__lgb11D_preds'),\n",
       " (918, 'param_2_big'),\n",
       " (900, 'mlp_preds'),\n",
       " (863, 'min'),\n",
       " (860, 'difference_mlp_preds__lgb11D_preds'),\n",
       " (857, 'difference_mlp_preds__lgb02A_preds'),\n",
       " (848, 'difference_mlp_preds__lgb14_preds'),\n",
       " (809, 'difference_rnn_preds__lgb31_preds'),\n",
       " (807, 'difference_rnn_preds__lgb14_preds'),\n",
       " (790, 'difference_lgb14_preds__rnn12_preds'),\n",
       " (789, 'difference_mlp_preds__lgb10_preds'),\n",
       " (769, 'difference_lgb02A_preds__rnn12_preds'),\n",
       " (767, 'difference_mlp_preds__lgb09_preds'),\n",
       " (758, 'difference_rnn_preds__lgb11D_preds'),\n",
       " (750, 'difference_lgb14_preds__rnn27_preds'),\n",
       " (745, 'difference_lgb31_preds__rnn27_preds'),\n",
       " (724, 'std'),\n",
       " (716, 'difference_lgb11D_preds__rnn27_preds'),\n",
       " (714, 'difference_lgb11D_preds__rnn12_preds'),\n",
       " (714, 'difference_lgb31_preds__rnn12_preds'),\n",
       " (708, 'difference_lgb10_preds__rnn27_preds'),\n",
       " (705, 'difference_lgb09_preds__rnn12_preds'),\n",
       " (681, 'sums_lgb11D_preds__lgb14_preds'),\n",
       " (676, 'difference_rnn_preds__lgb09_preds'),\n",
       " (670, 'difference_lgb10_preds__rnn12_preds'),\n",
       " (666, 'difference_lgb09_preds__rnn27_preds'),\n",
       " (660, 'lgb27_preds'),\n",
       " (655, 'difference_lgb02A_preds__rnn27_preds'),\n",
       " (637, 'difference_rnn_preds__lgb10_preds'),\n",
       " (623, 'difference_rnn_preds__lgb02A_preds'),\n",
       " (600, 'rnn27_preds'),\n",
       " (597, 'rnn12_preds'),\n",
       " (563, 'lgb11A_preds'),\n",
       " (555, 'sums_mlp_preds__rnn12_preds'),\n",
       " (555, 'sums_mlp_preds__rnn27_preds'),\n",
       " (524, 'sums_mlp_preds__lgb11D_preds'),\n",
       " (515, 'rnn_preds'),\n",
       " (495, 'sums_lgb11D_preds__rnn27_preds'),\n",
       " (493, 'sums_rnn27_preds__rnn12_preds'),\n",
       " (481, 'sums_lgb11D_preds__rnn12_preds'),\n",
       " (478, 'lgb02_preds'),\n",
       " (463, 'parent_category_name'),\n",
       " (462, 'lgb11D_preds'),\n",
       " (461, 'sums_rnn_preds__mlp_preds'),\n",
       " (436, 'sums_mlp_preds__lgb09_preds'),\n",
       " (428, 'sums_mlp_preds__lgb10_preds'),\n",
       " (427, 'sums_rnn_preds__lgb14_preds'),\n",
       " (422, 'sums_mlp_preds__lgb31_preds'),\n",
       " (416, 'sums_rnn_preds__rnn27_preds'),\n",
       " (407, 'sums_mlp_preds__lgb02A_preds'),\n",
       " (405, 'sums_rnn_preds__rnn12_preds'),\n",
       " (388, 'max'),\n",
       " (387, 'sums_lgb09_preds__lgb14_preds'),\n",
       " (380, 'lgb31_preds'),\n",
       " (375, 'lgb02A_preds'),\n",
       " (361, 'sums_lgb10_preds__lgb14_preds'),\n",
       " (357, 'lgb09_preds'),\n",
       " (350, 'sums_lgb02A_preds__rnn12_preds'),\n",
       " (345, 'sums_lgb31_preds__rnn27_preds'),\n",
       " (340, 'sums_lgb10_preds__rnn12_preds'),\n",
       " (339, 'lgb10_preds'),\n",
       " (330, 'sums_lgb14_preds__lgb02A_preds'),\n",
       " (327, 'sums_rnn_preds__lgb11D_preds'),\n",
       " (324, 'sums_lgb09_preds__rnn27_preds'),\n",
       " (321, 'sums_rnn_preds__lgb31_preds'),\n",
       " (317, 'sums_lgb31_preds__rnn12_preds'),\n",
       " (316, 'sums_lgb09_preds__rnn12_preds'),\n",
       " (310, 'sums_rnn_preds__lgb02A_preds'),\n",
       " (309, 'sums_rnn_preds__lgb10_preds'),\n",
       " (307, 'sums_lgb31_preds__lgb02A_preds'),\n",
       " (304, 'sums_lgb09_preds__lgb11D_preds'),\n",
       " (301, 'sums_lgb10_preds__rnn27_preds'),\n",
       " (299, 'sums_lgb09_preds__lgb10_preds'),\n",
       " (290, 'sums_lgb31_preds__lgb11D_preds'),\n",
       " (288, 'sums_lgb31_preds__lgb14_preds'),\n",
       " (288, 'sums_lgb02A_preds__rnn27_preds'),\n",
       " (287, 'sums_lgb10_preds__lgb11D_preds'),\n",
       " (286, 'sums_rnn_preds__lgb09_preds'),\n",
       " (266, 'sums_lgb31_preds__lgb09_preds'),\n",
       " (260, 'sums_lgb09_preds__lgb02A_preds'),\n",
       " (257, 'med'),\n",
       " (251, 'avg'),\n",
       " (249, 'sums_lgb31_preds__lgb10_preds'),\n",
       " (249, 'sums_lgb11D_preds__lgb02A_preds'),\n",
       " (239, 'sums_lgb10_preds__lgb02A_preds'),\n",
       " (134, 'user_type')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(clf.feature_importances_, train_X.columns ),key=lambda x: -x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1503424"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = 3000\n",
    "train_X = train_df[cols]\n",
    "train_y = y\n",
    "eval_set = [(train_X,train_y)]\n",
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds.\n",
      "[100]\ttraining's rmse: 0.219365\n",
      "[200]\ttraining's rmse: 0.213\n",
      "[300]\ttraining's rmse: 0.2119\n",
      "[400]\ttraining's rmse: 0.211555\n",
      "[500]\ttraining's rmse: 0.211345\n",
      "[600]\ttraining's rmse: 0.211176\n",
      "[700]\ttraining's rmse: 0.21103\n",
      "[800]\ttraining's rmse: 0.210898\n",
      "[900]\ttraining's rmse: 0.210776\n",
      "[1000]\ttraining's rmse: 0.210658\n",
      "[1100]\ttraining's rmse: 0.210545\n",
      "[1200]\ttraining's rmse: 0.210436\n",
      "[1300]\ttraining's rmse: 0.210329\n",
      "[1400]\ttraining's rmse: 0.21022\n",
      "[1500]\ttraining's rmse: 0.210117\n",
      "[1600]\ttraining's rmse: 0.210012\n",
      "[1700]\ttraining's rmse: 0.209908\n",
      "[1800]\ttraining's rmse: 0.209805\n",
      "[1900]\ttraining's rmse: 0.209705\n",
      "[2000]\ttraining's rmse: 0.209603\n",
      "[2100]\ttraining's rmse: 0.209504\n",
      "[2200]\ttraining's rmse: 0.209404\n",
      "[2300]\ttraining's rmse: 0.209304\n",
      "[2400]\ttraining's rmse: 0.209205\n",
      "[2500]\ttraining's rmse: 0.209106\n",
      "[2600]\ttraining's rmse: 0.209009\n",
      "[2700]\ttraining's rmse: 0.208913\n",
      "[2800]\ttraining's rmse: 0.208817\n",
      "[2900]\ttraining's rmse: 0.208723\n",
      "[3000]\ttraining's rmse: 0.20863\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\ttraining's rmse: 0.20863\n",
      "Training until validation scores don't improve for 80 rounds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    612\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m                                        callbacks=callbacks)\n\u001b[0m\u001b[1;32m    615\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    467\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    199\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1522\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1523\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1524\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1525\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_predls = []\n",
    "for i in range(3):\n",
    "    clf = LGBMRegressor(n_estimators=n_estimators, \n",
    "                    max_depth=-1, \n",
    "                    feature_fraction= 0.4,\n",
    "                    num_leaves=32, \n",
    "                    seed = i, \n",
    "                    learning_rate=.01)#, device='gpu')\n",
    "    clf.fit(train_X, train_y, early_stopping_rounds=80, \n",
    "        eval_set=eval_set, eval_metric='rmse', verbose=100, \n",
    "        categorical_feature=categories)\n",
    "    y_predls.append(clf.predict(test_df[cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>deal_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1503424</th>\n",
       "      <td>6544e41a8817</td>\n",
       "      <td>0.381307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503425</th>\n",
       "      <td>65b9484d670f</td>\n",
       "      <td>0.123870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503426</th>\n",
       "      <td>8bab230b2ecd</td>\n",
       "      <td>0.118797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503427</th>\n",
       "      <td>8e348601fefc</td>\n",
       "      <td>0.091458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503428</th>\n",
       "      <td>8bd2fe400b89</td>\n",
       "      <td>0.139507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              item_id  deal_probability\n",
       "1503424  6544e41a8817          0.381307\n",
       "1503425  65b9484d670f          0.123870\n",
       "1503426  8bab230b2ecd          0.118797\n",
       "1503427  8e348601fefc          0.091458\n",
       "1503428  8bd2fe400b89          0.139507"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['deal_probability'] = sum(y_predls)/len(y_predls)\n",
    "test_df['deal_probability'] = np.clip(test_df['deal_probability'], .0001, .9999)\n",
    "test_df[['item_id', 'deal_probability']].to_csv('../lgbbsub_1606CL2.csv.gz', compression='gzip', index=False, header=True)\n",
    "test_df[['item_id', 'deal_probability']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
