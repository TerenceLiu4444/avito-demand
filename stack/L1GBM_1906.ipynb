{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics#, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "import sys\n",
    "import warnings\n",
    "import itertools\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "path = \"/home/darragh/avito/data/\"\n",
    "#path = '/Users/dhanley2/Documents/avito/data/'\n",
    "#path = '/home/ubuntu/avito/data/'\n",
    "#data_path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb25 = pd.read_csv('../lgCV_2505.csv.gz', compression='gzip')\n",
    "lgb02A = pd.read_csv(path+'../sub/lgCV_0206A.csv.gz', compression='gzip')\n",
    "lgb09 = pd.read_csv(path+'../sub/lgCV_0906.csv.gz', compression='gzip')\n",
    "lgb10 = pd.read_csv(path+'../sub/lgCV_1006.csv.gz', compression='gzip')\n",
    "lgb11A= pd.read_csv(path+'../sub/lgCV_1106A.csv.gz', compression='gzip')\n",
    "lgb11D= pd.read_csv(path+'../sub/lgCV_1106D.csv.gz', compression='gzip')\n",
    "lgb14= pd.read_csv(path+'../sub/lgCV_1406.csv.gz', compression='gzip')\n",
    "lgb14A= pd.read_csv(path+'../sub/lgCV_1406A.csv.gz', compression='gzip')\n",
    "lgb27 = pd.read_csv(path+'../sub/lgCV_2705B.csv.gz', compression='gzip')\n",
    "lgb31 = pd.read_csv(path+'../sub/lgCV_3105.csv.gz', compression='gzip')\n",
    "lgb02 = pd.read_csv(path+'../sub/lgCV_0206.csv.gz', compression='gzip')\n",
    "lgb17 = pd.read_csv(path+'../sub/lgCV_1706.csv.gz', compression='gzip')\n",
    "lgb19 = pd.read_csv(path+'../sub/lgCV_1906.csv.gz', compression='gzip')\n",
    "rnn =   pd.read_csv(path+'../sub/rnnCV_2805.csv.gz', compression='gzip')\n",
    "rnn27 = pd.read_csv(path+'../sub/rnnCV_2705A.csv.gz', compression='gzip')\n",
    "rnn12 = pd.read_csv(path+'../sub/rnnCV_1206.csv.gz', compression='gzip')\n",
    "mlp =   pd.read_csv(path+'../sub/mlpCV_2505.csv.gz', compression='gzip')\n",
    "rdgv19 =   pd.read_csv(path+'../sub/rdgv19CV_1606.csv.gz', compression='gzip')\n",
    "truth = pd.read_csv(path+'train.csv.zip', compression='zip', parse_dates = [\"activation_date\"])\n",
    "y =     truth['deal_probability'].values\n",
    "truth.drop('deal_probability', 1)\n",
    "test =  pd.read_csv(path+'test.csv.zip', compression='zip', parse_dates = [\"activation_date\"])\n",
    "test['deal_probability']=float('NAN') \n",
    "truth = pd.concat([truth,test[truth.columns]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb14['deal_probability'] =  ( lgb14['deal_probability'].values + lgb14A['deal_probability'].values)*0.5\n",
    "lgb17['deal_probability'] =  ( lgb17['deal_probability'].values + lgb19['deal_probability'].values)*0.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_cts = truth['image_top_1'].value_counts().reset_index()\n",
    "#truth['image_top_big'] = 'lo_count'\n",
    "#big_top_1 = img_cts[img_cts['image_top_1']>5000]['index'].tolist()\n",
    "#idx = truth['image_top_1'].isin(big_top_1)\n",
    "#truth['image_top_big'][idx] = truth['image_top_1'][idx].astype(str).values\n",
    "\n",
    "def keep_big(df, col, cutoff):\n",
    "    cts = df[col].value_counts().reset_index()\n",
    "    df[col+'_big'] = 'lo_count'\n",
    "    big = cts[cts[col]>cutoff]['index'].tolist()\n",
    "    idx = df[col].isin(big)\n",
    "    df[col+'_big'][idx] = df[col][idx].astype(str).values\n",
    "    return df[col+'_big'].values\n",
    "truth['image_top_1_big'] = keep_big(truth, 'image_top_1', 5000)\n",
    "truth['param_1_big'] = keep_big(truth, 'param_1', 5000)\n",
    "truth['param_2_big'] = keep_big(truth, 'param_2', 5000)\n",
    "truth['param_3_big'] = keep_big(truth, 'param_3', 5000)\n",
    "truth['city_big'] = keep_big(truth, 'city', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_top_1_big</th>\n",
       "      <th>param_1_big</th>\n",
       "      <th>param_2_big</th>\n",
       "      <th>param_3_big</th>\n",
       "      <th>city_big</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lo_count</td>\n",
       "      <td>Постельные принадлежности</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>Екатеринбург</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lo_count</td>\n",
       "      <td>Другое</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>Самара</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lo_count</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>Ростов-на-Дону</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>796.0</td>\n",
       "      <td>Автомобильные кресла</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>Набережные Челны</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2264.0</td>\n",
       "      <td>С пробегом</td>\n",
       "      <td>ВАЗ (LADA)</td>\n",
       "      <td>lo_count</td>\n",
       "      <td>Волгоград</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_top_1_big                param_1_big param_2_big param_3_big  \\\n",
       "0        lo_count  Постельные принадлежности    lo_count    lo_count   \n",
       "1        lo_count                     Другое    lo_count    lo_count   \n",
       "2        lo_count                   lo_count    lo_count    lo_count   \n",
       "3           796.0       Автомобильные кресла    lo_count    lo_count   \n",
       "4          2264.0                 С пробегом  ВАЗ (LADA)    lo_count   \n",
       "\n",
       "           city_big  \n",
       "0      Екатеринбург  \n",
       "1            Самара  \n",
       "2    Ростов-на-Дону  \n",
       "3  Набережные Челны  \n",
       "4         Волгоград  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth[[c for c in truth.columns if 'big' in c]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb25.rename(columns={'deal_probability': 'lgb25_preds' }, inplace=True)\n",
    "lgb31.rename(columns={'deal_probability': 'lgb31_preds' }, inplace=True)\n",
    "lgb27.rename(columns={'deal_probability': 'lgb27_preds' }, inplace=True)\n",
    "lgb02.rename(columns={'deal_probability': 'lgb02_preds' }, inplace=True)\n",
    "lgb09.rename(columns={'deal_probability': 'lgb09_preds' }, inplace=True)\n",
    "lgb10.rename(columns={'deal_probability': 'lgb10_preds' }, inplace=True)\n",
    "lgb11D.rename(columns={'deal_probability': 'lgb11D_preds' }, inplace=True)\n",
    "lgb11A.rename(columns={'deal_probability': 'lgb11A_preds' }, inplace=True)\n",
    "lgb14.rename(columns={'deal_probability': 'lgb14_preds' }, inplace=True)\n",
    "lgb17.rename(columns={'deal_probability': 'lgb17_preds' }, inplace=True)\n",
    "#lgb19.rename(columns={'deal_probability': 'lgb19_preds' }, inplace=True)\n",
    "lgb02A.rename(columns={'deal_probability': 'lgb02A_preds' }, inplace=True)\n",
    "rnn27.rename(columns={'deal_probability': 'rnn27_preds' }, inplace=True)\n",
    "rnn12.rename(columns={'deal_probability': 'rnn12_preds' }, inplace=True)\n",
    "rdgv19.rename(columns={'deal_probability': 'rdgv19_preds' }, inplace=True)\n",
    "mlp.rename(columns={'deal_probability': 'mlp_preds' }, inplace=True)\n",
    "preds_df = lgb27.merge(rnn, on='item_id')\\\n",
    "                .merge(mlp, on='item_id')\\\n",
    "                .merge(lgb31, on='item_id')\\\n",
    "                .merge(lgb02, on='item_id')\\\n",
    "                .merge(lgb09, on='item_id')\\\n",
    "                .merge(lgb10, on='item_id')\\\n",
    "                .merge(lgb11A, on='item_id')\\\n",
    "                .merge(lgb11D, on='item_id')\\\n",
    "                .merge(lgb14, on='item_id')\\\n",
    "                .merge(lgb17, on='item_id')\\\n",
    "                .merge(lgb02A, on='item_id')\\\n",
    "                .merge(rnn27, on='item_id')\\\n",
    "                .merge(rnn12, on='item_id')\\\n",
    "                .merge(rdgv19, on='item_id')\\\n",
    "                .merge(truth, on='item_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rnn_preds',\n",
       " 'mlp_preds',\n",
       " 'lgb31_preds',\n",
       " 'lgb09_preds',\n",
       " 'lgb10_preds',\n",
       " 'lgb11D_preds',\n",
       " 'lgb14_preds',\n",
       " 'lgb17_preds',\n",
       " 'lgb02A_preds',\n",
       " 'rnn27_preds',\n",
       " 'rnn12_preds']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cols = [col for col in preds_df.columns if ('_preds' in col) \\\n",
    "             and ('lgb27' not in col) and ('lgb02_' not in col) and ('lgb11A_' not in col) \\\n",
    "             and ('rdgv19_' not in col)]\n",
    "\n",
    "preds_df['preds_sum'] = preds_df[pred_cols].sum(axis=1)\n",
    "pred_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df['price'].fillna(-1,inplace=True)\n",
    "preds_df['max'] = np.max(np.array([preds_df[col] for col in pred_cols]),axis=0)\n",
    "preds_df['min'] = np.min(np.array([preds_df[col] for col in pred_cols]),axis=0)\n",
    "preds_df['avg'] = np.mean(np.array([preds_df[col] for col in pred_cols]),axis=0)\n",
    "preds_df['med'] = np.median(np.array([preds_df[col] for col in pred_cols]),axis=0)\n",
    "preds_df['std'] = np.std(np.array([preds_df[col] for col in pred_cols]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference_rnn_preds__mlp_preds\n",
      "difference_rnn_preds__lgb31_preds\n",
      "difference_rnn_preds__lgb09_preds\n",
      "difference_rnn_preds__lgb10_preds\n",
      "difference_rnn_preds__lgb11D_preds\n",
      "difference_rnn_preds__lgb14_preds\n",
      "difference_rnn_preds__lgb17_preds\n",
      "difference_rnn_preds__lgb02A_preds\n",
      "difference_rnn_preds__rnn27_preds\n",
      "difference_rnn_preds__rnn12_preds\n",
      "difference_mlp_preds__lgb31_preds\n",
      "difference_mlp_preds__lgb09_preds\n",
      "difference_mlp_preds__lgb10_preds\n",
      "difference_mlp_preds__lgb11D_preds\n",
      "difference_mlp_preds__lgb14_preds\n",
      "difference_mlp_preds__lgb17_preds\n",
      "difference_mlp_preds__lgb02A_preds\n",
      "difference_mlp_preds__rnn27_preds\n",
      "difference_mlp_preds__rnn12_preds\n",
      "difference_lgb31_preds__lgb09_preds\n",
      "difference_lgb31_preds__lgb10_preds\n",
      "difference_lgb31_preds__lgb11D_preds\n",
      "difference_lgb31_preds__lgb14_preds\n",
      "difference_lgb31_preds__lgb17_preds\n",
      "difference_lgb31_preds__lgb02A_preds\n",
      "difference_lgb31_preds__rnn27_preds\n",
      "difference_lgb31_preds__rnn12_preds\n",
      "difference_lgb09_preds__lgb10_preds\n",
      "difference_lgb09_preds__lgb11D_preds\n",
      "difference_lgb09_preds__lgb14_preds\n",
      "difference_lgb09_preds__lgb17_preds\n",
      "difference_lgb09_preds__lgb02A_preds\n",
      "difference_lgb09_preds__rnn27_preds\n",
      "difference_lgb09_preds__rnn12_preds\n",
      "difference_lgb10_preds__lgb11D_preds\n",
      "difference_lgb10_preds__lgb14_preds\n",
      "difference_lgb10_preds__lgb17_preds\n",
      "difference_lgb10_preds__lgb02A_preds\n",
      "difference_lgb10_preds__rnn27_preds\n",
      "difference_lgb10_preds__rnn12_preds\n",
      "difference_lgb11D_preds__lgb14_preds\n",
      "difference_lgb11D_preds__lgb17_preds\n",
      "difference_lgb11D_preds__lgb02A_preds\n",
      "difference_lgb11D_preds__rnn27_preds\n",
      "difference_lgb11D_preds__rnn12_preds\n",
      "difference_lgb14_preds__lgb17_preds\n",
      "difference_lgb14_preds__lgb02A_preds\n",
      "difference_lgb14_preds__rnn27_preds\n",
      "difference_lgb14_preds__rnn12_preds\n",
      "difference_lgb17_preds__lgb02A_preds\n",
      "difference_lgb17_preds__rnn27_preds\n",
      "difference_lgb17_preds__rnn12_preds\n",
      "difference_lgb02A_preds__rnn27_preds\n",
      "difference_lgb02A_preds__rnn12_preds\n",
      "difference_rnn27_preds__rnn12_preds\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for p1, p2 in itertools.combinations(pred_cols, 2):\n",
    "    print('difference_%s__%s'%(p1,p2))\n",
    "    preds_df['difference_%s__%s'%(p1,p2)] = preds_df[p2] - preds_df[p1]\n",
    "    preds_df['sums_%s__%s'%(p1,p2)] = preds_df[p2] + preds_df[p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>lgb27_preds</th>\n",
       "      <th>rnn_preds</th>\n",
       "      <th>mlp_preds</th>\n",
       "      <th>lgb31_preds</th>\n",
       "      <th>lgb02_preds</th>\n",
       "      <th>lgb09_preds</th>\n",
       "      <th>lgb10_preds</th>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <th>...</th>\n",
       "      <th>difference_lgb17_preds__rnn27_preds</th>\n",
       "      <th>sums_lgb17_preds__rnn27_preds</th>\n",
       "      <th>difference_lgb17_preds__rnn12_preds</th>\n",
       "      <th>sums_lgb17_preds__rnn12_preds</th>\n",
       "      <th>difference_lgb02A_preds__rnn27_preds</th>\n",
       "      <th>sums_lgb02A_preds__rnn27_preds</th>\n",
       "      <th>difference_lgb02A_preds__rnn12_preds</th>\n",
       "      <th>sums_lgb02A_preds__rnn12_preds</th>\n",
       "      <th>difference_rnn27_preds__rnn12_preds</th>\n",
       "      <th>sums_rnn27_preds__rnn12_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b912c3c6a6ad</td>\n",
       "      <td>0.091656</td>\n",
       "      <td>0.069891</td>\n",
       "      <td>0.091223</td>\n",
       "      <td>0.083219</td>\n",
       "      <td>0.090855</td>\n",
       "      <td>0.109624</td>\n",
       "      <td>0.107764</td>\n",
       "      <td>0.095101</td>\n",
       "      <td>0.092921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029405</td>\n",
       "      <td>0.166066</td>\n",
       "      <td>-0.020858</td>\n",
       "      <td>0.174613</td>\n",
       "      <td>-0.041287</td>\n",
       "      <td>0.177948</td>\n",
       "      <td>-0.032740</td>\n",
       "      <td>0.186494</td>\n",
       "      <td>0.008546</td>\n",
       "      <td>0.145208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dac0150717d</td>\n",
       "      <td>0.147801</td>\n",
       "      <td>0.075968</td>\n",
       "      <td>0.211844</td>\n",
       "      <td>0.157973</td>\n",
       "      <td>0.119609</td>\n",
       "      <td>0.157466</td>\n",
       "      <td>0.161107</td>\n",
       "      <td>0.140269</td>\n",
       "      <td>0.144395</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042692</td>\n",
       "      <td>0.183969</td>\n",
       "      <td>-0.024771</td>\n",
       "      <td>0.201890</td>\n",
       "      <td>-0.089406</td>\n",
       "      <td>0.230683</td>\n",
       "      <td>-0.071485</td>\n",
       "      <td>0.248604</td>\n",
       "      <td>0.017921</td>\n",
       "      <td>0.159198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba83aefab5dc</td>\n",
       "      <td>0.186261</td>\n",
       "      <td>0.167167</td>\n",
       "      <td>0.236579</td>\n",
       "      <td>0.227048</td>\n",
       "      <td>0.258980</td>\n",
       "      <td>0.245236</td>\n",
       "      <td>0.219107</td>\n",
       "      <td>0.234076</td>\n",
       "      <td>0.222678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058110</td>\n",
       "      <td>0.381959</td>\n",
       "      <td>-0.072009</td>\n",
       "      <td>0.368060</td>\n",
       "      <td>-0.079412</td>\n",
       "      <td>0.403260</td>\n",
       "      <td>-0.093311</td>\n",
       "      <td>0.389361</td>\n",
       "      <td>-0.013899</td>\n",
       "      <td>0.309950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02996f1dd2ea</td>\n",
       "      <td>0.241699</td>\n",
       "      <td>0.260876</td>\n",
       "      <td>0.383699</td>\n",
       "      <td>0.231447</td>\n",
       "      <td>0.284130</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>0.255519</td>\n",
       "      <td>0.241802</td>\n",
       "      <td>0.271355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>0.553032</td>\n",
       "      <td>-0.025905</td>\n",
       "      <td>0.522551</td>\n",
       "      <td>-0.057652</td>\n",
       "      <td>0.615259</td>\n",
       "      <td>-0.088132</td>\n",
       "      <td>0.584779</td>\n",
       "      <td>-0.030481</td>\n",
       "      <td>0.527127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c90be56d2ab</td>\n",
       "      <td>0.407423</td>\n",
       "      <td>0.431520</td>\n",
       "      <td>0.420657</td>\n",
       "      <td>0.412563</td>\n",
       "      <td>0.430581</td>\n",
       "      <td>0.511145</td>\n",
       "      <td>0.511676</td>\n",
       "      <td>0.504849</td>\n",
       "      <td>0.503961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135966</td>\n",
       "      <td>0.836535</td>\n",
       "      <td>-0.064907</td>\n",
       "      <td>0.907594</td>\n",
       "      <td>-0.071704</td>\n",
       "      <td>0.772273</td>\n",
       "      <td>-0.000645</td>\n",
       "      <td>0.843332</td>\n",
       "      <td>0.071059</td>\n",
       "      <td>0.771628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id  lgb27_preds  rnn_preds  mlp_preds  lgb31_preds  lgb02_preds  \\\n",
       "0  b912c3c6a6ad     0.091656   0.069891   0.091223     0.083219     0.090855   \n",
       "1  2dac0150717d     0.147801   0.075968   0.211844     0.157973     0.119609   \n",
       "2  ba83aefab5dc     0.186261   0.167167   0.236579     0.227048     0.258980   \n",
       "3  02996f1dd2ea     0.241699   0.260876   0.383699     0.231447     0.284130   \n",
       "4  7c90be56d2ab     0.407423   0.431520   0.420657     0.412563     0.430581   \n",
       "\n",
       "   lgb09_preds  lgb10_preds  lgb11A_preds  lgb11D_preds  \\\n",
       "0     0.109624     0.107764      0.095101      0.092921   \n",
       "1     0.157466     0.161107      0.140269      0.144395   \n",
       "2     0.245236     0.219107      0.234076      0.222678   \n",
       "3     0.289101     0.255519      0.241802      0.271355   \n",
       "4     0.511145     0.511676      0.504849      0.503961   \n",
       "\n",
       "               ...               difference_lgb17_preds__rnn27_preds  \\\n",
       "0              ...                                         -0.029405   \n",
       "1              ...                                         -0.042692   \n",
       "2              ...                                         -0.058110   \n",
       "3              ...                                          0.004576   \n",
       "4              ...                                         -0.135966   \n",
       "\n",
       "   sums_lgb17_preds__rnn27_preds  difference_lgb17_preds__rnn12_preds  \\\n",
       "0                       0.166066                            -0.020858   \n",
       "1                       0.183969                            -0.024771   \n",
       "2                       0.381959                            -0.072009   \n",
       "3                       0.553032                            -0.025905   \n",
       "4                       0.836535                            -0.064907   \n",
       "\n",
       "   sums_lgb17_preds__rnn12_preds  difference_lgb02A_preds__rnn27_preds  \\\n",
       "0                       0.174613                             -0.041287   \n",
       "1                       0.201890                             -0.089406   \n",
       "2                       0.368060                             -0.079412   \n",
       "3                       0.522551                             -0.057652   \n",
       "4                       0.907594                             -0.071704   \n",
       "\n",
       "   sums_lgb02A_preds__rnn27_preds  difference_lgb02A_preds__rnn12_preds  \\\n",
       "0                        0.177948                             -0.032740   \n",
       "1                        0.230683                             -0.071485   \n",
       "2                        0.403260                             -0.093311   \n",
       "3                        0.615259                             -0.088132   \n",
       "4                        0.772273                             -0.000645   \n",
       "\n",
       "  sums_lgb02A_preds__rnn12_preds difference_rnn27_preds__rnn12_preds  \\\n",
       "0                       0.186494                            0.008546   \n",
       "1                       0.248604                            0.017921   \n",
       "2                       0.389361                           -0.013899   \n",
       "3                       0.584779                           -0.030481   \n",
       "4                       0.843332                            0.071059   \n",
       "\n",
       "  sums_rnn27_preds__rnn12_preds  \n",
       "0                      0.145208  \n",
       "1                      0.159198  \n",
       "2                      0.309950  \n",
       "3                      0.527127  \n",
       "4                      0.771628  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lgb27_preds',\n",
       " 'rnn_preds',\n",
       " 'mlp_preds',\n",
       " 'lgb31_preds',\n",
       " 'lgb02_preds',\n",
       " 'lgb09_preds',\n",
       " 'lgb10_preds',\n",
       " 'lgb11A_preds',\n",
       " 'lgb11D_preds',\n",
       " 'lgb14_preds',\n",
       " 'lgb17_preds',\n",
       " 'lgb02A_preds',\n",
       " 'rnn27_preds',\n",
       " 'rnn12_preds',\n",
       " 'rdgv19_preds']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cols = [col for col in preds_df.columns if ('preds' in col) \n",
    "             and ('difference' not in col) \n",
    "             and ('sum' not in col)]\n",
    "pred_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True     1503424\n",
      "False     508438\n",
      "Name: deal_probability, dtype: int64\n",
      "RMSE lgb27_preds:  0.21681527582821059\n",
      "RMSE rnn_preds:  0.21771476573780568\n",
      "RMSE mlp_preds:  0.2187544351068867\n",
      "RMSE lgb31_preds:  0.21681135578306754\n",
      "RMSE lgb02_preds:  0.21625386267187377\n",
      "RMSE lgb09_preds:  0.21581543265040168\n",
      "RMSE lgb10_preds:  0.21533498019117664\n",
      "RMSE lgb11A_preds:  0.21403812331071156\n",
      "RMSE lgb11D_preds:  0.21392147604708842\n",
      "RMSE lgb14_preds:  0.21329729304260686\n",
      "RMSE lgb17_preds:  0.21311496843894262\n",
      "RMSE lgb02A_preds:  0.21627136604335995\n",
      "RMSE rnn27_preds:  0.21698040871120608\n",
      "RMSE rnn12_preds:  0.2167114508342396\n",
      "RMSE rdgv19_preds:  0.24593955235646558\n"
     ]
    }
   ],
   "source": [
    "idx = preds_df['deal_probability']==preds_df['deal_probability']\n",
    "print(idx.value_counts())\n",
    "for col in [c for c in preds_df.columns if ('_preds' in c) and ('difference' not in c) and ('sum' not in c)]:\n",
    "    print('RMSE %s: '%(col), np.sqrt(metrics.mean_squared_error(preds_df['deal_probability'][idx].values, preds_df[col][idx].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldls = [[\"2017-03-15\", \"2017-03-16\", \"2017-03-17\"], \\\n",
    "       [\"2017-03-18\", \"2017-03-19\", \"2017-03-20\"], \\\n",
    "       [\"2017-03-21\", \"2017-03-22\", \"2017-03-23\"], \\\n",
    "       [\"2017-03-24\", \"2017-03-25\", \"2017-03-26\"], \\\n",
    "        [\"2017-03-27\", \"2017-03-28\", \"2017-03-29\", \\\n",
    "            \"2017-03-30\", \"2017-03-31\", \"2017-04-01\", \\\n",
    "            \"2017-04-02\", \"2017-04-03\",\"2017-04-07\"]]\n",
    "foldls = [[pd.to_datetime(d) for d in f] for f in foldls]\n",
    "preds_df['fold'] = -1\n",
    "for t, fold in enumerate(foldls):\n",
    "    preds_df['fold'][preds_df.activation_date.isin(fold)] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold0</th>\n",
       "      <th>Fold1</th>\n",
       "      <th>Fold2</th>\n",
       "      <th>Fold3</th>\n",
       "      <th>Fold4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lgb27_preds</td>\n",
       "      <td>0.216848</td>\n",
       "      <td>0.217096</td>\n",
       "      <td>0.217923</td>\n",
       "      <td>0.217597</td>\n",
       "      <td>0.213692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rnn_preds</td>\n",
       "      <td>0.218756</td>\n",
       "      <td>0.218966</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.219554</td>\n",
       "      <td>0.214747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlp_preds</td>\n",
       "      <td>0.219660</td>\n",
       "      <td>0.220088</td>\n",
       "      <td>0.216672</td>\n",
       "      <td>0.220347</td>\n",
       "      <td>0.216385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lgb31_preds</td>\n",
       "      <td>0.216537</td>\n",
       "      <td>0.216643</td>\n",
       "      <td>0.219230</td>\n",
       "      <td>0.217169</td>\n",
       "      <td>0.213430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lgb02_preds</td>\n",
       "      <td>0.216371</td>\n",
       "      <td>0.216447</td>\n",
       "      <td>0.217354</td>\n",
       "      <td>0.217032</td>\n",
       "      <td>0.213158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lgb09_preds</td>\n",
       "      <td>0.215514</td>\n",
       "      <td>0.215678</td>\n",
       "      <td>0.218418</td>\n",
       "      <td>0.216073</td>\n",
       "      <td>0.212293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lgb10_preds</td>\n",
       "      <td>0.215240</td>\n",
       "      <td>0.215533</td>\n",
       "      <td>0.217072</td>\n",
       "      <td>0.215802</td>\n",
       "      <td>0.212023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lgb11A_preds</td>\n",
       "      <td>0.215011</td>\n",
       "      <td>0.215205</td>\n",
       "      <td>0.211879</td>\n",
       "      <td>0.215771</td>\n",
       "      <td>0.211735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lgb11D_preds</td>\n",
       "      <td>0.214818</td>\n",
       "      <td>0.215074</td>\n",
       "      <td>0.211837</td>\n",
       "      <td>0.215720</td>\n",
       "      <td>0.211549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lgb14_preds</td>\n",
       "      <td>0.214204</td>\n",
       "      <td>0.214441</td>\n",
       "      <td>0.211074</td>\n",
       "      <td>0.215146</td>\n",
       "      <td>0.211051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lgb17_preds</td>\n",
       "      <td>0.214061</td>\n",
       "      <td>0.214275</td>\n",
       "      <td>0.210872</td>\n",
       "      <td>0.214884</td>\n",
       "      <td>0.210930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>lgb02A_preds</td>\n",
       "      <td>0.216081</td>\n",
       "      <td>0.216051</td>\n",
       "      <td>0.218825</td>\n",
       "      <td>0.216562</td>\n",
       "      <td>0.212741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rnn27_preds</td>\n",
       "      <td>0.218097</td>\n",
       "      <td>0.218115</td>\n",
       "      <td>0.214982</td>\n",
       "      <td>0.218651</td>\n",
       "      <td>0.214379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rnn12_preds</td>\n",
       "      <td>0.217658</td>\n",
       "      <td>0.217913</td>\n",
       "      <td>0.214952</td>\n",
       "      <td>0.218472</td>\n",
       "      <td>0.213781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rdgv19_preds</td>\n",
       "      <td>0.246571</td>\n",
       "      <td>0.246399</td>\n",
       "      <td>0.244456</td>\n",
       "      <td>0.247503</td>\n",
       "      <td>0.244406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model     Fold0     Fold1     Fold2     Fold3     Fold4\n",
       "0    lgb27_preds  0.216848  0.217096  0.217923  0.217597  0.213692\n",
       "1      rnn_preds  0.218756  0.218966  0.215764  0.219554  0.214747\n",
       "2      mlp_preds  0.219660  0.220088  0.216672  0.220347  0.216385\n",
       "3    lgb31_preds  0.216537  0.216643  0.219230  0.217169  0.213430\n",
       "4    lgb02_preds  0.216371  0.216447  0.217354  0.217032  0.213158\n",
       "5    lgb09_preds  0.215514  0.215678  0.218418  0.216073  0.212293\n",
       "6    lgb10_preds  0.215240  0.215533  0.217072  0.215802  0.212023\n",
       "7   lgb11A_preds  0.215011  0.215205  0.211879  0.215771  0.211735\n",
       "8   lgb11D_preds  0.214818  0.215074  0.211837  0.215720  0.211549\n",
       "9    lgb14_preds  0.214204  0.214441  0.211074  0.215146  0.211051\n",
       "10   lgb17_preds  0.214061  0.214275  0.210872  0.214884  0.210930\n",
       "11  lgb02A_preds  0.216081  0.216051  0.218825  0.216562  0.212741\n",
       "12   rnn27_preds  0.218097  0.218115  0.214982  0.218651  0.214379\n",
       "13   rnn12_preds  0.217658  0.217913  0.214952  0.218472  0.213781\n",
       "14  rdgv19_preds  0.246571  0.246399  0.244456  0.247503  0.244406"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for col in [c for c in preds_df.columns if ('_preds' in c) \\\n",
    "            and ('difference' not in c) \\\n",
    "            and ('sum' not in c)]:\n",
    "    lstmp = [col]\n",
    "    for i in range(5):\n",
    "        idx = preds_df['fold']==i\n",
    "        lstmp.append(np.sqrt(metrics.mean_squared_error(preds_df['deal_probability'][idx].values, \\\n",
    "                                                        preds_df[col][idx].values)))\n",
    "    scores.append(lstmp)\n",
    "pd.DataFrame(scores, columns = ['Model']+['Fold%s'%(i) for i in range(5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations in test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb27_preds</th>\n",
       "      <th>rnn_preds</th>\n",
       "      <th>mlp_preds</th>\n",
       "      <th>lgb31_preds</th>\n",
       "      <th>lgb02_preds</th>\n",
       "      <th>lgb09_preds</th>\n",
       "      <th>lgb10_preds</th>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <th>lgb14_preds</th>\n",
       "      <th>lgb17_preds</th>\n",
       "      <th>lgb02A_preds</th>\n",
       "      <th>rnn27_preds</th>\n",
       "      <th>rnn12_preds</th>\n",
       "      <th>rdgv19_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lgb27_preds</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915952</td>\n",
       "      <td>0.919171</td>\n",
       "      <td>0.990750</td>\n",
       "      <td>0.988682</td>\n",
       "      <td>0.978331</td>\n",
       "      <td>0.978298</td>\n",
       "      <td>0.966819</td>\n",
       "      <td>0.965873</td>\n",
       "      <td>0.961540</td>\n",
       "      <td>0.963754</td>\n",
       "      <td>0.983143</td>\n",
       "      <td>0.916804</td>\n",
       "      <td>0.920576</td>\n",
       "      <td>0.568406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn_preds</th>\n",
       "      <td>0.915952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929710</td>\n",
       "      <td>0.910602</td>\n",
       "      <td>0.913307</td>\n",
       "      <td>0.908867</td>\n",
       "      <td>0.913286</td>\n",
       "      <td>0.915655</td>\n",
       "      <td>0.913936</td>\n",
       "      <td>0.912870</td>\n",
       "      <td>0.915690</td>\n",
       "      <td>0.911443</td>\n",
       "      <td>0.985360</td>\n",
       "      <td>0.978274</td>\n",
       "      <td>0.551100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_preds</th>\n",
       "      <td>0.919171</td>\n",
       "      <td>0.929710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914307</td>\n",
       "      <td>0.916343</td>\n",
       "      <td>0.909521</td>\n",
       "      <td>0.913883</td>\n",
       "      <td>0.915367</td>\n",
       "      <td>0.913018</td>\n",
       "      <td>0.911656</td>\n",
       "      <td>0.915252</td>\n",
       "      <td>0.913600</td>\n",
       "      <td>0.925010</td>\n",
       "      <td>0.929518</td>\n",
       "      <td>0.577280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb31_preds</th>\n",
       "      <td>0.990750</td>\n",
       "      <td>0.910602</td>\n",
       "      <td>0.914307</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991984</td>\n",
       "      <td>0.981891</td>\n",
       "      <td>0.981375</td>\n",
       "      <td>0.966656</td>\n",
       "      <td>0.965897</td>\n",
       "      <td>0.961575</td>\n",
       "      <td>0.963672</td>\n",
       "      <td>0.986851</td>\n",
       "      <td>0.914204</td>\n",
       "      <td>0.916939</td>\n",
       "      <td>0.570034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb02_preds</th>\n",
       "      <td>0.988682</td>\n",
       "      <td>0.913307</td>\n",
       "      <td>0.916343</td>\n",
       "      <td>0.991984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982596</td>\n",
       "      <td>0.982052</td>\n",
       "      <td>0.970858</td>\n",
       "      <td>0.969933</td>\n",
       "      <td>0.966325</td>\n",
       "      <td>0.968201</td>\n",
       "      <td>0.987434</td>\n",
       "      <td>0.916726</td>\n",
       "      <td>0.920105</td>\n",
       "      <td>0.567698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb09_preds</th>\n",
       "      <td>0.978331</td>\n",
       "      <td>0.908867</td>\n",
       "      <td>0.909521</td>\n",
       "      <td>0.981891</td>\n",
       "      <td>0.982596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990447</td>\n",
       "      <td>0.976755</td>\n",
       "      <td>0.976540</td>\n",
       "      <td>0.972392</td>\n",
       "      <td>0.972977</td>\n",
       "      <td>0.988708</td>\n",
       "      <td>0.912375</td>\n",
       "      <td>0.915090</td>\n",
       "      <td>0.560909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb10_preds</th>\n",
       "      <td>0.978298</td>\n",
       "      <td>0.913286</td>\n",
       "      <td>0.913883</td>\n",
       "      <td>0.981375</td>\n",
       "      <td>0.982052</td>\n",
       "      <td>0.990447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982841</td>\n",
       "      <td>0.982033</td>\n",
       "      <td>0.977396</td>\n",
       "      <td>0.978691</td>\n",
       "      <td>0.985858</td>\n",
       "      <td>0.916436</td>\n",
       "      <td>0.920034</td>\n",
       "      <td>0.562639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <td>0.966819</td>\n",
       "      <td>0.915655</td>\n",
       "      <td>0.915367</td>\n",
       "      <td>0.966656</td>\n",
       "      <td>0.970858</td>\n",
       "      <td>0.976755</td>\n",
       "      <td>0.982841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992400</td>\n",
       "      <td>0.988703</td>\n",
       "      <td>0.989962</td>\n",
       "      <td>0.971893</td>\n",
       "      <td>0.918727</td>\n",
       "      <td>0.923137</td>\n",
       "      <td>0.558477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <td>0.965873</td>\n",
       "      <td>0.913936</td>\n",
       "      <td>0.913018</td>\n",
       "      <td>0.965897</td>\n",
       "      <td>0.969933</td>\n",
       "      <td>0.976540</td>\n",
       "      <td>0.982033</td>\n",
       "      <td>0.992400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989978</td>\n",
       "      <td>0.990876</td>\n",
       "      <td>0.971846</td>\n",
       "      <td>0.917196</td>\n",
       "      <td>0.921322</td>\n",
       "      <td>0.557072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb14_preds</th>\n",
       "      <td>0.961540</td>\n",
       "      <td>0.912870</td>\n",
       "      <td>0.911656</td>\n",
       "      <td>0.961575</td>\n",
       "      <td>0.966325</td>\n",
       "      <td>0.972392</td>\n",
       "      <td>0.977396</td>\n",
       "      <td>0.988703</td>\n",
       "      <td>0.989978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994906</td>\n",
       "      <td>0.967560</td>\n",
       "      <td>0.916160</td>\n",
       "      <td>0.920547</td>\n",
       "      <td>0.553930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb17_preds</th>\n",
       "      <td>0.963754</td>\n",
       "      <td>0.915690</td>\n",
       "      <td>0.915252</td>\n",
       "      <td>0.963672</td>\n",
       "      <td>0.968201</td>\n",
       "      <td>0.972977</td>\n",
       "      <td>0.978691</td>\n",
       "      <td>0.989962</td>\n",
       "      <td>0.990876</td>\n",
       "      <td>0.994906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968335</td>\n",
       "      <td>0.918859</td>\n",
       "      <td>0.923748</td>\n",
       "      <td>0.558075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb02A_preds</th>\n",
       "      <td>0.983143</td>\n",
       "      <td>0.911443</td>\n",
       "      <td>0.913600</td>\n",
       "      <td>0.986851</td>\n",
       "      <td>0.987434</td>\n",
       "      <td>0.988708</td>\n",
       "      <td>0.985858</td>\n",
       "      <td>0.971893</td>\n",
       "      <td>0.971846</td>\n",
       "      <td>0.967560</td>\n",
       "      <td>0.968335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914911</td>\n",
       "      <td>0.917453</td>\n",
       "      <td>0.564071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn27_preds</th>\n",
       "      <td>0.916804</td>\n",
       "      <td>0.985360</td>\n",
       "      <td>0.925010</td>\n",
       "      <td>0.914204</td>\n",
       "      <td>0.916726</td>\n",
       "      <td>0.912375</td>\n",
       "      <td>0.916436</td>\n",
       "      <td>0.918727</td>\n",
       "      <td>0.917196</td>\n",
       "      <td>0.916160</td>\n",
       "      <td>0.918859</td>\n",
       "      <td>0.914911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979744</td>\n",
       "      <td>0.558103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn12_preds</th>\n",
       "      <td>0.920576</td>\n",
       "      <td>0.978274</td>\n",
       "      <td>0.929518</td>\n",
       "      <td>0.916939</td>\n",
       "      <td>0.920105</td>\n",
       "      <td>0.915090</td>\n",
       "      <td>0.920034</td>\n",
       "      <td>0.923137</td>\n",
       "      <td>0.921322</td>\n",
       "      <td>0.920547</td>\n",
       "      <td>0.923748</td>\n",
       "      <td>0.917453</td>\n",
       "      <td>0.979744</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.564928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rdgv19_preds</th>\n",
       "      <td>0.568406</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.577280</td>\n",
       "      <td>0.570034</td>\n",
       "      <td>0.567698</td>\n",
       "      <td>0.560909</td>\n",
       "      <td>0.562639</td>\n",
       "      <td>0.558477</td>\n",
       "      <td>0.557072</td>\n",
       "      <td>0.553930</td>\n",
       "      <td>0.558075</td>\n",
       "      <td>0.564071</td>\n",
       "      <td>0.558103</td>\n",
       "      <td>0.564928</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lgb27_preds  rnn_preds  mlp_preds  lgb31_preds  lgb02_preds  \\\n",
       "lgb27_preds      1.000000   0.915952   0.919171     0.990750     0.988682   \n",
       "rnn_preds        0.915952   1.000000   0.929710     0.910602     0.913307   \n",
       "mlp_preds        0.919171   0.929710   1.000000     0.914307     0.916343   \n",
       "lgb31_preds      0.990750   0.910602   0.914307     1.000000     0.991984   \n",
       "lgb02_preds      0.988682   0.913307   0.916343     0.991984     1.000000   \n",
       "lgb09_preds      0.978331   0.908867   0.909521     0.981891     0.982596   \n",
       "lgb10_preds      0.978298   0.913286   0.913883     0.981375     0.982052   \n",
       "lgb11A_preds     0.966819   0.915655   0.915367     0.966656     0.970858   \n",
       "lgb11D_preds     0.965873   0.913936   0.913018     0.965897     0.969933   \n",
       "lgb14_preds      0.961540   0.912870   0.911656     0.961575     0.966325   \n",
       "lgb17_preds      0.963754   0.915690   0.915252     0.963672     0.968201   \n",
       "lgb02A_preds     0.983143   0.911443   0.913600     0.986851     0.987434   \n",
       "rnn27_preds      0.916804   0.985360   0.925010     0.914204     0.916726   \n",
       "rnn12_preds      0.920576   0.978274   0.929518     0.916939     0.920105   \n",
       "rdgv19_preds     0.568406   0.551100   0.577280     0.570034     0.567698   \n",
       "\n",
       "              lgb09_preds  lgb10_preds  lgb11A_preds  lgb11D_preds  \\\n",
       "lgb27_preds      0.978331     0.978298      0.966819      0.965873   \n",
       "rnn_preds        0.908867     0.913286      0.915655      0.913936   \n",
       "mlp_preds        0.909521     0.913883      0.915367      0.913018   \n",
       "lgb31_preds      0.981891     0.981375      0.966656      0.965897   \n",
       "lgb02_preds      0.982596     0.982052      0.970858      0.969933   \n",
       "lgb09_preds      1.000000     0.990447      0.976755      0.976540   \n",
       "lgb10_preds      0.990447     1.000000      0.982841      0.982033   \n",
       "lgb11A_preds     0.976755     0.982841      1.000000      0.992400   \n",
       "lgb11D_preds     0.976540     0.982033      0.992400      1.000000   \n",
       "lgb14_preds      0.972392     0.977396      0.988703      0.989978   \n",
       "lgb17_preds      0.972977     0.978691      0.989962      0.990876   \n",
       "lgb02A_preds     0.988708     0.985858      0.971893      0.971846   \n",
       "rnn27_preds      0.912375     0.916436      0.918727      0.917196   \n",
       "rnn12_preds      0.915090     0.920034      0.923137      0.921322   \n",
       "rdgv19_preds     0.560909     0.562639      0.558477      0.557072   \n",
       "\n",
       "              lgb14_preds  lgb17_preds  lgb02A_preds  rnn27_preds  \\\n",
       "lgb27_preds      0.961540     0.963754      0.983143     0.916804   \n",
       "rnn_preds        0.912870     0.915690      0.911443     0.985360   \n",
       "mlp_preds        0.911656     0.915252      0.913600     0.925010   \n",
       "lgb31_preds      0.961575     0.963672      0.986851     0.914204   \n",
       "lgb02_preds      0.966325     0.968201      0.987434     0.916726   \n",
       "lgb09_preds      0.972392     0.972977      0.988708     0.912375   \n",
       "lgb10_preds      0.977396     0.978691      0.985858     0.916436   \n",
       "lgb11A_preds     0.988703     0.989962      0.971893     0.918727   \n",
       "lgb11D_preds     0.989978     0.990876      0.971846     0.917196   \n",
       "lgb14_preds      1.000000     0.994906      0.967560     0.916160   \n",
       "lgb17_preds      0.994906     1.000000      0.968335     0.918859   \n",
       "lgb02A_preds     0.967560     0.968335      1.000000     0.914911   \n",
       "rnn27_preds      0.916160     0.918859      0.914911     1.000000   \n",
       "rnn12_preds      0.920547     0.923748      0.917453     0.979744   \n",
       "rdgv19_preds     0.553930     0.558075      0.564071     0.558103   \n",
       "\n",
       "              rnn12_preds  rdgv19_preds  \n",
       "lgb27_preds      0.920576      0.568406  \n",
       "rnn_preds        0.978274      0.551100  \n",
       "mlp_preds        0.929518      0.577280  \n",
       "lgb31_preds      0.916939      0.570034  \n",
       "lgb02_preds      0.920105      0.567698  \n",
       "lgb09_preds      0.915090      0.560909  \n",
       "lgb10_preds      0.920034      0.562639  \n",
       "lgb11A_preds     0.923137      0.558477  \n",
       "lgb11D_preds     0.921322      0.557072  \n",
       "lgb14_preds      0.920547      0.553930  \n",
       "lgb17_preds      0.923748      0.558075  \n",
       "lgb02A_preds     0.917453      0.564071  \n",
       "rnn27_preds      0.979744      0.558103  \n",
       "rnn12_preds      1.000000      0.564928  \n",
       "rdgv19_preds     0.564928      1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test correlation\n",
    "preds_df[~preds_df['deal_probability'].isnull()][[c for c in preds_df.columns if ('_preds' in c) \\\n",
    "                                                  and ('difference' not in c) and ('sum' not in c) ]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb27_preds</th>\n",
       "      <th>rnn_preds</th>\n",
       "      <th>mlp_preds</th>\n",
       "      <th>lgb31_preds</th>\n",
       "      <th>lgb02_preds</th>\n",
       "      <th>lgb09_preds</th>\n",
       "      <th>lgb10_preds</th>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <th>lgb14_preds</th>\n",
       "      <th>lgb17_preds</th>\n",
       "      <th>lgb02A_preds</th>\n",
       "      <th>rnn27_preds</th>\n",
       "      <th>rnn12_preds</th>\n",
       "      <th>rdgv19_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lgb27_preds</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930288</td>\n",
       "      <td>0.924283</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.989502</td>\n",
       "      <td>0.979729</td>\n",
       "      <td>0.979341</td>\n",
       "      <td>0.975840</td>\n",
       "      <td>0.973725</td>\n",
       "      <td>0.970062</td>\n",
       "      <td>0.972503</td>\n",
       "      <td>0.984742</td>\n",
       "      <td>0.930692</td>\n",
       "      <td>0.932951</td>\n",
       "      <td>0.571110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn_preds</th>\n",
       "      <td>0.930288</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.939951</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.927867</td>\n",
       "      <td>0.926158</td>\n",
       "      <td>0.928367</td>\n",
       "      <td>0.927119</td>\n",
       "      <td>0.925632</td>\n",
       "      <td>0.924680</td>\n",
       "      <td>0.926976</td>\n",
       "      <td>0.928496</td>\n",
       "      <td>0.988198</td>\n",
       "      <td>0.984113</td>\n",
       "      <td>0.559376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_preds</th>\n",
       "      <td>0.924283</td>\n",
       "      <td>0.939951</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922413</td>\n",
       "      <td>0.921927</td>\n",
       "      <td>0.918064</td>\n",
       "      <td>0.920496</td>\n",
       "      <td>0.919275</td>\n",
       "      <td>0.917496</td>\n",
       "      <td>0.916323</td>\n",
       "      <td>0.919199</td>\n",
       "      <td>0.922121</td>\n",
       "      <td>0.935069</td>\n",
       "      <td>0.936609</td>\n",
       "      <td>0.561935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb31_preds</th>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.922413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993168</td>\n",
       "      <td>0.982874</td>\n",
       "      <td>0.982519</td>\n",
       "      <td>0.978877</td>\n",
       "      <td>0.976777</td>\n",
       "      <td>0.973170</td>\n",
       "      <td>0.975607</td>\n",
       "      <td>0.988043</td>\n",
       "      <td>0.931468</td>\n",
       "      <td>0.932981</td>\n",
       "      <td>0.572757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb02_preds</th>\n",
       "      <td>0.989502</td>\n",
       "      <td>0.927867</td>\n",
       "      <td>0.921927</td>\n",
       "      <td>0.993168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984427</td>\n",
       "      <td>0.983525</td>\n",
       "      <td>0.980105</td>\n",
       "      <td>0.978173</td>\n",
       "      <td>0.975031</td>\n",
       "      <td>0.977087</td>\n",
       "      <td>0.989577</td>\n",
       "      <td>0.931447</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.570342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb09_preds</th>\n",
       "      <td>0.979729</td>\n",
       "      <td>0.926158</td>\n",
       "      <td>0.918064</td>\n",
       "      <td>0.982874</td>\n",
       "      <td>0.984427</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991413</td>\n",
       "      <td>0.988267</td>\n",
       "      <td>0.986666</td>\n",
       "      <td>0.983504</td>\n",
       "      <td>0.984455</td>\n",
       "      <td>0.989106</td>\n",
       "      <td>0.929748</td>\n",
       "      <td>0.931167</td>\n",
       "      <td>0.565333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb10_preds</th>\n",
       "      <td>0.979341</td>\n",
       "      <td>0.928367</td>\n",
       "      <td>0.920496</td>\n",
       "      <td>0.982519</td>\n",
       "      <td>0.983525</td>\n",
       "      <td>0.991413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>0.990473</td>\n",
       "      <td>0.986869</td>\n",
       "      <td>0.988382</td>\n",
       "      <td>0.986654</td>\n",
       "      <td>0.931841</td>\n",
       "      <td>0.933902</td>\n",
       "      <td>0.566736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb11A_preds</th>\n",
       "      <td>0.975840</td>\n",
       "      <td>0.927119</td>\n",
       "      <td>0.919275</td>\n",
       "      <td>0.978877</td>\n",
       "      <td>0.980105</td>\n",
       "      <td>0.988267</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993474</td>\n",
       "      <td>0.990047</td>\n",
       "      <td>0.991264</td>\n",
       "      <td>0.983556</td>\n",
       "      <td>0.930518</td>\n",
       "      <td>0.932743</td>\n",
       "      <td>0.563841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb11D_preds</th>\n",
       "      <td>0.973725</td>\n",
       "      <td>0.925632</td>\n",
       "      <td>0.917496</td>\n",
       "      <td>0.976777</td>\n",
       "      <td>0.978173</td>\n",
       "      <td>0.986666</td>\n",
       "      <td>0.990473</td>\n",
       "      <td>0.993474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991525</td>\n",
       "      <td>0.992446</td>\n",
       "      <td>0.981933</td>\n",
       "      <td>0.929068</td>\n",
       "      <td>0.931133</td>\n",
       "      <td>0.561824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb14_preds</th>\n",
       "      <td>0.970062</td>\n",
       "      <td>0.924680</td>\n",
       "      <td>0.916323</td>\n",
       "      <td>0.973170</td>\n",
       "      <td>0.975031</td>\n",
       "      <td>0.983504</td>\n",
       "      <td>0.986869</td>\n",
       "      <td>0.990047</td>\n",
       "      <td>0.991525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995582</td>\n",
       "      <td>0.978724</td>\n",
       "      <td>0.928224</td>\n",
       "      <td>0.930421</td>\n",
       "      <td>0.558673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb17_preds</th>\n",
       "      <td>0.972503</td>\n",
       "      <td>0.926976</td>\n",
       "      <td>0.919199</td>\n",
       "      <td>0.975607</td>\n",
       "      <td>0.977087</td>\n",
       "      <td>0.984455</td>\n",
       "      <td>0.988382</td>\n",
       "      <td>0.991264</td>\n",
       "      <td>0.992446</td>\n",
       "      <td>0.995582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979791</td>\n",
       "      <td>0.930381</td>\n",
       "      <td>0.932982</td>\n",
       "      <td>0.561605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lgb02A_preds</th>\n",
       "      <td>0.984742</td>\n",
       "      <td>0.928496</td>\n",
       "      <td>0.922121</td>\n",
       "      <td>0.988043</td>\n",
       "      <td>0.989577</td>\n",
       "      <td>0.989106</td>\n",
       "      <td>0.986654</td>\n",
       "      <td>0.983556</td>\n",
       "      <td>0.981933</td>\n",
       "      <td>0.978724</td>\n",
       "      <td>0.979791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.932071</td>\n",
       "      <td>0.933267</td>\n",
       "      <td>0.567816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn27_preds</th>\n",
       "      <td>0.930692</td>\n",
       "      <td>0.988198</td>\n",
       "      <td>0.935069</td>\n",
       "      <td>0.931468</td>\n",
       "      <td>0.931447</td>\n",
       "      <td>0.929748</td>\n",
       "      <td>0.931841</td>\n",
       "      <td>0.930518</td>\n",
       "      <td>0.929068</td>\n",
       "      <td>0.928224</td>\n",
       "      <td>0.930381</td>\n",
       "      <td>0.932071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987051</td>\n",
       "      <td>0.562929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnn12_preds</th>\n",
       "      <td>0.932951</td>\n",
       "      <td>0.984113</td>\n",
       "      <td>0.936609</td>\n",
       "      <td>0.932981</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.931167</td>\n",
       "      <td>0.933902</td>\n",
       "      <td>0.932743</td>\n",
       "      <td>0.931133</td>\n",
       "      <td>0.930421</td>\n",
       "      <td>0.932982</td>\n",
       "      <td>0.933267</td>\n",
       "      <td>0.987051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.568866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rdgv19_preds</th>\n",
       "      <td>0.571110</td>\n",
       "      <td>0.559376</td>\n",
       "      <td>0.561935</td>\n",
       "      <td>0.572757</td>\n",
       "      <td>0.570342</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>0.566736</td>\n",
       "      <td>0.563841</td>\n",
       "      <td>0.561824</td>\n",
       "      <td>0.558673</td>\n",
       "      <td>0.561605</td>\n",
       "      <td>0.567816</td>\n",
       "      <td>0.562929</td>\n",
       "      <td>0.568866</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              lgb27_preds  rnn_preds  mlp_preds  lgb31_preds  lgb02_preds  \\\n",
       "lgb27_preds      1.000000   0.930288   0.924283     0.991439     0.989502   \n",
       "rnn_preds        0.930288   1.000000   0.939951     0.927835     0.927867   \n",
       "mlp_preds        0.924283   0.939951   1.000000     0.922413     0.921927   \n",
       "lgb31_preds      0.991439   0.927835   0.922413     1.000000     0.993168   \n",
       "lgb02_preds      0.989502   0.927867   0.921927     0.993168     1.000000   \n",
       "lgb09_preds      0.979729   0.926158   0.918064     0.982874     0.984427   \n",
       "lgb10_preds      0.979341   0.928367   0.920496     0.982519     0.983525   \n",
       "lgb11A_preds     0.975840   0.927119   0.919275     0.978877     0.980105   \n",
       "lgb11D_preds     0.973725   0.925632   0.917496     0.976777     0.978173   \n",
       "lgb14_preds      0.970062   0.924680   0.916323     0.973170     0.975031   \n",
       "lgb17_preds      0.972503   0.926976   0.919199     0.975607     0.977087   \n",
       "lgb02A_preds     0.984742   0.928496   0.922121     0.988043     0.989577   \n",
       "rnn27_preds      0.930692   0.988198   0.935069     0.931468     0.931447   \n",
       "rnn12_preds      0.932951   0.984113   0.936609     0.932981     0.933333   \n",
       "rdgv19_preds     0.571110   0.559376   0.561935     0.572757     0.570342   \n",
       "\n",
       "              lgb09_preds  lgb10_preds  lgb11A_preds  lgb11D_preds  \\\n",
       "lgb27_preds      0.979729     0.979341      0.975840      0.973725   \n",
       "rnn_preds        0.926158     0.928367      0.927119      0.925632   \n",
       "mlp_preds        0.918064     0.920496      0.919275      0.917496   \n",
       "lgb31_preds      0.982874     0.982519      0.978877      0.976777   \n",
       "lgb02_preds      0.984427     0.983525      0.980105      0.978173   \n",
       "lgb09_preds      1.000000     0.991413      0.988267      0.986666   \n",
       "lgb10_preds      0.991413     1.000000      0.992340      0.990473   \n",
       "lgb11A_preds     0.988267     0.992340      1.000000      0.993474   \n",
       "lgb11D_preds     0.986666     0.990473      0.993474      1.000000   \n",
       "lgb14_preds      0.983504     0.986869      0.990047      0.991525   \n",
       "lgb17_preds      0.984455     0.988382      0.991264      0.992446   \n",
       "lgb02A_preds     0.989106     0.986654      0.983556      0.981933   \n",
       "rnn27_preds      0.929748     0.931841      0.930518      0.929068   \n",
       "rnn12_preds      0.931167     0.933902      0.932743      0.931133   \n",
       "rdgv19_preds     0.565333     0.566736      0.563841      0.561824   \n",
       "\n",
       "              lgb14_preds  lgb17_preds  lgb02A_preds  rnn27_preds  \\\n",
       "lgb27_preds      0.970062     0.972503      0.984742     0.930692   \n",
       "rnn_preds        0.924680     0.926976      0.928496     0.988198   \n",
       "mlp_preds        0.916323     0.919199      0.922121     0.935069   \n",
       "lgb31_preds      0.973170     0.975607      0.988043     0.931468   \n",
       "lgb02_preds      0.975031     0.977087      0.989577     0.931447   \n",
       "lgb09_preds      0.983504     0.984455      0.989106     0.929748   \n",
       "lgb10_preds      0.986869     0.988382      0.986654     0.931841   \n",
       "lgb11A_preds     0.990047     0.991264      0.983556     0.930518   \n",
       "lgb11D_preds     0.991525     0.992446      0.981933     0.929068   \n",
       "lgb14_preds      1.000000     0.995582      0.978724     0.928224   \n",
       "lgb17_preds      0.995582     1.000000      0.979791     0.930381   \n",
       "lgb02A_preds     0.978724     0.979791      1.000000     0.932071   \n",
       "rnn27_preds      0.928224     0.930381      0.932071     1.000000   \n",
       "rnn12_preds      0.930421     0.932982      0.933267     0.987051   \n",
       "rdgv19_preds     0.558673     0.561605      0.567816     0.562929   \n",
       "\n",
       "              rnn12_preds  rdgv19_preds  \n",
       "lgb27_preds      0.932951      0.571110  \n",
       "rnn_preds        0.984113      0.559376  \n",
       "mlp_preds        0.936609      0.561935  \n",
       "lgb31_preds      0.932981      0.572757  \n",
       "lgb02_preds      0.933333      0.570342  \n",
       "lgb09_preds      0.931167      0.565333  \n",
       "lgb10_preds      0.933902      0.566736  \n",
       "lgb11A_preds     0.932743      0.563841  \n",
       "lgb11D_preds     0.931133      0.561824  \n",
       "lgb14_preds      0.930421      0.558673  \n",
       "lgb17_preds      0.932982      0.561605  \n",
       "lgb02A_preds     0.933267      0.567816  \n",
       "rnn27_preds      0.987051      0.562929  \n",
       "rnn12_preds      1.000000      0.568866  \n",
       "rdgv19_preds     0.568866      1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train correlation\n",
    "preds_df[preds_df['deal_probability'].isnull()][[c for c in preds_df.columns if ('_preds' in c)  \\\n",
    "                                                  and ('difference' not in c) and ('sum' not in c) ]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [c for c in preds_df.columns if '_preds' in c]\n",
    "cols += [c for c in preds_df.columns if 'difference' in c]\n",
    "cols += ['price', 'max', 'min', 'avg', 'std', 'med', 'item_seq_number']\n",
    "categories = ['region', 'param_1_big', 'parent_category_name', 'category_name', \\\n",
    "              'param_2_big', 'param_3_big', 'city_big', 'user_type', 'image_top_1_big']#,\n",
    "cols += categories\n",
    "cols = list(set(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categories:\n",
    "    preds_df[col] = LabelEncoder().fit_transform(preds_df[col].fillna(\"0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = preds_df[~preds_df['deal_probability'].isnull()]\n",
    "test_df = preds_df[preds_df['deal_probability'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 4000\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(train_df[cols], y, train_size=.8, random_state=12345)\n",
    "eval_set = [(train_X,train_y),(valid_X,valid_y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1202739"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds.\n",
      "[100]\ttraining's rmse: 0.21918\tvalid_1's rmse: 0.219563\n",
      "[200]\ttraining's rmse: 0.212761\tvalid_1's rmse: 0.213384\n",
      "[300]\ttraining's rmse: 0.211644\tvalid_1's rmse: 0.212467\n",
      "[400]\ttraining's rmse: 0.211289\tvalid_1's rmse: 0.212288\n",
      "[500]\ttraining's rmse: 0.211063\tvalid_1's rmse: 0.212224\n",
      "[600]\ttraining's rmse: 0.210878\tvalid_1's rmse: 0.212193\n",
      "[700]\ttraining's rmse: 0.210717\tvalid_1's rmse: 0.212174\n",
      "[800]\ttraining's rmse: 0.210569\tvalid_1's rmse: 0.212161\n",
      "[900]\ttraining's rmse: 0.210425\tvalid_1's rmse: 0.212151\n",
      "[1000]\ttraining's rmse: 0.210285\tvalid_1's rmse: 0.212143\n",
      "[1100]\ttraining's rmse: 0.210147\tvalid_1's rmse: 0.212138\n",
      "[1200]\ttraining's rmse: 0.210009\tvalid_1's rmse: 0.212133\n",
      "[1300]\ttraining's rmse: 0.209881\tvalid_1's rmse: 0.212128\n",
      "[1400]\ttraining's rmse: 0.209754\tvalid_1's rmse: 0.212124\n",
      "[1500]\ttraining's rmse: 0.209627\tvalid_1's rmse: 0.212119\n",
      "[1600]\ttraining's rmse: 0.209503\tvalid_1's rmse: 0.212116\n",
      "[1700]\ttraining's rmse: 0.209378\tvalid_1's rmse: 0.212111\n",
      "[1800]\ttraining's rmse: 0.209255\tvalid_1's rmse: 0.212105\n",
      "[1900]\ttraining's rmse: 0.209132\tvalid_1's rmse: 0.212102\n",
      "[2000]\ttraining's rmse: 0.209011\tvalid_1's rmse: 0.212098\n",
      "[2100]\ttraining's rmse: 0.208894\tvalid_1's rmse: 0.212095\n",
      "[2200]\ttraining's rmse: 0.208773\tvalid_1's rmse: 0.212091\n",
      "[2300]\ttraining's rmse: 0.208655\tvalid_1's rmse: 0.212088\n",
      "[2400]\ttraining's rmse: 0.208541\tvalid_1's rmse: 0.212085\n",
      "[2500]\ttraining's rmse: 0.208424\tvalid_1's rmse: 0.212082\n",
      "[2600]\ttraining's rmse: 0.208309\tvalid_1's rmse: 0.21208\n",
      "[2700]\ttraining's rmse: 0.208192\tvalid_1's rmse: 0.212077\n",
      "[2800]\ttraining's rmse: 0.208075\tvalid_1's rmse: 0.212075\n",
      "Early stopping, best iteration is:\n",
      "[2779]\ttraining's rmse: 0.208099\tvalid_1's rmse: 0.212073\n",
      "CPU times: user 47min 41s, sys: 10.6 s, total: 47min 51s\n",
      "Wall time: 6min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gc.collect()\n",
    "clf = LGBMRegressor(n_estimators=n_estimators, \n",
    "                    max_depth=-1, \n",
    "                    feature_fraction= 0.4,\n",
    "                    num_leaves=32, \n",
    "                    learning_rate=.01)#, device='gpu')\n",
    "clf.fit(train_X, train_y, early_stopping_rounds=80, \n",
    "        eval_set=eval_set, eval_metric='rmse', verbose=100, \n",
    "        categorical_feature=categories)\n",
    "# [1575]\ttraining's rmse: 0.209567\tvalid_1's rmse: 0.212278\n",
    "# [2728]\ttraining's rmse: 0.208114\tvalid_1's rmse: 0.212214 ... keep big\n",
    "# [2796]\ttraining's rmse: 0.208275\tvalid_1's rmse: 0.212167\n",
    "# [2500]\ttraining's rmse: 0.208429\tvalid_1's rmse: 0.212098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5564, 'city_big'),\n",
       " (4520, 'param_1_big'),\n",
       " (3116, 'category_name'),\n",
       " (3044, 'region'),\n",
       " (2169, 'image_top_1_big'),\n",
       " (1428, 'rdgv19_preds'),\n",
       " (1427, 'difference_rnn_preds__rnn27_preds'),\n",
       " (1231, 'difference_rnn_preds__rnn12_preds'),\n",
       " (1090, 'param_3_big'),\n",
       " (1000, 'item_seq_number'),\n",
       " (990, 'difference_rnn27_preds__rnn12_preds'),\n",
       " (973, 'difference_lgb11D_preds__lgb14_preds'),\n",
       " (930, 'difference_lgb11D_preds__lgb17_preds'),\n",
       " (912, 'price'),\n",
       " (911, 'difference_lgb09_preds__lgb02A_preds'),\n",
       " (908, 'difference_lgb31_preds__lgb17_preds'),\n",
       " (875, 'difference_lgb31_preds__lgb09_preds'),\n",
       " (862, 'difference_lgb09_preds__lgb10_preds'),\n",
       " (850, 'difference_mlp_preds__rnn27_preds'),\n",
       " (844, 'difference_lgb10_preds__lgb02A_preds'),\n",
       " (832, 'difference_lgb14_preds__lgb17_preds'),\n",
       " (825, 'lgb17_preds'),\n",
       " (810, 'difference_lgb31_preds__lgb02A_preds'),\n",
       " (807, 'difference_mlp_preds__lgb31_preds'),\n",
       " (804, 'difference_mlp_preds__rnn12_preds'),\n",
       " (779, 'difference_lgb10_preds__lgb17_preds'),\n",
       " (762, 'difference_lgb10_preds__lgb14_preds'),\n",
       " (753, 'difference_rnn_preds__mlp_preds'),\n",
       " (751, 'sums_lgb17_preds__rnn27_preds'),\n",
       " (729, 'difference_lgb31_preds__lgb10_preds'),\n",
       " (729, 'difference_lgb17_preds__lgb02A_preds'),\n",
       " (725, 'difference_lgb10_preds__lgb11D_preds'),\n",
       " (723, 'min'),\n",
       " (720, 'difference_lgb31_preds__lgb14_preds'),\n",
       " (718, 'mlp_preds'),\n",
       " (717, 'sums_mlp_preds__lgb17_preds'),\n",
       " (706, 'difference_lgb09_preds__lgb14_preds'),\n",
       " (698, 'difference_lgb31_preds__lgb11D_preds'),\n",
       " (697, 'param_2_big'),\n",
       " (687, 'difference_lgb09_preds__lgb17_preds'),\n",
       " (682, 'difference_lgb11D_preds__lgb02A_preds'),\n",
       " (682, 'difference_lgb09_preds__lgb11D_preds'),\n",
       " (681, 'sums_lgb17_preds__rnn12_preds'),\n",
       " (672, 'sums_lgb14_preds__lgb17_preds'),\n",
       " (660, 'difference_mlp_preds__lgb02A_preds'),\n",
       " (647, 'difference_lgb14_preds__lgb02A_preds'),\n",
       " (644, 'difference_mlp_preds__lgb10_preds'),\n",
       " (642, 'difference_lgb31_preds__rnn12_preds'),\n",
       " (608, 'difference_mlp_preds__lgb11D_preds'),\n",
       " (603, 'difference_lgb31_preds__rnn27_preds'),\n",
       " (597, 'difference_mlp_preds__lgb17_preds'),\n",
       " (586, 'difference_mlp_preds__lgb14_preds'),\n",
       " (586, 'sums_lgb14_preds__rnn27_preds'),\n",
       " (575, 'sums_mlp_preds__lgb14_preds'),\n",
       " (572, 'difference_rnn_preds__lgb31_preds'),\n",
       " (568, 'difference_lgb17_preds__rnn12_preds'),\n",
       " (563, 'difference_lgb14_preds__rnn12_preds'),\n",
       " (561, 'sums_lgb14_preds__rnn12_preds'),\n",
       " (561, 'difference_mlp_preds__lgb09_preds'),\n",
       " (560, 'lgb14_preds'),\n",
       " (553, 'difference_lgb10_preds__rnn12_preds'),\n",
       " (543, 'difference_rnn_preds__lgb17_preds'),\n",
       " (543, 'difference_lgb02A_preds__rnn12_preds'),\n",
       " (541, 'rnn27_preds'),\n",
       " (536, 'difference_lgb14_preds__rnn27_preds'),\n",
       " (536, 'difference_rnn_preds__lgb14_preds'),\n",
       " (530, 'std'),\n",
       " (523, 'difference_lgb17_preds__rnn27_preds'),\n",
       " (506, 'difference_lgb02A_preds__rnn27_preds'),\n",
       " (505, 'difference_rnn_preds__lgb11D_preds'),\n",
       " (501, 'difference_lgb11D_preds__rnn27_preds'),\n",
       " (501, 'difference_lgb10_preds__rnn27_preds'),\n",
       " (498, 'difference_lgb11D_preds__rnn12_preds'),\n",
       " (479, 'difference_lgb09_preds__rnn27_preds'),\n",
       " (463, 'lgb27_preds'),\n",
       " (457, 'sums_mlp_preds__rnn27_preds'),\n",
       " (454, 'difference_rnn_preds__lgb02A_preds'),\n",
       " (445, 'rnn12_preds'),\n",
       " (442, 'difference_lgb09_preds__rnn12_preds'),\n",
       " (439, 'difference_rnn_preds__lgb10_preds'),\n",
       " (435, 'difference_rnn_preds__lgb09_preds'),\n",
       " (433, 'sums_mlp_preds__rnn12_preds'),\n",
       " (396, 'sums_rnn27_preds__rnn12_preds'),\n",
       " (394, 'lgb11A_preds'),\n",
       " (378, 'lgb02_preds'),\n",
       " (370, 'rnn_preds'),\n",
       " (348, 'sums_rnn_preds__mlp_preds'),\n",
       " (333, 'sums_mlp_preds__lgb11D_preds'),\n",
       " (333, 'sums_mlp_preds__lgb02A_preds'),\n",
       " (332, 'sums_rnn_preds__rnn12_preds'),\n",
       " (321, 'sums_mlp_preds__lgb09_preds'),\n",
       " (317, 'parent_category_name'),\n",
       " (313, 'sums_lgb11D_preds__rnn12_preds'),\n",
       " (301, 'sums_rnn_preds__rnn27_preds'),\n",
       " (297, 'sums_mlp_preds__lgb10_preds'),\n",
       " (288, 'lgb11D_preds'),\n",
       " (287, 'lgb02A_preds'),\n",
       " (276, 'sums_lgb31_preds__rnn27_preds'),\n",
       " (275, 'sums_mlp_preds__lgb31_preds'),\n",
       " (275, 'lgb09_preds'),\n",
       " (268, 'max'),\n",
       " (268, 'lgb31_preds'),\n",
       " (262, 'sums_lgb11D_preds__lgb17_preds'),\n",
       " (260, 'sums_lgb11D_preds__rnn27_preds'),\n",
       " (259, 'sums_lgb02A_preds__rnn12_preds'),\n",
       " (254, 'lgb10_preds'),\n",
       " (250, 'sums_rnn_preds__lgb11D_preds'),\n",
       " (245, 'sums_lgb02A_preds__rnn27_preds'),\n",
       " (243, 'sums_rnn_preds__lgb10_preds'),\n",
       " (243, 'sums_lgb31_preds__lgb02A_preds'),\n",
       " (236, 'sums_lgb09_preds__rnn27_preds'),\n",
       " (235, 'sums_lgb31_preds__rnn12_preds'),\n",
       " (230, 'sums_rnn_preds__lgb14_preds'),\n",
       " (229, 'sums_lgb10_preds__rnn27_preds'),\n",
       " (229, 'sums_lgb09_preds__rnn12_preds'),\n",
       " (227, 'sums_lgb10_preds__lgb17_preds'),\n",
       " (227, 'sums_lgb09_preds__lgb17_preds'),\n",
       " (224, 'sums_rnn_preds__lgb09_preds'),\n",
       " (221, 'sums_rnn_preds__lgb31_preds'),\n",
       " (219, 'sums_lgb10_preds__rnn12_preds'),\n",
       " (217, 'sums_lgb11D_preds__lgb14_preds'),\n",
       " (212, 'sums_rnn_preds__lgb17_preds'),\n",
       " (211, 'sums_lgb31_preds__lgb11D_preds'),\n",
       " (201, 'sums_lgb09_preds__lgb02A_preds'),\n",
       " (201, 'sums_rnn_preds__lgb02A_preds'),\n",
       " (196, 'sums_lgb09_preds__lgb10_preds'),\n",
       " (194, 'sums_lgb10_preds__lgb02A_preds'),\n",
       " (192, 'sums_lgb31_preds__lgb14_preds'),\n",
       " (191, 'sums_lgb09_preds__lgb11D_preds'),\n",
       " (185, 'sums_lgb09_preds__lgb14_preds'),\n",
       " (183, 'sums_lgb31_preds__lgb10_preds'),\n",
       " (182, 'sums_lgb14_preds__lgb02A_preds'),\n",
       " (182, 'sums_lgb31_preds__lgb17_preds'),\n",
       " (171, 'med'),\n",
       " (171, 'sums_lgb10_preds__lgb14_preds'),\n",
       " (164, 'sums_lgb31_preds__lgb09_preds'),\n",
       " (163, 'sums_lgb10_preds__lgb11D_preds'),\n",
       " (160, 'sums_lgb17_preds__lgb02A_preds'),\n",
       " (155, 'sums_lgb11D_preds__lgb02A_preds'),\n",
       " (138, 'avg'),\n",
       " (88, 'user_type')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(clf.feature_importances_, train_X.columns ),key=lambda x: -x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1503424"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = 2750\n",
    "train_X = train_df[cols]\n",
    "train_y = y\n",
    "eval_set = [(train_X,train_y)]\n",
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 80 rounds.\n",
      "[100]\ttraining's rmse: 0.21927\n",
      "[200]\ttraining's rmse: 0.212895\n",
      "[300]\ttraining's rmse: 0.211813\n",
      "[400]\ttraining's rmse: 0.211491\n",
      "[500]\ttraining's rmse: 0.211295\n",
      "[600]\ttraining's rmse: 0.211131\n",
      "[700]\ttraining's rmse: 0.210989\n",
      "[800]\ttraining's rmse: 0.210858\n",
      "[900]\ttraining's rmse: 0.210735\n",
      "[1000]\ttraining's rmse: 0.210618\n",
      "[1100]\ttraining's rmse: 0.210506\n",
      "[1200]\ttraining's rmse: 0.210396\n",
      "[1300]\ttraining's rmse: 0.210288\n",
      "[1400]\ttraining's rmse: 0.210178\n",
      "[1500]\ttraining's rmse: 0.210073\n",
      "[1600]\ttraining's rmse: 0.209966\n",
      "[1700]\ttraining's rmse: 0.209866\n",
      "[1800]\ttraining's rmse: 0.20976\n",
      "[1900]\ttraining's rmse: 0.209658\n",
      "[2000]\ttraining's rmse: 0.209556\n",
      "[2100]\ttraining's rmse: 0.209458\n",
      "[2200]\ttraining's rmse: 0.209357\n",
      "[2300]\ttraining's rmse: 0.209258\n",
      "[2400]\ttraining's rmse: 0.209158\n",
      "[2500]\ttraining's rmse: 0.209058\n",
      "[2600]\ttraining's rmse: 0.20896\n",
      "[2700]\ttraining's rmse: 0.208862\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2750]\ttraining's rmse: 0.208815\n",
      "Training until validation scores don't improve for 80 rounds.\n",
      "[100]\ttraining's rmse: 0.219273\n",
      "[200]\ttraining's rmse: 0.212898\n",
      "[300]\ttraining's rmse: 0.211811\n",
      "[400]\ttraining's rmse: 0.211494\n",
      "[500]\ttraining's rmse: 0.211297\n",
      "[600]\ttraining's rmse: 0.211136\n",
      "[700]\ttraining's rmse: 0.210991\n",
      "[800]\ttraining's rmse: 0.210864\n",
      "[900]\ttraining's rmse: 0.210742\n",
      "[1000]\ttraining's rmse: 0.210623\n",
      "[1100]\ttraining's rmse: 0.21051\n",
      "[1200]\ttraining's rmse: 0.210399\n",
      "[1300]\ttraining's rmse: 0.210291\n",
      "[1400]\ttraining's rmse: 0.210182\n",
      "[1500]\ttraining's rmse: 0.210076\n",
      "[1600]\ttraining's rmse: 0.209972\n",
      "[1700]\ttraining's rmse: 0.209867\n",
      "[1800]\ttraining's rmse: 0.209766\n",
      "[1900]\ttraining's rmse: 0.209667\n",
      "[2000]\ttraining's rmse: 0.209567\n",
      "[2100]\ttraining's rmse: 0.209464\n",
      "[2200]\ttraining's rmse: 0.209364\n",
      "[2300]\ttraining's rmse: 0.209265\n",
      "[2400]\ttraining's rmse: 0.209165\n",
      "[2500]\ttraining's rmse: 0.209067\n",
      "[2600]\ttraining's rmse: 0.208966\n",
      "[2700]\ttraining's rmse: 0.20887\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2750]\ttraining's rmse: 0.208822\n",
      "Training until validation scores don't improve for 80 rounds.\n",
      "[100]\ttraining's rmse: 0.219273\n",
      "[200]\ttraining's rmse: 0.212896\n",
      "[300]\ttraining's rmse: 0.211816\n",
      "[400]\ttraining's rmse: 0.211497\n",
      "[500]\ttraining's rmse: 0.211299\n",
      "[600]\ttraining's rmse: 0.211138\n",
      "[700]\ttraining's rmse: 0.210994\n",
      "[800]\ttraining's rmse: 0.210862\n",
      "[900]\ttraining's rmse: 0.21074\n",
      "[1000]\ttraining's rmse: 0.210622\n",
      "[1100]\ttraining's rmse: 0.210512\n",
      "[1200]\ttraining's rmse: 0.210405\n",
      "[1300]\ttraining's rmse: 0.210297\n",
      "[1400]\ttraining's rmse: 0.210189\n",
      "[1500]\ttraining's rmse: 0.210084\n",
      "[1600]\ttraining's rmse: 0.20998\n",
      "[1700]\ttraining's rmse: 0.209873\n",
      "[1800]\ttraining's rmse: 0.209768\n",
      "[1900]\ttraining's rmse: 0.209667\n",
      "[2000]\ttraining's rmse: 0.209563\n",
      "[2100]\ttraining's rmse: 0.209464\n",
      "[2200]\ttraining's rmse: 0.209363\n",
      "[2300]\ttraining's rmse: 0.209262\n",
      "[2400]\ttraining's rmse: 0.209162\n",
      "[2500]\ttraining's rmse: 0.209063\n",
      "[2600]\ttraining's rmse: 0.208965\n",
      "[2700]\ttraining's rmse: 0.208865\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2750]\ttraining's rmse: 0.208815\n",
      "Training until validation scores don't improve for 80 rounds.\n",
      "[100]\ttraining's rmse: 0.21927\n",
      "[200]\ttraining's rmse: 0.2129\n",
      "[300]\ttraining's rmse: 0.211819\n",
      "[400]\ttraining's rmse: 0.211499\n",
      "[500]\ttraining's rmse: 0.211302\n",
      "[600]\ttraining's rmse: 0.211141\n",
      "[700]\ttraining's rmse: 0.211\n",
      "[800]\ttraining's rmse: 0.210872\n",
      "[900]\ttraining's rmse: 0.21075\n",
      "[1000]\ttraining's rmse: 0.210632\n",
      "[1100]\ttraining's rmse: 0.210518\n",
      "[1200]\ttraining's rmse: 0.210409\n",
      "[1300]\ttraining's rmse: 0.210299\n",
      "[1400]\ttraining's rmse: 0.210192\n",
      "[1500]\ttraining's rmse: 0.210086\n",
      "[1600]\ttraining's rmse: 0.209978\n",
      "[1700]\ttraining's rmse: 0.209876\n",
      "[1800]\ttraining's rmse: 0.209773\n",
      "[1900]\ttraining's rmse: 0.20967\n",
      "[2000]\ttraining's rmse: 0.209568\n",
      "[2100]\ttraining's rmse: 0.209467\n",
      "[2200]\ttraining's rmse: 0.209368\n",
      "[2300]\ttraining's rmse: 0.20927\n",
      "[2400]\ttraining's rmse: 0.209169\n",
      "[2500]\ttraining's rmse: 0.209068\n",
      "[2600]\ttraining's rmse: 0.208968\n",
      "[2700]\ttraining's rmse: 0.208869\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2750]\ttraining's rmse: 0.208818\n",
      "Training until validation scores don't improve for 80 rounds.\n",
      "[100]\ttraining's rmse: 0.219273\n",
      "[200]\ttraining's rmse: 0.212897\n",
      "[300]\ttraining's rmse: 0.21181\n",
      "[400]\ttraining's rmse: 0.21149\n",
      "[500]\ttraining's rmse: 0.21129\n",
      "[600]\ttraining's rmse: 0.211133\n",
      "[700]\ttraining's rmse: 0.210992\n",
      "[800]\ttraining's rmse: 0.21086\n",
      "[900]\ttraining's rmse: 0.210736\n",
      "[1000]\ttraining's rmse: 0.210618\n",
      "[1100]\ttraining's rmse: 0.210505\n",
      "[1200]\ttraining's rmse: 0.210397\n",
      "[1300]\ttraining's rmse: 0.21029\n",
      "[1400]\ttraining's rmse: 0.210183\n",
      "[1500]\ttraining's rmse: 0.210079\n",
      "[1600]\ttraining's rmse: 0.209976\n",
      "[1700]\ttraining's rmse: 0.20987\n",
      "[1800]\ttraining's rmse: 0.209766\n",
      "[1900]\ttraining's rmse: 0.209664\n",
      "[2000]\ttraining's rmse: 0.209562\n",
      "[2100]\ttraining's rmse: 0.209461\n",
      "[2200]\ttraining's rmse: 0.20936\n",
      "[2300]\ttraining's rmse: 0.209259\n",
      "[2400]\ttraining's rmse: 0.209159\n",
      "[2500]\ttraining's rmse: 0.209062\n",
      "[2600]\ttraining's rmse: 0.20896\n",
      "[2700]\ttraining's rmse: 0.208861\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2750]\ttraining's rmse: 0.208812\n",
      "CPU times: user 5h 20min 19s, sys: 1min 30s, total: 5h 21min 50s\n",
      "Wall time: 42min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_predls = []\n",
    "for i in range(5):\n",
    "    clf = LGBMRegressor(n_estimators=n_estimators, \n",
    "                    max_depth=-1, \n",
    "                    feature_fraction= 0.4,\n",
    "                    num_leaves=32, \n",
    "                    seed = i, \n",
    "                    learning_rate=.01)#, device='gpu')\n",
    "    clf.fit(train_X, train_y, early_stopping_rounds=80, \n",
    "        eval_set=eval_set, eval_metric='rmse', verbose=100, \n",
    "        categorical_feature=categories)\n",
    "    y_predls.append(clf.predict(test_df[cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>deal_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1503424</th>\n",
       "      <td>6544e41a8817</td>\n",
       "      <td>0.453654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503425</th>\n",
       "      <td>65b9484d670f</td>\n",
       "      <td>0.146255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503426</th>\n",
       "      <td>8bab230b2ecd</td>\n",
       "      <td>0.139817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503427</th>\n",
       "      <td>8e348601fefc</td>\n",
       "      <td>0.103871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503428</th>\n",
       "      <td>8bd2fe400b89</td>\n",
       "      <td>0.160189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              item_id  deal_probability\n",
       "1503424  6544e41a8817          0.453654\n",
       "1503425  65b9484d670f          0.146255\n",
       "1503426  8bab230b2ecd          0.139817\n",
       "1503427  8e348601fefc          0.103871\n",
       "1503428  8bd2fe400b89          0.160189"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['deal_probability'] = sum(y_predls)/len(y_predls)\n",
    "test_df['deal_probability'] = np.clip(test_df['deal_probability'], .0001, .9999)\n",
    "test_df[['item_id', 'deal_probability']].to_csv('../lgbbsub_1906L2.csv.gz', compression='gzip', index=False, header=True)\n",
    "test_df[['item_id', 'deal_probability']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
